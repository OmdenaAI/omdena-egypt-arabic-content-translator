,text,summary,keywords,lang,title,html,publish_date
0,"مقدمة للتعلّم المُوَجَّه

إذا كان لدينا مجموعة من نقاط البيانات $\{x^{(1)}, ..., x^{(m)}\}$ مرتبطة بمجموعة مخرجات $\{y^{(1)}, ..., y^{(m)}\}$، نريد أن نبني مُصَنِّف يتعلم كيف يتوقع $y$ من $x$.

نوع التوقّع أنواع نماذج التوقّع المختلفة موضحة في الجدول التالي:

الانحدار (regression) التصنيف (classification) المُخرَج مستمر صنف أمثلة انحدار خطّي (linear regression) انحدار لوجستي (logistic regression) , آلة المتجهات الداعمة (SVM) , بايز البسيط (Naive Bayes)

نوع النموذج أنواع النماذج المختلفة موضحة في الجدول التالي:

نموذج تمييزي (discriminative) نموذج توليدي (generative) الهدف التقدير المباشر لـ $P(y|x)$ تقدير $P(x|y)$ ثم استنتاج $P(y|x)$ ماذا يتعلم حدود القرار التوزيع الاحتمالي للبيانات توضيح أمثلة الانحدار (regression) , آلة المتجهات الداعمة (SVM) GDA , بايز البسيط (Naive Bayes)

الرموز ومفاهيم أساسية

الفرضية (hypothesis) الفرضية، ويرمز لها بـ $h_\theta$، هي النموذج الذي نختاره. إذا كان لدينا المدخل $x^{(i)}$، فإن المخرج الذي سيتوقعه النموذج هو $h_\theta(x^{(i)})$.

دالة الخسارة (loss function) دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما. الجدول التالي يحتوي على بعض دوال الخسارة الشائعة:

خطأ أصغر تربيع

(least squared error) خسارة لوجستية

(logistic loss) خسارة مفصلية

(Hinge loss) الانتروبيا التقاطعية

(cross-entropy) $\displaystyle\frac{1}{2}(y-z)^2$ $\displaystyle\log(1+\exp(-yz))$ $\displaystyle\max(0,1-yz)$ $\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$ الانحدار الخطّي

(linear regression) الانحدار اللوجستي

(logistic regression) آلة المتجهات الداعمة

(SVM) الشبكات العصبية

(neural network)

دالة التكلفة (cost function) دالة التكلفة $J$ تستخدم عادة لتقييم أداء نموذج ما، ويتم تعريفها مع دالة الخسارة $L$ كالتالي:

\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]

النزول الاشتقاقي (gradient descent) لنعرّف معدل التعلّم $\alpha\in\mathbb{R}$، يمكن تعريف القانون الذي يتم تحديث خوارزمية النزول الاشتقاقي من خلاله باستخدام معدل التعلّم ودالة التكلفة $J$ كالتالي:

\[\boxed{\theta\longleftarrow\theta-\alpha

abla J(\theta)}\]

ملاحظة: في النزول الاشتقاقي العشوائي (stochastic gradient descent, SGD) يتم تحديث المُعاملات (parameters) بناءاً على كل عينة تدريب على حدة، بينما في النزول الاشتقاقي الحُزَمي (batch gradient descent) يتم تحديثها باستخدام حُزَم من عينات التدريب.

الأرجحية (likelihood) تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم (maximizing) الأرجحية. عملياً يتم استخدام الأرجحية اللوغاريثمية (log-likelihood) $\ell(\theta)=\log(L(\theta))$ حيث أنها أسهل في التحسين (optimize). فيكون لدينا:

\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]

خوارزمية نيوتن (Newton's algorithm) خوارزمية نيوتن هي طريقة حسابية للعثور على $\theta$ بحيث يكون $\ell'(\theta)=0$. قاعدة التحديث للخوارزمية كالتالي:

\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]

ملاحظة: هناك خوارزمية أعم وهي متعددة الأبعاد (multidimensional)، يطلق عليها خوارزمية نيوتن-رافسون (Newton-Raphson)، ويتم تحديثها عبر القانون التالي:

\[\theta\leftarrow\theta-\left(

abla_\theta^2\ell(\theta)\right)^{-1}

abla_\theta\ell(\theta)\]

النماذج الخطيّة (linear models)

الانحدار الخطّي (linear regression)

هنا نفترض أن $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$

المعادلة الطبيعية/الناظمية (normal) إذا كان لدينا المصفوفة $X$، القيمة $\theta$ التي تقلل من دالة التكلفة يمكن حلها رياضياً بشكل مغلق (closed-form) عن طريق:

\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]

خوارزمية أصغر معدل تربيع LMS إذا كان لدينا معدل التعلّم $\alpha$، فإن قانون التحديث لخوارزمية أصغر معدل تربيع (Least Mean Squares, LMS) لمجموعة بيانات من $m$ عينة، ويطلق عليه قانون تعلم ويدرو-هوف (Widrow-Hoff)، كالتالي:

\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]

ملاحظة: قانون التحديث هذا يعتبر حالة خاصة من النزول الاشتقاقي (gradient descent).

الانحدار الموزون محليّاً (LWR) الانحدار الموزون محليّاً (Locally Weighted Regression)، ويعرف بـ LWR، هو نوع من الانحدار الخطي يَزِن كل عينة تدريب أثناء حساب دالة التكلفة باستخدام $w^{(i)}(x)$، التي يمكن تعريفها باستخدام المُدخل (parameter) $\tau\in\mathbb{R}$ كالتالي:

\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]

التصنيف والانحدار اللوجستي

دالة سيجمويد (sigmoid) دالة سيجمويد $g$، وتعرف كذلك بالدالة اللوجستية، تعرّف كالتالي:

\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]

الانحدار اللوجستي (logistic regression) نفترض هنا أن $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. فيكون لدينا:

\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]

ملاحظة: ليس هناك حل رياضي مغلق للانحدار اللوجستي.

انحدار سوفت ماكس (softmax) ويطلق عليه الانحدار اللوجستي متعدد الأصناف (multiclass logistic regression)، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين. في العرف يتم تعيين $\theta_K=0$، بحيث تجعل مُدخل بيرنوللي (Bernoulli) $\phi_i$ لكل فئة $i$ يساوي:

\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]

النماذج الخطية العامة (Generalized Linear Models, GLM)

العائلة الأُسيّة (Exponential family) يطلق على صنف من التوزيعات (distributions) بأنها تنتمي إلى العائلة الأسيّة إذا كان يمكن كتابتها بواسطة مُدخل قانوني (canonical parameter) $\eta$، إحصاء كافٍ (sufficient statistic) $T(y)$، ودالة تجزئة لوغاريثمية $a(\eta)$، كالتالي:

\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]

ملاحظة: كثيراً ما سيكون $T(y)=y$. كذلك فإن $\exp(-a(\eta))$ يمكن أن تفسر كمُدخل تسوية (normalization) للتأكد من أن الاحتمالات يكون حاصل جمعها يساوي واحد.

تم تلخيص أكثر التوزيعات الأسيّة استخداماً في الجدول التالي:

التوزيع $\eta$ $T(y)$ $a(\eta)$ $b(y)$ بِرنوللي (Bernoulli) $\log\left(\frac{\phi}{1-\phi}\right)$ $y$ $\log(1+\exp(\eta))$ $1$ جاوسي (Gaussian) $\mu$ $y$ $\frac{\eta^2}{2}$ $\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$ بواسون (Poisson) $\log(\lambda)$ $y$ $e^{\eta}$ $\displaystyle\frac{1}{y!}$ هندسي (Geometric) $\log(1-\phi)$ $y$ $\log\left(\frac{e^\eta}{1-e^\eta}\right)$ $1$

افتراضات GLMs تهدف النماذج الخطيّة العامة (GLM) إلى توقع المتغير العشوائي $y$ كدالة لـ $x\in\mathbb{R}^{n+1}$، وتستند إلى ثلاثة افتراضات:

$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$ $(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$ $(3)\quad\boxed{\eta=\theta^Tx}$

ملاحظة: أصغر تربيع (least squares) الاعتيادي و الانحدار اللوجستي يعتبران من الحالات الخاصة للنماذج الخطيّة العامة.

آلة المتجهات الداعمة (Support Vector Machines)

تهدف آلة المتجهات الداعمة (SVM) إلى العثور على الخط الذي يعظم أصغر مسافة إليه:

مُصنِّف الهامش الأحسن (optimal margin classifier) يعرَّف مُصنِّف الهامش الأحسن $h$ كالتالي:

\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]

حيث $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ هو الحل لمشكلة التحسين (optimization) التالية:

\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\text{و }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]

ملاحظة: يتم تعريف الخط بهذه المعادلة $\boxed{w^Tx-b=0}$.

الخسارة المفصلية (Hinge loss) تستخدم الخسارة المفصلية في حل SVM ويعرف على النحو التالي:

\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]

النواة (kernel) إذا كان لدينا دالة ربط الخصائص (features) $\phi$، يمكننا تعريف النواة $K$ كالتالي:

\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]

عملياً، يمكن أن تُعَرَّف الدالة $K$ عن طريق المعادلة $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$، ويطلق عليها النواة الجاوسية (Gaussian kernel)، وهي تستخدم بكثرة.

ملاحظة: نقول أننا نستخدم ""حيلة النواة"" (kernel trick) لحساب دالة التكلفة عند استخدام النواة لأننا في الحقيقة لا نحتاج أن نعرف التحويل الصريح $\phi$، الذي يكون في الغالب شديد التعقيد. ولكن، نحتاج أن فقط أن نحسب القيم $K(x,z)$.

اللّاغرانجي (Lagrangian) يتم تعريف اللّاغرانجي $\mathcal{L}(w,b)$ على النحو التالي:

\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]

ملاحظة: المعامِلات (coefficients) $\beta_i$ يطلق عليها مضروبات لاغرانج (Lagrange multipliers).

التعلم التوليدي (generative learning)

النموذج التوليدي في البداية يحاول أن يتعلم كيف تم توليد البيانات عن طريق تقدير $P(x|y)$، التي يمكن حينها استخدامها لتقدير $P(y|x)$ باستخدام قانون بايز (Bayes' rule).

تحليل التمايز الجاوسي (Gaussian Discriminant Analysis)

الإطار تحليل التمايز الجاوسي يفترض أن $y$ و $x|y=0$ و $x|y=1$ بحيث يكونوا كالتالي:

$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$ $(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$ $(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$

التقدير الجدول التالي يلخص التقديرات التي يمكننا التوصل لها عند تعظيم الأرجحية (likelihood):

$\widehat{\phi}$ $\widehat{\mu_j}\quad{\small(j=0,1)}$ $\widehat{\Sigma}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$ $\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$

بايز البسيط (Naive Bayes)

الافتراض يفترض نموذج بايز البسيط أن جميع الخصائص لكل عينة بيانات مستقلة (independent):

\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]

الحل تعظيم الأرجحية اللوغاريثمية (log-likelihood) يعطينا الحلول التالية إذا كان $k\in\{0,1\},l\in[\![1,L]\!]$: $k\in\{0,1\},l\in[\![1,L]\!]$

\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ و }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ و }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]

ملاحظة: بايز البسيط يستخدم بشكل واسع لتصنيف النصوص واكتشاف البريد الإلكتروني المزعج.

الطرق الشجرية (tree-based) والتجميعية (ensemble)

هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار (regression) والتصنيف (classification).

التصنيف والانحدار الشجري (CART) والاسم الشائع له أشجار القرار (decision trees)، يمكن أن يمثل كأشجار ثنائية (binary trees). من المزايا لهذه الطريقة إمكانية تفسيرها بسهولة.

الغابة العشوائية (random forest) هي أحد الطرق الشجرية التي تستخدم عدداً كبيراً من أشجار القرار مبنية باستخدام مجموعة عشوائية من الخصائص. بخلاف شجرة القرار البسيطة لا يمكن تفسير النموذج بسهولة، ولكن أدائها العالي جعلها أحد الخوارزمية المشهورة.

ملاحظة: أشجار القرار نوع من الخوارزميات التجميعية (ensemble).

التعزيز (boosting) فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي. الطرق الأساسية ملخصة في الجدول التالي:

التعزيز التَكَيُّفي (adaptive boosting) التعزيز الاشتقاقي (gradient boosting) • يتم التركيز على مواطن الخطأ لتحسين النتيجة في الخطوة التالية. • يتم تدريب خوارزميات التعلم الضعيفة على الأخطاء المتبقية.

طرق أخرى غير بارامترية (non-parametric)

خوارزمية أقرب الجيران ($k$-nearest neighbors) تعتبر خوارزمية أقرب الجيران، وتعرف بـ $k$-NN، طريقة غير بارامترية، حيث يتم تحديد نتيجة عينة من البيانات من خلال عدد $k$ من البيانات المجاورة في مجموعة التدريب. ويمكن استخدامها للتصنيف والانحدار.

ملاحظة: كلما زاد المُدخل $k$، كلما زاد الانحياز (bias)، وكلما نقص $k$، زاد التباين (variance).

نظرية التعلُّم

حد الاتحاد (union bound) لنجعل $A_1, ..., A_k$ تمثل $k$ حدث. فيكون لدينا:

\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]

متراجحة هوفدينج (Hoeffding) لنجعل $Z_1, .., Z_m$ تمثل $m$ متغير مستقلة وموزعة بشكل مماثل (iid) مأخوذة من توزيع بِرنوللي (Bernoulli distribution) ذا مُدخل $\phi$. لنجعل $\widehat{\phi}$ متوسط العينة (sample mean) و $\gamma>0$ ثابت. فيكون لدينا:

\[\boxed{P(|\phi-\widehat{\phi}|>\gamma)\leqslant2\exp(-2\gamma^2m)}\]

ملاحظة: هذه المتراجحة تعرف كذلك بحد تشرنوف (Chernoff bound).

خطأ التدريب ليكن لدينا المُصنِّف $h$، يمكن تعريف خطأ التدريب $\widehat{\epsilon}(h)$، ويعرف كذلك بالخطر التجريبي أو الخطأ التجريبي، كالتالي:

\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})

eq y^{(i)}\}}}\]

تقريباً صحيح احتمالياً (Probably Approximately Correct, PAC) هو إطار يتم من خلاله إثبات العديد من نظريات التعلم، ويحتوي على الافتراضات التالية:

- مجموعتي التدريب والاختبار يتبعان نفس التوزيع.

- عينات التدريب تؤخذ بشكل مستقل.

مجموعة تكسيرية (shattering set) إذا كان لدينا المجموعة $S=\{x^{(1)},...,x^{(d)}\}$، ومجموعة مُصنٍّفات $\mathcal{H}$، نقول أن $\mathcal{H}$ تكسر $S$ (H shatters S) إذا كان لكل مجموعة علامات (labels) $\{y^{(1)}, ..., y^{(d)}\}$ لدينا:

\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]

مبرهنة الحد الأعلى (upper bound theorem) لنجعل $\mathcal{H}$ فئة فرضية محدودة (finite hypothesis class) بحيث $|\mathcal{H}|=k$، و $\delta$ وحجم العينة $m$ ثابتين. حينها سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:

\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]

بُعْد فابنيك تشرفونيكس (Vapnik-Chervonenkis, VC) لفئة فرضية غير محدودة (infinite hypothesis class) $\mathcal{H}$، ويرمز له بـ $\textrm{VC}(\mathcal{H})$، هو حجم أكبر مجموعة (set) التي تم تكسيرها بواسطة $\mathcal{H}$ (shattered by $\mathcal{H}$).

مبرهنة فابنيك (Vapnik theorem) ليكن لدينا $\mathcal{H}$، مع $\textrm{VC}(\mathcal{H})=d$ وعدد عيّنات التدريب $m$. سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:

\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]","دالة الخسارة (loss function) دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما.
الأرجحية (likelihood) تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم (maximizing) الأرجحية.
انحدار سوفت ماكس (softmax) ويطلق عليه الانحدار اللوجستي متعدد الأصناف (multiclass logistic regression)، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين.
الطرق الشجرية (tree-based) والتجميعية (ensemble)هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار (regression) والتصنيف (classification).
التعزيز (boosting) فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي.","['لدينا', 'regression', 'أن', 'إذا', 'الانحدار', 'يتم', 'y', 'تعلم', 'دالة', 'الجدول', 'باستخدام', 'موجه']",ar,تعلّم موجَّه,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>تعلّم موجَّه - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-supervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلّم موجَّه</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>مقدمة</a></div> <div class=dropdown-container> <a href=#introduction><span>نوع التوقع</span></a> <a href=#introduction><span>نوع النموذج</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#notations>الرموز ومفاهيم أساسية</a></div> <div class=dropdown-container> <a href=#notations><span>دالة الخسارة</span></a> <a href=#notations><span>النزول الاشتقاقي</span></a> <a href=#notations><span>الأرجحية</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#linear-models>النماذج الخطيّة</a></div> <div class=dropdown-container> <a href=#linear-models><span>الانحدار الخطّي</span></a> <a href=#linear-models><span>الانحدار اللوجستي</span></a> <a href=#linear-models><span>النماذج الخطية العامة</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#svm>آلة المتجهات الداعمة <span class=ltr>(SVM)</span></a></div> <div class=dropdown-container> <a href=#svm><span>مُصنِّف الهامش الأحسن</span></a> <a href=#svm><span>الفرق المفصلي</span></a> <a href=#svm><span>النواة</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#generative-learning>التعلم التوليدي</a></div> <div class=dropdown-container> <a href=#generative-learning><span>تحليل التمايز الجاوسي</span></a> <a href=#generative-learning><span>بايز البسيط</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#tree>الطرق الشجرية والتجميعية</a></div> <div class=dropdown-container> <a href=#tree><span>التصنيف والانحدار الشجري    <span class=ltr>(CART)</span></span></a> <a href=#tree><span>الغابة العشوائية <span class=ltr>(random forest)</span></span></a> <a href=#tree><span>التعزيز <span class=ltr>(boosting)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#other>طرق أخرى</a></div> <div class=dropdown-container> <a href=#other><span>خوارزمية أقرب الجيران <span class=ltr>(k-NN)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#learning-theory>نظرية التعلُّم</a></div> <div class=dropdown-container> <a href=#learning-theory><span>متراجحة هوفدنك</span></a> <a href=#learning-theory><span>تقريباً صحيح احتمالياً <span class=ltr>(PAC)</span></span></a> <a href=#learning-theory><span>بُعْد فابنيك-تشرفونيكس <span class=ltr>(VC     dimension)</span></span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-supervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button><b>تعلّم موجَّه</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع للتعلّم المُوَجَّه
</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة فارس القنيعير. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>مقدمة للتعلّم المُوَجَّه</h2>
<p>إذا كان لدينا مجموعة من نقاط البيانات $\{x^{(1)}, ..., x^{(m)}\}$ مرتبطة بمجموعة مخرجات $\{y^{(1)}, ..., y^{(m)}\}$، نريد أن نبني مُصَنِّف يتعلم كيف يتوقع $y$ من $x$.</p>
<p><span class=""new-item item-b"">نوع التوقّع</span> أنواع نماذج التوقّع المختلفة موضحة في الجدول التالي:</p>
<div class=mobile-container>
<center>
  <table style=""table-layout:fixed; width:100%; min-width:300px;"">
  <colgroup>
  <col style=width:120px>
  <col style=width:50%>
  <col style=width:50%>
  </colgroup>
<tbody>
<tr>
<td align=center><b></b></td>
<td align=center><b>الانحدار <span class=""ltr stick-together"">(regression)</span></b></td>
<td align=center><b>التصنيف <span class=""ltr stick-together"">(classification)</span></b></td>
</tr>
<tr>
<td align=center><b>المُخرَج</b></td>
<td align=center>مستمر</td>
<td align=center>صنف</td>
</tr>
<tr>
<td align=center><b>أمثلة</b></td>
<td align=center>انحدار خطّي <span class=""ltr stick-together"">(linear regression)</span></td>
<td align=center>انحدار لوجستي <span class=""ltr stick-together"">(logistic regression)</span>, آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span>, بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">نوع النموذج</span> أنواع النماذج المختلفة موضحة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:300px;"">
<colgroup>
<col style=width:120px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>نموذج تمييزي <span class=""ltr stick-together"">(discriminative)</span></b></td>
<td align=center><b>نموذج توليدي <span class=""ltr stick-together"">(generative)</span></b></td>
</tr>
<tr>
<td align=center><b>الهدف</b></td>
<td align=right>التقدير المباشر لـ $P(y|x)$</td>
<td align=right>تقدير $P(x|y)$ ثم استنتاج $P(y|x)$</td>
</tr>
<tr>
<td align=center><b>ماذا يتعلم</b></td>
<td align=right>حدود القرار</td>
<td align=right>التوزيع الاحتمالي للبيانات</td>
</tr>
<tr>
<td align=center><b>توضيح</b></td>
<td align=center style=""width: 41%;""><img alt=""Discriminative model"" class=img-responsive src=teaching/cs-229/illustrations/discriminative-model.png?767b34c21d43a4fd8b59683578e132f9></td>
<td align=center style=""width: 41%;""><img alt=""Generative model"" class=img-responsive src=teaching/cs-229/illustrations/generative-model.png?df0642cec6e99ac162cd4848d26f41c3></td>
</tr>
<tr>
<td align=center><b>أمثلة</b></td>
<td align=right>الانحدار <span class=""ltr stick-together"">(regression)</span>, آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span></td>
<td align=right><span class=""ltr stick-together"">GDA</span>, بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>الرموز ومفاهيم أساسية</h2>
<p><span class=""new-item item-b"">الفرضية <span class=""ltr stick-together"">(hypothesis)</span></span> الفرضية، ويرمز لها بـ $h_\theta$، هي النموذج الذي نختاره. إذا كان لدينا المدخل $x^{(i)}$، فإن المخرج الذي سيتوقعه النموذج هو $h_\theta(x^{(i)})$.</p>
<br>
<p><span class=""new-item item-r"">دالة الخسارة <span class=""ltr stick-together"">(loss function)</span></span> دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما. الجدول التالي يحتوي على بعض دوال الخسارة الشائعة:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:820px;"">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>خطأ أصغر تربيع <br><span class=""ltr stick-together"">(least squared error)</span></b></td>
<td align=center><b>خسارة لوجستية <br><span class=""ltr stick-together"">(logistic loss)</span></b></td>
<td align=center><b>خسارة مفصلية <br><span class=""ltr stick-together"">(Hinge loss)</span></b></td>
<td align=center><b>الانتروبيا التقاطعية <br><span class=""ltr stick-together"">(cross-entropy)</span></b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{2}(y-z)^2$</td>
<td align=center>$\displaystyle\log(1+\exp(-yz))$</td>
<td align=center>$\displaystyle\max(0,1-yz)$</td>
<td align=center style=vertical-align:middle><div id=some_math style=font-size:75%>$\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$</div></td>
</tr>
<tr>
<td align=center style=""width: 25%;""><img alt=""Least squared error"" class=img-responsive src=teaching/cs-229/illustrations/least-square-error.png?63fef2552284b0dc15f27d1ef0b79fea></td>
<td align=center style=""width: 25%;""><img alt=""Logistic loss"" class=img-responsive src=teaching/cs-229/illustrations/logistic-loss.png?1bc1cb6d682c1bbfb978ec894afdf588></td>
<td align=center style=""width: 25%;""><img alt=""Hinge loss"" class=img-responsive src=teaching/cs-229/illustrations/hinge-loss.png?3f1b26410c446f52885dcc5266937c84></td>
<td align=center style=""width: 25%;""><img alt=""Cross entropy"" class=img-responsive src=teaching/cs-229/illustrations/cross-entropy.png?037ea4073873c9be4a7de099dac6d3b5></td>
</tr>
<tr>
<td align=center>الانحدار الخطّي <br><span class=""ltr stick-together"">(linear regression)</span></td>
<td align=center>الانحدار اللوجستي <br><span class=""ltr stick-together"">(logistic regression)</span></td>
<td align=center>آلة المتجهات الداعمة <br><span class=""ltr stick-together"">(SVM)</span></td>
<td align=center>الشبكات العصبية <br><span class=""ltr stick-together"">(neural network)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">دالة التكلفة <span class=""ltr stick-together"">(cost function)</span></span> دالة التكلفة $J$ تستخدم عادة لتقييم أداء نموذج ما، ويتم تعريفها مع دالة الخسارة $L$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]
</div>
<br>
<p><span class=""new-item item-r"">النزول الاشتقاقي <span class=""ltr stick-together"">(gradient descent)</span></span> لنعرّف معدل التعلّم $\alpha\in\mathbb{R}$، يمكن تعريف القانون الذي يتم تحديث خوارزمية النزول الاشتقاقي من خلاله باستخدام معدل التعلّم ودالة التكلفة $J$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{\theta\longleftarrow\theta-\alpha\nabla J(\theta)}\]
</div>
<br>
<center>
<img alt=""Gradient descent"" class=img-responsive src=teaching/cs-229/illustrations/gradient-descent.png?01662c4a8147a55ba09f4f5c047641ba style=width:100%;max-width:500px>
</center>
<br>
<p><span class=remark>ملاحظة: في النزول الاشتقاقي العشوائي <span class=""ltr stick-together"">(stochastic gradient descent, SGD)</span> يتم تحديث المُعاملات <span class=""ltr stick-together"">(parameters)</span> بناءاً على كل عينة تدريب على حدة، بينما في النزول الاشتقاقي الحُزَمي <span class=""ltr stick-together"">(batch gradient descent)</span> يتم تحديثها باستخدام حُزَم من عينات التدريب.</span></p>
<br>
<p><span class=""new-item item-b"">الأرجحية <span class=""ltr stick-together"">(likelihood)</span></span> تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم <span class=""ltr stick-together"">(maximizing)</span> الأرجحية. عملياً يتم استخدام الأرجحية اللوغاريثمية <span class=""ltr stick-together"">(log-likelihood)</span> $\ell(\theta)=\log(L(\theta))$ حيث أنها أسهل في التحسين (optimize). فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]
</div>
<br>
<p><span class=""new-item item-r"">خوارزمية نيوتن <span class=""ltr stick-together"">(Newton's algorithm)</span></span> خوارزمية نيوتن هي طريقة حسابية للعثور على $\theta$ بحيث يكون $\ell'(\theta)=0$. قاعدة التحديث للخوارزمية كالتالي:</p>
<div class=mobile-container>
\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]
</div>
<p><span class=remark>ملاحظة: هناك خوارزمية أعم وهي متعددة الأبعاد <span class=""ltr stick-together"">(multidimensional)</span>، يطلق عليها خوارزمية نيوتن-رافسون <span class=""ltr stick-together"">(Newton-Raphson)</span>، ويتم تحديثها عبر القانون التالي:</span></p>
<div class=mobile-container>
\[\theta\leftarrow\theta-\left(\nabla_\theta^2\ell(\theta)\right)^{-1}\nabla_\theta\ell(\theta)\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#linear-models id=linear-models></a>النماذج الخطيّة <span class=""ltr stick-together"">(linear models)</span></h2>
<h3>الانحدار الخطّي <span class=""ltr stick-together"">(linear regression)</span></h3>
<p>هنا نفترض أن $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$</p>
<p><span class=""new-item item-g"">المعادلة الطبيعية/الناظمية <span class=""ltr stick-together"">(normal)</span></span> إذا كان لدينا المصفوفة $X$، القيمة $\theta$ التي تقلل من دالة التكلفة يمكن حلها رياضياً بشكل مغلق <span class=""ltr stick-together"">(closed-form)</span> عن طريق:</p>
<div class=mobile-container>
\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]
</div>
<br>
<p><span class=""new-item item-g"">خوارزمية أصغر معدل تربيع <span class=""ltr stick-together"">LMS</span></span> إذا كان لدينا معدل التعلّم $\alpha$، فإن قانون التحديث لخوارزمية أصغر معدل تربيع <span class=""ltr stick-together"">(Least Mean Squares, LMS)</span> لمجموعة بيانات من $m$ عينة، ويطلق عليه قانون تعلم ويدرو-هوف <span class=""ltr stick-together"">(Widrow-Hoff)</span>، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]
</div>
<p><span class=remark>ملاحظة: قانون التحديث هذا يعتبر حالة خاصة من النزول الاشتقاقي <span class=""ltr stick-together"">(gradient descent)</span>.</span></p>
<br>
<p><span class=""new-item item-b"">الانحدار الموزون محليّاً <span class=""ltr stick-together"">(LWR)</span></span> الانحدار الموزون محليّاً <span class=""ltr stick-together"">(Locally Weighted Regression)</span>، ويعرف بـ <span class=""ltr stick-together"">LWR</span>، هو نوع من الانحدار الخطي يَزِن كل عينة تدريب أثناء حساب دالة التكلفة باستخدام $w^{(i)}(x)$، التي يمكن تعريفها باستخدام المُدخل <span class=""ltr stick-together"">(parameter)</span> $\tau\in\mathbb{R}$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]
</div>
<br>
<h3>التصنيف والانحدار اللوجستي</h3>
<p><span class=""new-item item-b"">دالة سيجمويد <span class=""ltr stick-together"">(sigmoid)</span></span> دالة سيجمويد $g$، وتعرف كذلك بالدالة اللوجستية، تعرّف كالتالي:</p>
<div class=mobile-container>
\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]
</div>
<br>
<p><span class=""new-item item-b"">الانحدار اللوجستي <span class=""ltr stick-together"">(logistic regression)</span></span> نفترض هنا أن  $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]
</div>
<p><span class=remark>ملاحظة: ليس هناك حل رياضي مغلق للانحدار اللوجستي.</span></p>
<br>
<p><span class=""new-item item-b"">انحدار سوفت ماكس <span class=""ltr stick-together"">(softmax)</span></span> ويطلق عليه الانحدار اللوجستي متعدد الأصناف <span class=""ltr stick-together"">(multiclass logistic regression)</span>، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين. في العرف يتم تعيين $\theta_K=0$، بحيث تجعل مُدخل بيرنوللي <span class=""ltr stick-together"">(Bernoulli)</span> $\phi_i$ لكل فئة $i$ يساوي:</p>
<div class=mobile-container>
\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]
</div>
<br>
<h3>النماذج الخطية العامة <span class=""ltr stick-together"">(Generalized Linear Models, GLM)</span></h3>
<p><span class=""new-item item-r"">العائلة الأُسيّة <span class=""ltr stick-together"">(Exponential family)</span></span> يطلق على صنف من التوزيعات <span class=""ltr stick-together"">(distributions)</span> بأنها تنتمي إلى العائلة الأسيّة إذا كان يمكن كتابتها بواسطة مُدخل قانوني <span class=""ltr stick-together"">(canonical parameter)</span> $\eta$، إحصاء كافٍ <span class=""ltr stick-together"">(sufficient statistic)</span> $T(y)$، ودالة تجزئة لوغاريثمية $a(\eta)$، كالتالي:</p>
<div class=mobile-container>
\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]
</div>
<p><span class=remark>ملاحظة: كثيراً ما سيكون $T(y)=y$. كذلك فإن $\exp(-a(\eta))$ يمكن أن تفسر كمُدخل تسوية <span class=""ltr stick-together"">(normalization)</span> للتأكد من أن الاحتمالات يكون حاصل جمعها يساوي واحد.</span></p>
<p>تم تلخيص أكثر التوزيعات الأسيّة استخداماً في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>التوزيع</b></td>
<td align=center><b>$\eta$</b></td>
<td align=center><b>$T(y)$</b></td>
<td align=center><b>$a(\eta)$</b></td>
<td align=center><b>$b(y)$</b></td>
</tr>
<tr>
<td align=center>بِرنوللي <span class=""ltr stick-together"">(Bernoulli)</span></td>
<td align=center>$\log\left(\frac{\phi}{1-\phi}\right)$</td>
<td align=center>$y$</td>
<td align=center>$\log(1+\exp(\eta))$</td>
<td align=center>$1$</td>
</tr>
<tr>
<td align=center>جاوسي <span class=""ltr stick-together"">(Gaussian)</span></td>
<td align=center>$\mu$</td>
<td align=center>$y$</td>
<td align=center>$\frac{\eta^2}{2}$</td>
<td align=center>$\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$</td>
</tr>
<tr>
<td align=center>بواسون <span class=""ltr stick-together"">(Poisson)</span></td>
<td align=center>$\log(\lambda)$</td>
<td align=center>$y$</td>
<td align=center>$e^{\eta}$</td>
<td align=center>$\displaystyle\frac{1}{y!}$</td>
</tr>
<tr>
<td align=center>هندسي <span class=""ltr stick-together"">(Geometric)</span></td>
<td align=center>$\log(1-\phi)$</td>
<td align=center>$y$</td>
<td align=center>$\log\left(\frac{e^\eta}{1-e^\eta}\right)$</td>
<td align=center>$1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">افتراضات <span class=""ltr stick-together"">GLMs</span></span> تهدف النماذج الخطيّة العامة <span class=""ltr stick-together"">(GLM)</span> إلى توقع المتغير العشوائي $y$ كدالة لـ $x\in\mathbb{R}^{n+1}$، وتستند إلى ثلاثة افتراضات:
</p>
<div class=row>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(3)\quad\boxed{\eta=\theta^Tx}$</div>
</div>
<br>
<p><span class=remark>ملاحظة: أصغر تربيع <span class=""ltr stick-together"">(least squares)</span> الاعتيادي و الانحدار اللوجستي يعتبران من الحالات الخاصة للنماذج الخطيّة العامة.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#svm id=svm></a>آلة المتجهات الداعمة <span class=""ltr stick-together"">(Support Vector Machines)</span></h2>
<p>تهدف آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span> إلى العثور على الخط الذي يعظم أصغر مسافة إليه:</p>
<p><span class=""new-item item-b"">مُصنِّف الهامش الأحسن <span class=""ltr stick-together"">(optimal margin classifier)</span></span> يعرَّف مُصنِّف الهامش الأحسن $h$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]
</div>
<p>حيث $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ هو الحل لمشكلة التحسين <span class=""ltr stick-together"">(optimization)</span> التالية:</p>
<div class=mobile-container>
\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\text{و }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]
</div>
<center>
<img alt=SVM class=img-responsive src=teaching/cs-229/illustrations/svm-ar.png?7780eef79aa94961ada7f3bebb5be22a style=width:100%;max-width:600px>
</center>
<p><span class=remark>ملاحظة: يتم تعريف الخط بهذه المعادلة <span style=""font-family: monospace !important;"">$\boxed{w^Tx-b=0}$</span>.</span></p>
<br>
<p><span class=""new-item item-b"">الخسارة المفصلية <span class=""ltr stick-together"">(Hinge loss)</span></span> تستخدم الخسارة المفصلية في حل <span class=""ltr stick-together"">SVM</span> ويعرف على النحو التالي:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]
</div>
<br>
<p><span class=""new-item item-b"">النواة <span class=""ltr stick-together"">(kernel)</span></span> إذا كان لدينا دالة ربط الخصائص <span class=""ltr stick-together"">(features)</span> $\phi$، يمكننا تعريف النواة $K$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]
</div>
<p>عملياً، يمكن أن تُعَرَّف الدالة $K$ عن طريق المعادلة $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$، ويطلق عليها النواة الجاوسية <span class=""ltr stick-together"">(Gaussian kernel)</span>، وهي تستخدم بكثرة.</p>
<center>
<img alt=""SVM kernel"" class=img-responsive src=teaching/cs-229/illustrations/svm-kernel-ar.png?2bd4e3e7bf624b23c1640ed04e234f44>
</center>
<br>
<p><span class=remark>ملاحظة: نقول أننا نستخدم ""حيلة النواة"" <span class=""ltr stick-together"">(kernel trick)</span> لحساب دالة التكلفة عند استخدام النواة لأننا في الحقيقة لا نحتاج أن نعرف التحويل الصريح $\phi$، الذي يكون في الغالب شديد التعقيد. ولكن، نحتاج أن فقط أن نحسب القيم $K(x,z)$.</span></p>
<br>
<p><span class=""new-item item-r"">اللّاغرانجي <span class=""ltr stick-together"">(Lagrangian)</span></span> يتم تعريف اللّاغرانجي $\mathcal{L}(w,b)$ على النحو التالي:</p>
<div class=mobile-container>
\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]
</div>
<p><span class=remark>ملاحظة: المعامِلات <span class=""ltr stick-together"">(coefficients)</span> $\beta_i$ يطلق عليها مضروبات لاغرانج <span class=""ltr stick-together"">(Lagrange multipliers)</span>.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#generative-learning id=generative-learning></a>التعلم التوليدي <span class=""ltr stick-together"">(generative learning)</span></h2>
<p>النموذج التوليدي في البداية يحاول أن يتعلم كيف تم توليد البيانات عن طريق تقدير $P(x|y)$، التي يمكن حينها استخدامها لتقدير $P(y|x)$ باستخدام قانون بايز <span class=""ltr stick-together"">(Bayes' rule)</span>.</p>
<h3>تحليل التمايز الجاوسي <span class=""ltr stick-together"">(Gaussian Discriminant Analysis)</span></h3>
<p><span class=""new-item item-b"">الإطار</span> تحليل التمايز الجاوسي يفترض أن $y$ و $x|y=0$ و $x|y=1$ بحيث يكونوا كالتالي:</p>
<div class=row>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$</div>
</div>
<br>
<p><span class=""new-item item-b"">التقدير</span> الجدول التالي يلخص التقديرات التي يمكننا التوصل لها عند تعظيم الأرجحية <span class=""ltr stick-together"">(likelihood)</span>:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>$\widehat{\phi}$</b></td>
<td align=right><b>$\widehat{\mu_j}\quad{\small(j=0,1)}$</b></td>
<td align=center><b>$\widehat{\Sigma}$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$</td>
<td align=center>$\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$</td>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></h3>
<p><span class=""new-item item-b"">الافتراض</span> يفترض نموذج بايز البسيط أن جميع الخصائص لكل عينة بيانات مستقلة <span class=""ltr stick-together"">(independent)</span>:</p>
<div class=mobile-container>
\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]
</div>
<br>
<p><span class=""new-item item-r"">الحل</span> تعظيم الأرجحية اللوغاريثمية <span class=""ltr stick-together"">(log-likelihood)</span> يعطينا الحلول التالية إذا كان $k\in\{0,1\},l\in[\![1,L]\!]$: $k\in\{0,1\},l\in[\![1,L]\!]$ </p>
<div class=mobile-container>
\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ و }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ و }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]
</div>
<p><span class=remark>ملاحظة: بايز البسيط يستخدم بشكل واسع لتصنيف النصوص واكتشاف البريد الإلكتروني المزعج.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#tree id=tree></a>الطرق الشجرية <span class=""ltr stick-together"">(tree-based)</span> والتجميعية <span class=""ltr stick-together"">(ensemble)</span></h2>
<p>هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار <span class=""ltr stick-together"">(regression)</span> والتصنيف <span class=""ltr stick-together"">(classification)</span>.</p>
<p><span class=""new-item item-b"">التصنيف والانحدار الشجري <span class=""ltr stick-together"">(CART)</span></span> والاسم الشائع له أشجار القرار <span class=""ltr stick-together"">(decision trees)</span>، يمكن أن يمثل كأشجار ثنائية <span class=""ltr stick-together"">(binary trees)</span>. من المزايا لهذه الطريقة إمكانية تفسيرها بسهولة.</p>
<br>
<p><span class=""new-item item-b"">الغابة العشوائية <span class=""ltr stick-together"">(random forest)</span></span> هي أحد الطرق الشجرية التي تستخدم عدداً كبيراً من أشجار القرار مبنية باستخدام مجموعة عشوائية من الخصائص. بخلاف شجرة القرار البسيطة لا يمكن تفسير النموذج بسهولة، ولكن أدائها العالي جعلها أحد الخوارزمية المشهورة.</p>
<p><span class=remark>ملاحظة: أشجار القرار نوع من الخوارزميات التجميعية <span class=""ltr stick-together"">(ensemble)</span>.</span></p>
<br>
<p><span class=""new-item item-b"">التعزيز <span class=""ltr stick-together"">(boosting)</span></span> فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي. الطرق الأساسية ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>التعزيز التَكَيُّفي <span class=""ltr stick-together"">(adaptive boosting)</span></b></td>
<td align=center><b>التعزيز الاشتقاقي <span class=""ltr stick-together"">(gradient boosting)</span></b></td>
</tr>
<tr>
<td align=right>• يتم التركيز على مواطن الخطأ لتحسين النتيجة في الخطوة التالية.</td>
<td align=right>• يتم تدريب خوارزميات التعلم الضعيفة على الأخطاء المتبقية.</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#other id=other></a>طرق أخرى غير بارامترية <span class=""ltr stick-together"">(non-parametric)</span></h2>
<p><span class=""new-item item-b"">خوارزمية أقرب الجيران <span class=""ltr stick-together"">($k$-nearest neighbors)</span></span> تعتبر خوارزمية أقرب الجيران، وتعرف بـ <span class=""ltr stick-together"">$k$-NN</span>، طريقة غير بارامترية، حيث يتم تحديد نتيجة عينة من البيانات من خلال عدد $k$ من البيانات المجاورة في مجموعة التدريب. ويمكن استخدامها للتصنيف والانحدار.</p>
<p><span class=remark>ملاحظة: كلما زاد المُدخل $k$، كلما زاد الانحياز <span class=""ltr stick-together"">(bias)</span>، وكلما نقص $k$، زاد التباين <span class=""ltr stick-together"">(variance)</span>.</span></p>
<div class=mobile-container>
<center>
<img alt=""k nearest neighbors"" class=img-responsive src=teaching/cs-229/illustrations/k-nearest-neighbors.png?02f80a524bb11e2b7a70b58c9ed3b0f4 style=width:100%;max-width:740px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#learning-theory id=learning-theory></a>نظرية التعلُّم</h2>
<p><span class=""new-item item-r"">حد الاتحاد <span class=""ltr stick-together"">(union bound)</span></span> لنجعل $A_1, ..., A_k$ تمثل $k$ حدث. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]
</div>
<center>
<img alt=""Union bound"" class=img-responsive src=teaching/cs-229/illustrations/union-bound.png?aab917859fa8e260e865def69a2889b8 style=width:100%;max-width:700px>
</center>
<br>
<p><span class=""new-item item-r"">متراجحة هوفدينج <span class=""ltr stick-together"">(Hoeffding)</span></span> لنجعل $Z_1, .., Z_m$ تمثل $m$ متغير مستقلة وموزعة بشكل مماثل <span class=""ltr stick-together"">(iid)</span> مأخوذة من توزيع بِرنوللي <span class=""ltr stick-together"">(Bernoulli distribution)</span> ذا مُدخل $\phi$. لنجعل $\widehat{\phi}$ متوسط العينة <span class=""ltr stick-together"">(sample mean)</span> و $\gamma&gt;0$ ثابت. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{P(|\phi-\widehat{\phi}|&gt;\gamma)\leqslant2\exp(-2\gamma^2m)}\]
</div>
<p><span class=remark>ملاحظة: هذه المتراجحة تعرف كذلك بحد تشرنوف <span class=""ltr stick-together"">(Chernoff bound)</span>.</span></p>
<br>
<p><span class=""new-item item-g"">خطأ التدريب</span> ليكن لدينا المُصنِّف $h$، يمكن تعريف خطأ التدريب $\widehat{\epsilon}(h)$، ويعرف كذلك بالخطر التجريبي أو الخطأ التجريبي، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})\neq y^{(i)}\}}}\]
</div>
<br>
<p><span class=""new-item item-g"">تقريباً صحيح احتمالياً <span class=""ltr stick-together"">(Probably Approximately Correct, PAC)</span></span> هو إطار يتم من خلاله إثبات العديد من نظريات التعلم، ويحتوي على الافتراضات التالية:
<br>- مجموعتي التدريب والاختبار يتبعان نفس التوزيع.
<br>- عينات التدريب تؤخذ بشكل مستقل.</p>
<br>
<p><span class=""new-item item-g"">مجموعة تكسيرية <span class=""ltr stick-together"">(shattering set)</span></span> إذا كان لدينا المجموعة $S=\{x^{(1)},...,x^{(d)}\}$، ومجموعة مُصنٍّفات $\mathcal{H}$، نقول أن $\mathcal{H}$ تكسر $S$ <span class=""ltr stick-together"">(H shatters S)</span> إذا كان لكل مجموعة علامات <span class=""ltr stick-together"">(labels)</span> $\{y^{(1)}, ..., y^{(d)}\}$ لدينا:</p>
<div class=mobile-container>
\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]
</div>
<br>
<p><span class=""new-item item-r"">مبرهنة الحد الأعلى <span class=""ltr stick-together"">(upper bound theorem)</span></span> لنجعل $\mathcal{H}$ فئة فرضية محدودة <span class=""ltr stick-together"">(finite hypothesis class)</span> بحيث $|\mathcal{H}|=k$، و $\delta$ وحجم العينة $m$ ثابتين. حينها سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]
</div>
<br>
<p><span class=""new-item item-g"">بُعْد فابنيك</span> تشرفونيكس <span class=""ltr stick-together"">(Vapnik-Chervonenkis, VC)</span> لفئة فرضية غير محدودة <span class=""ltr stick-together"">(infinite hypothesis class)</span> $\mathcal{H}$، ويرمز له بـ $\textrm{VC}(\mathcal{H})$، هو حجم أكبر مجموعة <span class=""ltr stick-together"">(set)</span> التي تم تكسيرها بواسطة $\mathcal{H}$ <span class=""ltr stick-together"">(shattered by $\mathcal{H}$)</span>.</p>
<center>
<img alt=""VC dimension"" class=img-responsive src=teaching/cs-229/illustrations/vc-dimension.png?73859dedcc66a0e47526936f801b7b56>
</center>
<br>
<p><span class=""new-item item-r"">مبرهنة فابنيك <span class=""ltr stick-together"">(Vapnik theorem)</span></span> ليكن لدينا $\mathcal{H}$، مع $\textrm{VC}(\mathcal{H})=d$ وعدد عيّنات التدريب $m$. سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]
</div>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
1,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Supervised Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Introduction to Supervised Learning

Given a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.

Type of prediction The different types of predictive models are summed up in the table below:

Regression Classification Outcome Continuous Class Examples Linear regression Logistic regression, SVM, Naive Bayes

Type of model The different models are summed up in the table below:

Discriminative model Generative model Goal Directly estimate $P(y|x)$ Estimate $P(x|y)$ to then deduce $P(y|x)$ What's learned Decision boundary Probability distributions of the data Illustration Examples Regressions, SVMs GDA, Naive Bayes

Notations and general concepts

Hypothesis The hypothesis is noted $h_\theta$ and is the model that we choose. For a given input data $x^{(i)}$ the model prediction output is $h_\theta(x^{(i)})$.

Loss function A loss function is a function $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ that takes as inputs the predicted value $z$ corresponding to the real data value $y$ and outputs how different they are. The common loss functions are summed up in the table below:

Least squared error Logistic loss Hinge loss Cross-entropy $\displaystyle\frac{1}{2}(y-z)^2$ $\displaystyle\log(1+\exp(-yz))$ $\displaystyle\max(0,1-yz)$ $\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$ Linear regression Logistic regression SVM Neural Network

Cost function The cost function $J$ is commonly used to assess the performance of a model, and is defined with the loss function $L$ as follows:

\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]

Gradient descent By noting $\alpha\in\mathbb{R}$ the learning rate, the update rule for gradient descent is expressed with the learning rate and the cost function $J$ as follows:

\[\boxed{\theta\longleftarrow\theta-\alpha

abla J(\theta)}\]

Remark: Stochastic gradient descent (SGD) is updating the parameter based on each training example, and batch gradient descent is on a batch of training examples.

Likelihood The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization. We have:

\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]

Remark: in practice, we use the log-likelihood $\ell(\theta)=\log(L(\theta))$ which is easier to optimize.

Newton's algorithm Newton's algorithm is a numerical method that finds $\theta$ such that $\ell'(\theta)=0$. Its update rule is as follows:

\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]

Remark: the multidimensional generalization, also known as the Newton-Raphson method, has the following update rule:

\[\theta\leftarrow\theta-\left(

abla_\theta^2\ell(\theta)\right)^{-1}

abla_\theta\ell(\theta)\]

Linear models

Linear regression

We assume here that $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$

Normal equations By noting $X$ the design matrix, the value of $\theta$ that minimizes the cost function is a closed-form solution such that:

\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]

LMS algorithm By noting $\alpha$ the learning rate, the update rule of the Least Mean Squares (LMS) algorithm for a training set of $m$ data points, which is also known as the Widrow-Hoff learning rule, is as follows:

\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]

Remark: the update rule is a particular case of the gradient ascent.

LWR Locally Weighted Regression, also known as LWR, is a variant of linear regression that weights each training example in its cost function by $w^{(i)}(x)$, which is defined with parameter $\tau\in\mathbb{R}$ as:

\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]

Classification and logistic regression

Sigmoid function The sigmoid function $g$, also known as the logistic function, is defined as follows:

\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]

Logistic regression We assume here that $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. We have the following form:

\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]

Remark: logistic regressions do not have closed form solutions.

Softmax regression A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes. By convention, we set $\theta_K=0$, which makes the Bernoulli parameter $\phi_i$ of each class $i$ be such that:

\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]

Generalized Linear Models

Exponential family A class of distributions is said to be in the exponential family if it can be written in terms of a natural parameter, also called the canonical parameter or link function, $\eta$, a sufficient statistic $T(y)$ and a log-partition function $a(\eta)$ as follows:

\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]

Remark: we will often have $T(y)=y$. Also, $\exp(-a(\eta))$ can be seen as a normalization parameter that will make sure that the probabilities sum to one.

The most common exponential distributions are summed up in the following table:

Distribution $\eta$ $T(y)$ $a(\eta)$ $b(y)$ Bernoulli $\log\left(\frac{\phi}{1-\phi}\right)$ $y$ $\log(1+\exp(\eta))$ $1$ Gaussian $\mu$ $y$ $\frac{\eta^2}{2}$ $\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$ Poisson $\log(\lambda)$ $y$ $e^{\eta}$ $\displaystyle\frac{1}{y!}$ Geometric $\log(1-\phi)$ $y$ $\log\left(\frac{e^\eta}{1-e^\eta}\right)$ $1$

Assumptions of GLMs Generalized Linear Models (GLM) aim at predicting a random variable $y$ as a function of $x\in\mathbb{R}^{n+1}$ and rely on the following 3 assumptions:

$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$ $(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$ $(3)\quad\boxed{\eta=\theta^Tx}$

Remark: ordinary least squares and logistic regression are special cases of generalized linear models.

Support Vector Machines

The goal of support vector machines is to find the line that maximizes the minimum distance to the line.

Optimal margin classifier The optimal margin classifier $h$ is such that:

\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]

where $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ is the solution of the following optimization problem:

\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\textrm{such that }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]

Remark: the decision boundary is defined as $\boxed{w^Tx-b=0}$.

Hinge loss The hinge loss is used in the setting of SVMs and is defined as follows:

\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]

Kernel Given a feature mapping $\phi$, we define the kernel $K$ as follows:

\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]

In practice, the kernel $K$ defined by $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$ is called the Gaussian kernel and is commonly used.

Remark: we say that we use the ""kernel trick"" to compute the cost function using the kernel because we actually don't need to know the explicit mapping $\phi$, which is often very complicated. Instead, only the values $K(x,z)$ are needed.

Lagrangian We define the Lagrangian $\mathcal{L}(w,b)$ as follows:

\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]

Remark: the coefficients $\beta_i$ are called the Lagrange multipliers.

Generative Learning

A generative model first tries to learn how the data is generated by estimating $P(x|y)$, which we can then use to estimate $P(y|x)$ by using Bayes' rule.

Gaussian Discriminant Analysis

Setting The Gaussian Discriminant Analysis assumes that $y$ and $x|y=0$ and $x|y=1$ are such that:

$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$ $(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$ $(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$

Estimation The following table sums up the estimates that we find when maximizing the likelihood:

$\widehat{\phi}$ $\widehat{\mu_j}\quad{\small(j=0,1)}$ $\widehat{\Sigma}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$ $\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$

Naive Bayes

Assumption The Naive Bayes model supposes that the features of each data point are all independent:

\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]

Solutions Maximizing the log-likelihood gives the following solutions:

\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ and }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ and }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]

Remark: Naive Bayes is widely used for text classification and spam detection.

Tree-based and ensemble methods

These methods can be used for both regression and classification problems.

CART Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable.

Random forest It is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm.

Remark: random forests are a type of ensemble methods.

Boosting The idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below:

Adaptive boosting Gradient boosting • High weights are put on errors to improve at the next boosting step

• Known as Adaboost • Weak learners are trained on residuals

• Examples include XGBoost

Other non-parametric approaches

$k$-nearest neighbors The $k$-nearest neighbors algorithm, commonly known as $k$-NN, is a non-parametric approach where the response of a data point is determined by the nature of its $k$ neighbors from the training set. It can be used in both classification and regression settings.

Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.

Learning Theory

Union bound Let $A_1, ..., A_k$ be $k$ events. We have:

\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]

Hoeffding inequality Let $Z_1, .., Z_m$ be $m$ iid variables drawn from a Bernoulli distribution of parameter $\phi$. Let $\widehat{\phi}$ be their sample mean and $\gamma>0$ fixed. We have:

\[\boxed{P(|\phi-\widehat{\phi}|>\gamma)\leqslant2\exp(-2\gamma^2m)}\]

Remark: this inequality is also known as the Chernoff bound.

Training error For a given classifier $h$, we define the training error $\widehat{\epsilon}(h)$, also known as the empirical risk or empirical error, to be as follows:

\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})

eq y^{(i)}\}}}\]

Probably Approximately Correct (PAC) PAC is a framework under which numerous results on learning theory were proved, and has the following set of assumptions:

the training and testing sets follow the same distribution

the training examples are drawn independently

Shattering Given a set $S=\{x^{(1)},...,x^{(d)}\}$, and a set of classifiers $\mathcal{H}$, we say that $\mathcal{H}$ shatters $S$ if for any set of labels $\{y^{(1)}, ..., y^{(d)}\}$, we have:

\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]

Upper bound theorem Let $\mathcal{H}$ be a finite hypothesis class such that $|\mathcal{H}|=k$ and let $\delta$ and the sample size $m$ be fixed. Then, with probability of at least $1-\delta$, we have:

\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]

VC dimension The Vapnik-Chervonenkis (VC) dimension of a given infinite hypothesis class $\mathcal{H}$, noted $\textrm{VC}(\mathcal{H})$ is the size of the largest set that is shattered by $\mathcal{H}$.

Remark: the VC dimension of ${\small\mathcal{H}=\{\textrm{set of linear classifiers in 2 dimensions}\}}$ is 3.

Theorem (Vapnik) Let $\mathcal{H}$ be given, with $\textrm{VC}(\mathcal{H})=d$ and $m$ the number of training examples. With probability at least $1-\delta$, we have:

\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]","Would you like to see this cheatsheet in your native language?
CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksSupervised Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiIntroduction to Supervised LearningGiven a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.
Likelihood The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization.
Softmax regression A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes.
Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.","['supervised', 'set', 'function', 'model', 'logistic', 'training', 'learning', 'cheatsheet', 'parameter', 'y', 'known', 'regression']",en,Supervised Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Supervised Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Supervised Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>Introduction</a></div> <div class=dropdown-container> <a href=#introduction><span>Type of prediction</span></a> <a href=#introduction><span>Type of model</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#notations>Notations and general concepts</a></div> <div class=dropdown-container> <a href=#notations><span>Loss function</span></a> <a href=#notations><span>Gradient descent</span></a> <a href=#notations><span>Likelihood</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#linear-models>Linear models</a></div> <div class=dropdown-container> <a href=#linear-models><span>Linear regression</span></a> <a href=#linear-models><span>Logisitic regression</span></a> <a href=#linear-models><span>Generalized linear models</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#svm>Support Vector Machines</a></div> <div class=dropdown-container> <a href=#svm><span>Optimal margin classifier</span></a> <a href=#svm><span>Hinge loss</span></a> <a href=#svm><span>Kernel</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#generative-learning>Generative learning</a></div> <div class=dropdown-container> <a href=#generative-learning><span>Gaussian Discriminant Analysis</span></a> <a href=#generative-learning><span>Naive Bayes</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#tree>Trees and ensemble methods</a></div> <div class=dropdown-container> <a href=#tree><span>CART</span></a> <a href=#tree><span>Random forest</span></a> <a href=#tree><span>Boosting</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#other>Other methods</a></div> <div class=dropdown-container> <a href=#other><span>k-NN</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#learning-theory>Learning Theory</a></div> <div class=dropdown-container> <a href=#learning-theory><span>Hoeffding inequality</span></a> <a href=#learning-theory><span>PAC</span></a> <a href=#learning-theory><span>VC dimension</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button><b>Supervised Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Supervised Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>Introduction to Supervised Learning</h2>
<p>Given a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.</p>
<p><span class=""new-item item-b"">Type of prediction</span> The different types of predictive models are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b></b></td>
<td align=center><b>Regression</b></td>
<td align=center><b>Classification</b></td>
</tr>
<tr>
<td align=center><b>Outcome</b></td>
<td align=center>Continuous</td>
<td align=center>Class</td>
</tr>
<tr>
<td align=center><b>Examples</b></td>
<td align=center>Linear regression</td>
<td align=center>Logistic regression, SVM, Naive Bayes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Type of model</span> The different models are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:300px;"">
  <colgroup>
    <col style=width:120px>
    <col style=width:50%>
    <col style=width:50%>
  </colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>Discriminative model</b></td>
<td align=center><b>Generative model</b></td>
</tr>
<tr>
<td align=center><b>Goal</b></td>
<td align=left>Directly estimate $P(y|x)$</td>
<td align=left>Estimate $P(x|y)$ to then deduce $P(y|x)$</td>
</tr>
<tr>
<td align=center><b>What's learned</b></td>
<td align=left>Decision boundary</td>
<td align=left>Probability distributions of the data</td>
</tr>
<tr>
<td align=center><b>Illustration</b></td>
<td align=center style=""width: 41%;""><img alt=""Discriminative model"" class=img-responsive src=teaching/cs-229/illustrations/discriminative-model.png?767b34c21d43a4fd8b59683578e132f9></td>
<td align=center style=""width: 41%;""><img alt=""Generative model"" class=img-responsive src=teaching/cs-229/illustrations/generative-model.png?df0642cec6e99ac162cd4848d26f41c3></td>
</tr>
<tr>
<td align=center><b>Examples</b></td>
<td align=left>Regressions, SVMs</td>
<td align=left>GDA, Naive Bayes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>Notations and general concepts</h2>
<p><span class=""new-item item-b"">Hypothesis</span> The hypothesis is noted $h_\theta$ and is the model that we choose. For a given input data $x^{(i)}$ the model prediction output is $h_\theta(x^{(i)})$.</p>
<br>
<p><span class=""new-item item-r"">Loss function</span> A loss function is a function $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ that takes as inputs the predicted value $z$ corresponding to the real data value $y$ and outputs how different they are. The common loss functions are summed up in the table below:</p>
<div class=mobile-container>
<center>
  <table style=""table-layout:fixed; width:100%; min-width:820px;"">
    <colgroup>
      <col style=width:25%>
      <col style=width:25%>
      <col style=width:25%>
      <col style=width:25%>
    </colgroup>
<tbody>
<tr>
<td align=center><b>Least squared error</b></td>
<td align=center><b>Logistic loss</b></td>
<td align=center><b>Hinge loss</b></td>
<td align=center><b>Cross-entropy</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{2}(y-z)^2$</td>
<td align=center>$\displaystyle\log(1+\exp(-yz))$</td>
<td align=center>$\displaystyle\max(0,1-yz)$</td>
<td align=center style=vertical-align:middle><div id=some_math style=font-size:75%>$\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$</div></td>
</tr>
<tr>
<td align=center style=""width: 25%;""><img alt=""Least squared error"" class=img-responsive src=teaching/cs-229/illustrations/least-square-error.png?63fef2552284b0dc15f27d1ef0b79fea></td>
<td align=center style=""width: 25%;""><img alt=""Logistic loss"" class=img-responsive src=teaching/cs-229/illustrations/logistic-loss.png?1bc1cb6d682c1bbfb978ec894afdf588></td>
<td align=center style=""width: 25%;""><img alt=""Hinge loss"" class=img-responsive src=teaching/cs-229/illustrations/hinge-loss.png?3f1b26410c446f52885dcc5266937c84></td>
<td align=center style=""width: 25%;""><img alt=""Cross entropy"" class=img-responsive src=teaching/cs-229/illustrations/cross-entropy.png?037ea4073873c9be4a7de099dac6d3b5></td>
</tr>
<tr>
<td align=center>Linear regression</td>
<td align=center>Logistic regression</td>
<td align=center>SVM</td>
<td align=center>Neural Network</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Cost function</span> The cost function $J$ is commonly used to assess the performance of a model, and is defined with the loss function $L$ as follows:</p>
<div class=mobile-container>
\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]
</div>
<br>
<p><span class=""new-item item-r"">Gradient descent</span> By noting $\alpha\in\mathbb{R}$ the learning rate, the update rule for gradient descent is expressed with the learning rate and the cost function $J$ as follows:</p>
<div class=mobile-container>
\[\boxed{\theta\longleftarrow\theta-\alpha\nabla J(\theta)}\]
</div>
<br>
<center>
  <img alt=""Gradient descent"" class=img-responsive src=teaching/cs-229/illustrations/gradient-descent.png?01662c4a8147a55ba09f4f5c047641ba style=width:100%;max-width:500px>
</center>
<br>
<p><span class=remark>Remark: Stochastic gradient descent (SGD) is updating the parameter based on each training example, and batch gradient descent is on a batch of training examples.</span></p>
<br>
<p><span class=""new-item item-b"">Likelihood</span> The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization. We have:</p>
<div class=mobile-container>
\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]
</div>
<p><span class=remark>Remark: in practice, we use the log-likelihood $\ell(\theta)=\log(L(\theta))$ which is easier to optimize.</span></p>
<br>
<p><span class=""new-item item-r"">Newton's algorithm</span> Newton's algorithm is a numerical method that finds $\theta$ such that $\ell'(\theta)=0$. Its update rule is as follows:</p>
<div class=mobile-container>
\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]
</div>
<p><span class=remark>Remark: the multidimensional generalization, also known as the Newton-Raphson method, has the following update rule:</span></p>
<div class=mobile-container>
\[\theta\leftarrow\theta-\left(\nabla_\theta^2\ell(\theta)\right)^{-1}\nabla_\theta\ell(\theta)\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#linear-models id=linear-models></a>Linear models</h2>
<h3>Linear regression</h3>
<p>We assume here that $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$</p>
<p><span class=""new-item item-g"">Normal equations</span> By noting $X$ the design matrix, the value of $\theta$ that minimizes the cost function is a closed-form solution such that:</p>
<div class=mobile-container>
\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]
</div>
<br>
<p><span class=""new-item item-g"">LMS algorithm</span> By noting $\alpha$ the learning rate, the update rule of the Least Mean Squares (LMS) algorithm for a training set of $m$ data points, which is also known as the Widrow-Hoff learning rule, is as follows:</p>
<div class=mobile-container>
\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]
</div>
<p><span class=remark>Remark: the update rule is a particular case of the gradient ascent.</span></p>
<br>
<p><span class=""new-item item-b"">LWR</span> Locally Weighted Regression, also known as LWR, is a variant of linear regression that weights each training example in its cost function by $w^{(i)}(x)$, which is defined with parameter $\tau\in\mathbb{R}$ as:</p>
<div class=mobile-container>
\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]
</div>
<br>
<h3>Classification and logistic regression</h3>
<p><span class=""new-item item-b"">Sigmoid function</span> The sigmoid function $g$, also known as the logistic function, is defined as follows:</p>
<div class=mobile-container>
\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]
</div>
<br>
<p><span class=""new-item item-b"">Logistic regression</span> We assume here that $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. We have the following form:</p>
<div class=mobile-container>
\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]
</div>
<p><span class=remark>Remark: logistic regressions do not have closed form solutions.</span></p>
<br>
<p><span class=""new-item item-b"">Softmax regression</span> A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes. By convention, we set $\theta_K=0$, which makes the Bernoulli parameter $\phi_i$ of each class $i$ be such that:</p>
<div class=mobile-container>
\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]
</div>
<br>
<h3>Generalized Linear Models</h3>
<p><span class=""new-item item-r"">Exponential family</span> A class of distributions is said to be in the exponential family if it can be written in terms of a natural parameter, also called the canonical parameter or link function, $\eta$, a sufficient statistic $T(y)$ and a log-partition function $a(\eta)$ as follows:</p>
<div class=mobile-container>
\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]
</div>
<p><span class=remark>Remark: we will often have $T(y)=y$. Also, $\exp(-a(\eta))$ can be seen as a normalization parameter that will make sure that the probabilities sum to one.</span></p>
<p>The most common exponential distributions are summed up in the following table:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Distribution</b></td>
<td align=center><b>$\eta$</b></td>
<td align=center><b>$T(y)$</b></td>
<td align=center><b>$a(\eta)$</b></td>
<td align=center><b>$b(y)$</b></td>
</tr>
<tr>
<td align=center>Bernoulli</td>
<td align=center>$\log\left(\frac{\phi}{1-\phi}\right)$</td>
<td align=center>$y$</td>
<td align=center>$\log(1+\exp(\eta))$</td>
<td align=center>$1$</td>
</tr>
<tr>
<td align=center>Gaussian</td>
<td align=center>$\mu$</td>
<td align=center>$y$</td>
<td align=center>$\frac{\eta^2}{2}$</td>
<td align=center>$\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$</td>
</tr>
<tr>
<td align=center>Poisson</td>
<td align=center>$\log(\lambda)$</td>
<td align=center>$y$</td>
<td align=center>$e^{\eta}$</td>
<td align=center>$\displaystyle\frac{1}{y!}$</td>
</tr>
<tr>
<td align=center>Geometric</td>
<td align=center>$\log(1-\phi)$</td>
<td align=center>$y$</td>
<td align=center>$\log\left(\frac{e^\eta}{1-e^\eta}\right)$</td>
<td align=center>$1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Assumptions of GLMs</span> Generalized Linear Models (GLM) aim at predicting a random variable $y$ as a function of $x\in\mathbb{R}^{n+1}$ and rely on the following 3 assumptions:</p>
<div class=row>
 <div class=col-sm-4>$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$</div>
 <div class=col-sm-4>$(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$</div>
 <div class=col-sm-4>$(3)\quad\boxed{\eta=\theta^Tx}$</div>
</div>
<br>
<p><span class=remark>Remark: ordinary least squares and logistic regression are special cases of generalized linear models.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#svm id=svm></a>Support Vector Machines</h2>
<p>The goal of support vector machines is to find the line that maximizes the minimum distance to the line.</p>
<p><span class=""new-item item-b"">Optimal margin classifier</span> The optimal margin classifier $h$ is such that:</p>
<div class=mobile-container>
\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]
</div>
<p>where $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ is the solution of the following optimization problem:</p>
<div class=mobile-container>
\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\textrm{such that }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]
</div>
<center>
  <img alt=SVM class=img-responsive src=teaching/cs-229/illustrations/svm-en.png?d23456fe589935f26cf32c1664c90851 style=width:100%;max-width:600px>
</center>
<p><span class=remark>Remark: the decision boundary is defined as $\boxed{w^Tx-b=0}$.</span></p>
<br>
<p><span class=""new-item item-b"">Hinge loss</span> The hinge loss is used in the setting of SVMs and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]
</div>
<br>
<p><span class=""new-item item-b"">Kernel</span> Given a feature mapping $\phi$, we define the kernel $K$ as follows:</p>
<div class=mobile-container>
\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]
</div>
<p>In practice, the kernel $K$ defined by $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$ is called the Gaussian kernel and is commonly used.</p>
<center>
  <img alt=""SVM kernel"" class=img-responsive src=teaching/cs-229/illustrations/svm-kernel-en.png?43f2af419ba926948a5bbf3289f2cf39>
</center>
<br>
<p><span class=remark>Remark: we say that we use the ""kernel trick"" to compute the cost function using the kernel because we actually don't need to know the explicit mapping $\phi$, which is often very complicated. Instead, only the values $K(x,z)$ are needed.</span></p>
<br>
<p><span class=""new-item item-r"">Lagrangian</span> We define the Lagrangian $\mathcal{L}(w,b)$ as follows:</p>
<div class=mobile-container>
\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]
</div>
<p><span class=remark>Remark: the coefficients $\beta_i$ are called the Lagrange multipliers.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#generative-learning id=generative-learning></a>Generative Learning</h2>
<p>A generative model first tries to learn how the data is generated by estimating $P(x|y)$, which we can then use to estimate $P(y|x)$ by using Bayes' rule.</p>
<h3>Gaussian Discriminant Analysis</h3>
<p><span class=""new-item item-b"">Setting</span> The Gaussian Discriminant Analysis assumes that $y$ and $x|y=0$ and $x|y=1$ are such that:</p>
<div class=row>
 <div class=col-sm-4>$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$</div>
 <div class=col-sm-4>$(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$</div>
 <div class=col-sm-4>$(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$</div>
</div>
<br>
<p><span class=""new-item item-b"">Estimation</span> The following table sums up the estimates that we find when maximizing the likelihood:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>$\widehat{\phi}$</b></td>
<td align=right><b>$\widehat{\mu_j}\quad{\small(j=0,1)}$</b></td>
<td align=center><b>$\widehat{\Sigma}$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$</td>
<td align=center>$\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$</td>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Naive Bayes</h3>
<p><span class=""new-item item-b"">Assumption</span> The Naive Bayes model supposes that the features of each data point are all independent:</p>
<div class=mobile-container>
\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]
</div>
<br>
<p><span class=""new-item item-r"">Solutions</span> Maximizing the log-likelihood gives the following solutions:
</p><div class=mobile-container>
\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ and }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ and }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]
</div>
with $k\in\{0,1\}$ and $l\in[\![1,L]\!]$<p></p>
<p><span class=remark>Remark: Naive Bayes is widely used for text classification and spam detection.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#tree id=tree></a>Tree-based and ensemble methods</h2>
<p>These methods can be used for both regression and classification problems.</p>
<p><span class=""new-item item-b"">CART</span> Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable.</p>
<br>
<p><span class=""new-item item-b"">Random forest</span> It is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm.</p>
<p><span class=remark>Remark: random forests are a type of ensemble methods.</span></p>
<br>
<p><span class=""new-item item-b"">Boosting</span> The idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Adaptive boosting</b></td>
<td align=center><b>Gradient boosting</b></td>
</tr>
<tr>
<td align=left>• High weights are put on errors to improve at the next boosting step<br>
• Known as Adaboost</td>
<td align=left>• Weak learners are trained on residuals<br>
• Examples include XGBoost</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#other id=other></a>Other non-parametric approaches</h2>
<p><span class=""new-item item-b"">$k$-nearest neighbors</span> The $k$-nearest neighbors algorithm, commonly known as $k$-NN, is a non-parametric approach where the response of a data point is determined by the nature of its $k$ neighbors from the training set. It can be used in both classification and regression settings.</p>
<p><span class=remark>Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.</span></p>
<div class=mobile-container>
<center>
  <img alt=""k nearest neighbors"" class=img-responsive src=teaching/cs-229/illustrations/k-nearest-neighbors.png?02f80a524bb11e2b7a70b58c9ed3b0f4 style=width:100%;max-width:740px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#learning-theory id=learning-theory></a>Learning Theory</h2>
<p><span class=""new-item item-r"">Union bound</span> Let $A_1, ..., A_k$ be $k$ events. We have:</p>
<div class=mobile-container>
\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]
</div>
<center>
<img alt=""Union bound"" class=img-responsive src=teaching/cs-229/illustrations/union-bound.png?aab917859fa8e260e865def69a2889b8 style=width:100%;max-width:700px>
</center>
<br>
<p><span class=""new-item item-r"">Hoeffding inequality</span> Let $Z_1, .., Z_m$ be $m$ iid variables drawn from a Bernoulli distribution of parameter $\phi$. Let $\widehat{\phi}$ be their sample mean and $\gamma&gt;0$ fixed. We have:</p>
<div class=mobile-container>
\[\boxed{P(|\phi-\widehat{\phi}|&gt;\gamma)\leqslant2\exp(-2\gamma^2m)}\]
</div>
<p><span class=remark>Remark: this inequality is also known as the Chernoff bound.</span></p>
<br>
<p><span class=""new-item item-g"">Training error</span> For a given classifier $h$, we define the training error $\widehat{\epsilon}(h)$, also known as the empirical risk or empirical error, to be as follows:</p>
<div class=mobile-container>
\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})\neq y^{(i)}\}}}\]
</div>
<br>
<p><span class=""new-item item-g"">Probably Approximately Correct (PAC)</span> PAC is a framework under which numerous results on learning theory were proved, and has the following set of assumptions:</p>
<ul>
	<li>the training and testing sets follow the same distribution</li>
	<li>the training examples are drawn independently</li>
</ul>
<br>
<p><span class=""new-item item-g"">Shattering</span> Given a set $S=\{x^{(1)},...,x^{(d)}\}$, and a set of classifiers $\mathcal{H}$, we say that $\mathcal{H}$ shatters $S$ if for any set of labels $\{y^{(1)}, ..., y^{(d)}\}$, we have:</p>
<div class=mobile-container>
\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]
</div>
<br>
<p><span class=""new-item item-r"">Upper bound theorem</span> Let $\mathcal{H}$ be a finite hypothesis class such that $|\mathcal{H}|=k$ and let $\delta$ and the sample size $m$ be fixed. Then, with probability of at least $1-\delta$, we have:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]
</div>
<br>
<p><span class=""new-item item-g"">VC dimension</span> The Vapnik-Chervonenkis (VC) dimension of a given infinite hypothesis class $\mathcal{H}$, noted $\textrm{VC}(\mathcal{H})$ is the size of the largest set that is shattered by $\mathcal{H}$.</p>
<p><span class=remark>Remark: the VC dimension of ${\small\mathcal{H}=\{\textrm{set of linear classifiers in 2 dimensions}\}}$ is 3.</span></p>
<center>
  <img alt=""VC dimension"" class=img-responsive src=teaching/cs-229/illustrations/vc-dimension.png?73859dedcc66a0e47526936f801b7b56>
</center>
<br>
<p><span class=""new-item item-r"">Theorem (Vapnik)</span> Let $\mathcal{H}$ be given, with $\textrm{VC}(\mathcal{H})=d$ and $m$ the number of training examples. With probability at least $1-\delta$, we have:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
2,"مرجع سريع للتعلّم غير المُوَجَّه

مقدمة للتعلّم غير المُوَجَّه

الحافز الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.

متباينة جينسن لتكن $f$ دالة محدبة و $X$ متغير عشوائي. لدينا المتباينة التالية:

\[\boxed{E[f(X)]\geqslant f(E[X])}\]

التجميع

تعظيم القيمة المتوقعة (Expectation-Maximization)

المتغيرات الكامنة المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$. في مايلي الإعدادات الشائعة التي تحتوي على متغيرات كامنة:

الإعداد المتغير الكامن $z$ $x|z$ ملاحظات خليط من $k$ توزيع جاوسي $\textrm{Multinomial}(\phi)$ $\mathcal{N}(\mu_j,\Sigma_j)$ $\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$ تحليل عاملي $\mathcal{N}(0,I)$ $\mathcal{N}(\mu+\Lambda z,\psi)$ $\mu_j\in\mathbb{R}^n$

خوارزمية تعظيم القيمة المتوقعة (Expectation-Maximization) هي عبارة عن طريقة فعالة لتقدير المُدخل $\theta$ عبر تقدير تقدير الأرجحية الأعلى (maximum likelihood estimation)، ويتم ذلك بشكل تكراري حيث يتم إيجاد حد أدنى للأرجحية (الخطوة M)، ثم يتم تحسين (optimizing) ذلك الحد الأدنى (الخطوة E)، كما يلي:

- الخطوة E : حساب الاحتمال البعدي $Q_{i}(z^{(i)})$ بأن تصدر كل نقطة $x^{(i)}$ من مجموعة (cluster) $z^{(i)}$ كما يلي:

\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]

- الخطوة M : يتم استعمال الاحتمالات البعدية $Q_i(z^{(i)})$ كأوزان خاصة لكل مجموعة (cluster) على النقط $x^{(i)}$، لكي يتم تقدير نموذج لكل مجموعة بشكل منفصل، و ذلك كما يلي:

\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]

التجميع بالمتوسطات $k$ (k means clustering)

نرمز لمجموعة النقط $i$ بـ $c^{(i)}$، ونرمز بـ $\mu_j$ مركز المجموعات $j$.

خوارزمية بعد الاستهلال العشوائي للنقاط المركزية (centroids) للمجوعات $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$، التجميع بالمتوسطات $k$ تكرر الخطوة التالية حتى التقارب:

\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{و}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]

دالة التحريف (distortion function) لكي نتأكد من أن الخوارزمية تقاربت، ننظر إلى دالة التحريف المعرفة كما يلي:

\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]

التجميع الهرمي

خوارزمية هي عبارة عن خوارزمية تجميع تعتمد على طريقة تجميع هرمية تبني مجموعات متداخلة بشكل متتال.

الأنواع هنالك عدة أنواع من خوارزميات التجميع الهرمي التي ترمي إلى تحسين دوال هدف (objective function) مختلفة، هذه الأنواع ملخصة في الجدول التالي:

ربط وارْد (ward linkage) الربط المتوسط الربط الكامل تصغير المسافة داخل المجموعة تصغير متوسط المسافة بين أزواج المجموعات تصغير المسافة العظمى بين أزواج المجموعات

مقاييس تقدير المجموعات

في التعلّم غير المُوَجَّه من الصعب غالباً تقدير أداء نموذج ما، لأن القيم الحقيقية تكون غير متوفرة كما هو الحال في التعلًم المُوَجَّه.

معامل الظّل (silhouette coefficient) إذا رمزنا $a$ و $b$ لمتوسط المسافة بين عينة وكل النقط المنتمية لنفس الصنف، و بين عينة وكل النقط المنتمية لأقرب مجموعة، المعامل الظِلِّي $s$ لعينة واحدة معرف كالتالي:

\[\boxed{s=\frac{b-a}{\max(a,b)}}\]

مؤشر كالينسكي-هارباز (Calinski-Harabaz index) إذا رمزنا بـ $k$ لعدد المجموعات، فإن $B_k$ و $W_k$ مصفوفتي التشتت بين المجموعات وداخلها تعرف كالتالي:

\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]

مؤشر كالينسكي-هارباز $s(k)$ يشير إلى جودة نموذج تجميعي في تعريف مجموعاته، بحيث كلما كانت النتيجة أعلى كلما دل ذلك على أن المجموعات أكثر كثافة وأكثر انفصالاً فيما بينها. هذا المؤشر معرّف كالتالي:

\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]

تقليص الأبعاد

تحليل المكون الرئيس

إنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.

قيمة ذاتية (eigenvalue)، متجه ذاتي (eigenvector) لتكن $A\in\mathbb{R}^{n\times n}$ مصفوفة، نقول أن $\lambda$ قيمة ذاتية للمصفوفة $A$ إذا وُجِد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجهاً ذاتياً، بحيث:

\[\boxed{Az=\lambda z}\]

مبرهنة الطّيف (spectral theorem) لتكن $A\in\mathbb{R}^{n\times n}$. إذا كانت $A$ متناظرة فإنها يمكن أن تكون شبه قطرية عن طريق مصفوفة متعامدة حقيقية $U\in\mathbb{R}^{n\times n}$. إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:

\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]

ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي (principal eigenvector) للمصفوفة $A$.

خوارزمية تحليل المكون الرئيس (Principal Component Analysis, PCA) طريقة لخفض الأبعاد تهدف إلى إسقاط البيانات على $k$ بُعد بحيث يتم تعطيم التباين (variance)، خطواتها كالتالي:

- الخطوة 1 : تسوية البيانات بحيث تصبح ذات متوسط يساوي صفر وانحراف معياري يساوي واحد.

\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{و}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]

- الخطوة 2 : حساب $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$، وهي متناظرة وذات قيم ذاتية حقيقية.

- الخطوة 3 : حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.

- الخطوة 4 : إسقاط البيانات على $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.

هذا الإجراء يعظم التباين بين كل الفضاءات البُعدية.

تحليل المكونات المستقلة

هي طريقة تهدف إلى إيجاد المصادر التوليدية الكامنة.

افتراضات لنفترض أن بياناتنا $x$ تم توليدها عن طريق المتجه المصدر $s=(s_1,...,s_n)$ ذا $n$ بُعد، حيث $s_i$ متغيرات عشوائية مستقلة، وذلك عبر مصفوفة خلط غير منفردة (mixing and non-singular) $A$ كالتالي:

\[\boxed{x=As}\]

الهدف هو العثور على مصفوفة الفصل $W=A^{-1}$.

خوارزمية تحليل المكونات المستقلة (ICA) لبيل وسجنوسكي (Bell and Sejnowski) هذه الخوارزمية تجد مصفوفة الفصل $W$ عن طريق الخطوات التالية:

- اكتب الاحتمال لـ $x=As=W^{-1}s$ كالتالي:

\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]

- لتكن $\{x^{(i)}, i\in[\![1,m]\!]\}$ بيانات التمرن و $g$ دالة سيجمويد، اكتب الأرجحية اللوغاريتمية (log likelihood) كالتالي:

\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]

هكذا، باستخدام الصعود الاشتقاقي العشوائي (stochastic gradient ascent)، لكل عينة تدريب $x^{(i)}$ نقوم بتحديث $W$ كما يلي:

\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]","مرجع سريع للتعلّم غير المُوَجَّهمقدمة للتعلّم غير المُوَجَّهالحافز الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.
لدينا المتباينة التالية:\[\boxed{E[f(X)]\geqslant f(E[X])}\]التجميعتعظيم القيمة المتوقعة (Expectation-Maximization)المتغيرات الكامنة المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$.
هذا المؤشر معرّف كالتالي:\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]تقليص الأبعادتحليل المكون الرئيسإنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.
إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي (principal eigenvector) للمصفوفة $A$.
- الخطوة 3 : حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.","['إلى', 'المجموعات', 'الخطوة', 'تقدير', 'البيانات', 'إذا', 'مصفوفة', 'يتم', 'تعلم', 'k', 'طريقة', 'موجه']",ar,تعلم غير موجَّه,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>تعلم غير موجَّه - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-unsupervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلم غير موجَّه</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#intro>مقدمة</a></div> <div class=dropdown-container> <a href=#intro><span>الحافز</span></a> <a href=#intro><span>متباينة جينسن</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#clustering>التجميع</a></div> <div class=dropdown-container> <a href=#clustering><span>تعظيم القيمة المتوقعة</span></a> <a href=#clustering><span>تجميع <span class=ltr>k</span>-متوسطات</span></a> <a href=#clustering><span>التجميع الهرمي</span></a> <a href=#clustering><span>مقاييس</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#dimension-reduction>تقليص الأبعاد</a></div> <div class=dropdown-container> <a href=#dimension-reduction><span>تحليل المكون الرئيس <span class=ltr>(PCA)</span></span></a> <a href=#dimension-reduction><span>تحليل المكونات المستقلة <span class=ltr>(ICA)</span></span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-unsupervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button><b>تعلم غير موجَّه</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع للتعلّم غير المُوَجَّه</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة رضوان لغوينسات. تمت المراجعة بواسطة فارس القنيعير.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#intro id=intro></a>مقدمة للتعلّم غير المُوَجَّه</h2>
<p><span class=""new-item item-b"">الحافز</span> الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.</p>
<br>
<p><span class=""new-item item-r"">متباينة جينسن</span> لتكن $f$ دالة محدبة و $X$ متغير عشوائي. لدينا المتباينة التالية:</p>
<div class=mobile-container>
\[\boxed{E[f(X)]\geqslant f(E[X])}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#clustering id=clustering></a>التجميع</h2>
<h3>تعظيم القيمة المتوقعة <span class=""ltr stick-together"">(Expectation-Maximization)</span></h3>
<p><span class=""new-item item-r"">المتغيرات الكامنة</span> المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$. في مايلي الإعدادات الشائعة التي تحتوي على متغيرات كامنة:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>الإعداد</b></td>
<td align=center><b>المتغير الكامن $z$</b></td>
<td align=center>$x|z$</td>
<td align=center><b>ملاحظات</b></td>
</tr>
<tr>
<td align=center>خليط من $k$ توزيع جاوسي</td>
<td align=center>$\textrm{Multinomial}(\phi)$</td>
<td align=center>$\mathcal{N}(\mu_j,\Sigma_j)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$</td>
</tr>
<tr>
<td align=center>تحليل عاملي</td>
<td align=center>$\mathcal{N}(0,I)$</td>
<td align=center>$\mathcal{N}(\mu+\Lambda z,\psi)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> تعظيم القيمة المتوقعة <span class=""ltr stick-together"">(Expectation-Maximization)</span> هي عبارة عن طريقة فعالة لتقدير المُدخل $\theta$ عبر تقدير تقدير الأرجحية الأعلى <span class=""ltr stick-together"">(maximum likelihood estimation)</span>، ويتم ذلك بشكل تكراري حيث يتم إيجاد حد أدنى للأرجحية (الخطوة <span class=""ltr stick-together"">M</span>)، ثم يتم تحسين <span class=""ltr stick-together"">(optimizing)</span> ذلك الحد الأدنى (الخطوة <span class=""ltr stick-together"">E</span>)، كما يلي:</p>
<br><p>- <u>الخطوة <span class=""ltr stick-together"">E</span> </u>: حساب الاحتمال البعدي $Q_{i}(z^{(i)})$ بأن تصدر كل نقطة $x^{(i)}$ من مجموعة <span class=""ltr stick-together"">(cluster)</span> $z^{(i)}$ كما يلي:</p>
<div class=mobile-container>
\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]
</div>
<p>- <u>  الخطوة <span class=""ltr stick-together"">M</span> </u>: يتم استعمال الاحتمالات البعدية $Q_i(z^{(i)})$ كأوزان خاصة لكل مجموعة <span class=""ltr stick-together"">(cluster)</span> على النقط $x^{(i)}$، لكي يتم تقدير نموذج لكل مجموعة بشكل منفصل، و ذلك كما يلي:</p>
<div class=mobile-container>
\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/expectation-maximization-ar.png?648fa970fe475c6ad81fba10453d562a>
</center>
<br>
<h3>التجميع بالمتوسطات $k$ <span class=""ltr stick-together"">(k means clustering)</span></h3>
<p>نرمز لمجموعة النقط $i$ بـ $c^{(i)}$، ونرمز بـ $\mu_j$ مركز المجموعات $j$.</p>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> بعد الاستهلال العشوائي للنقاط المركزية <span class=""ltr stick-together"">(centroids)</span> للمجوعات $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$، التجميع بالمتوسطات $k$ تكرر الخطوة التالية حتى التقارب:</p>
<div class=mobile-container>
\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{و}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/k-means-ar.png?3dfcdd31f92a900fef44fb3d507c1f39>
</center>
<br>
<p><span class=""new-item item-b"">دالة التحريف <span class=""ltr stick-together"">(distortion function)</span></span> لكي نتأكد من أن الخوارزمية تقاربت، ننظر إلى دالة التحريف المعرفة كما يلي:</p>
<div class=mobile-container>
\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]
</div>
<br>
<h3>التجميع الهرمي</h3>
<p><span class=""new-item item-g"">خوارزمية</span> هي عبارة عن خوارزمية تجميع تعتمد على طريقة تجميع هرمية تبني مجموعات متداخلة بشكل متتال.</p>
<br>
<p><span class=""new-item item-b"">الأنواع</span> هنالك عدة أنواع من خوارزميات التجميع الهرمي التي ترمي إلى تحسين دوال هدف <span class=""ltr stick-together"">(objective function)</span> مختلفة، هذه الأنواع ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>ربط وارْد <span class=""ltr stick-together"">(ward linkage)</span></b></td>
<td align=center><b>الربط المتوسط</b></td>
<td align=center><b>الربط الكامل</b></td>
</tr>
<tr>
<td align=center>تصغير المسافة داخل المجموعة</td>
<td align=center>تصغير متوسط المسافة بين أزواج المجموعات</td>
<td align=center>تصغير المسافة العظمى بين أزواج المجموعات</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>مقاييس تقدير المجموعات</h3>
<p>في التعلّم غير المُوَجَّه من الصعب غالباً تقدير أداء نموذج ما، لأن القيم الحقيقية تكون غير متوفرة كما هو الحال في التعلًم المُوَجَّه.</p>
<p><span class=""new-item item-b"">معامل الظّل <span class=""ltr stick-together"">(silhouette coefficient)</span></span> إذا رمزنا $a$ و $b$ لمتوسط المسافة بين عينة وكل النقط المنتمية لنفس الصنف، و بين عينة وكل النقط المنتمية لأقرب مجموعة، المعامل الظِلِّي $s$ لعينة واحدة معرف كالتالي:</p>
<div class=mobile-container>
\[\boxed{s=\frac{b-a}{\max(a,b)}}\]
</div>
<br>
<p><span class=""new-item item-b"">مؤشر كالينسكي-هارباز <span class=""ltr stick-together"">(Calinski-Harabaz index)</span></span> إذا رمزنا بـ $k$ لعدد المجموعات، فإن $B_k$ و $W_k$ مصفوفتي التشتت بين المجموعات وداخلها تعرف كالتالي:</p>
<div class=mobile-container>
\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]
</div>
<p>مؤشر كالينسكي-هارباز $s(k)$ يشير إلى جودة نموذج تجميعي في تعريف مجموعاته، بحيث كلما كانت النتيجة أعلى كلما دل ذلك على أن المجموعات أكثر كثافة وأكثر انفصالاً فيما بينها. هذا المؤشر معرّف كالتالي:</p>
<div class=mobile-container>
\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#dimension-reduction id=dimension-reduction></a>تقليص الأبعاد</h2>
<h3>تحليل المكون الرئيس</h3>
<p>إنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.</p>
<p><span class=""new-item item-b"">قيمة ذاتية <span class=""ltr stick-together"">(eigenvalue)</span>، متجه ذاتي <span class=""ltr stick-together"">(eigenvector)</span></span> لتكن $A\in\mathbb{R}^{n\times n}$ مصفوفة، نقول أن $\lambda$ قيمة ذاتية للمصفوفة $A$ إذا وُجِد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجهاً ذاتياً، بحيث:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">مبرهنة الطّيف <span class=""ltr stick-together"">(spectral theorem)</span></span> لتكن $A\in\mathbb{R}^{n\times n}$. إذا كانت $A$ متناظرة فإنها يمكن أن تكون شبه قطرية عن طريق مصفوفة متعامدة حقيقية $U\in\mathbb{R}^{n\times n}$. إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]
</div>
<br>
<p><i>ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي <span class=""ltr stick-together"">(principal eigenvector)</span> للمصفوفة $A$.</i></p>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> تحليل المكون الرئيس <span class=""ltr stick-together"">(Principal Component Analysis, PCA)</span> طريقة لخفض الأبعاد تهدف إلى إسقاط البيانات على $k$ بُعد بحيث يتم تعطيم التباين <span class=""ltr stick-together"">(variance)</span>، خطواتها كالتالي:</p>
<br><p>- <u>الخطوة 1</u>: تسوية البيانات بحيث تصبح ذات متوسط يساوي صفر وانحراف معياري يساوي واحد.</p>
<div class=mobile-container>
\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{و}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]
</div>
<br><p>- <u>الخطوة 2</u>: حساب $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$، وهي متناظرة وذات قيم ذاتية حقيقية.
<br>- <u>الخطوة 3</u>: حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.
<br>- <u>الخطوة 4</u>: إسقاط البيانات على $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.</p>
<p>هذا الإجراء يعظم التباين بين كل الفضاءات البُعدية.</p>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/pca-ar.png?700b7fcad5a743233edf410818b4a45e>
</center>
<br>
<h3>تحليل المكونات المستقلة</h3>
<p>هي طريقة تهدف إلى إيجاد المصادر التوليدية الكامنة.</p>
<p><span class=""new-item item-r"">افتراضات</span> لنفترض أن بياناتنا $x$ تم توليدها عن طريق المتجه المصدر $s=(s_1,...,s_n)$ ذا $n$ بُعد، حيث $s_i$ متغيرات عشوائية مستقلة، وذلك عبر مصفوفة خلط غير منفردة <span class=""ltr stick-together"">(mixing and non-singular)</span> $A$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{x=As}\]
</div>
<p>الهدف هو العثور على مصفوفة الفصل $W=A^{-1}$.</p>
<br>
<p><span class=""new-item item-g"">خوارزمية تحليل المكونات المستقلة <span class=""ltr stick-together"">(ICA)</span> لبيل وسجنوسكي <span class=""ltr stick-together"">(Bell and Sejnowski)</span></span> هذه الخوارزمية تجد مصفوفة الفصل $W$ عن طريق الخطوات التالية:
<br>- اكتب الاحتمال لـ $x=As=W^{-1}s$ كالتالي:</p>
<div class=mobile-container>
\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]
</div>
<br><p>- لتكن $\{x^{(i)}, i\in[\![1,m]\!]\}$ بيانات التمرن و $g$ دالة سيجمويد، اكتب الأرجحية اللوغاريتمية <span class=""ltr stick-together"">(log likelihood)</span> كالتالي:</p>
<div class=mobile-container>
\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]
</div>
<p>هكذا، باستخدام الصعود الاشتقاقي العشوائي <span class=""ltr stick-together"">(stochastic gradient ascent)</span>، لكل عينة تدريب $x^{(i)}$ نقوم بتحديث $W$ كما يلي:</p>
<div class=mobile-container>
\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]
</div>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
3,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Unsupervised Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Introduction to Unsupervised Learning

Motivation The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.

Jensen's inequality Let $f$ be a convex function and $X$ a random variable. We have the following inequality:

\[\boxed{E[f(X)]\geqslant f(E[X])}\]

Clustering

Expectation-Maximization

Latent variables Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$. Here are the most common settings where there are latent variables:

Setting Latent variable $z$ $x|z$ Comments Mixture of $k$ Gaussians $\textrm{Multinomial}(\phi)$ $\mathcal{N}(\mu_j,\Sigma_j)$ $\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$ Factor analysis $\mathcal{N}(0,I)$ $\mathcal{N}(\mu+\Lambda z,\psi)$ $\mu_j\in\mathbb{R}^n$

Algorithm The Expectation-Maximization (EM) algorithm gives an efficient method at estimating the parameter $\theta$ through maximum likelihood estimation by repeatedly constructing a lower-bound on the likelihood (E-step) and optimizing that lower bound (M-step) as follows:

E-step : Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows: \[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]

: Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows: M-step : Use the posterior probabilities $Q_i(z^{(i)})$ as cluster specific weights on data points $x^{(i)}$ to separately re-estimate each cluster model as follows: \[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]

$k$-means clustering

We note $c^{(i)}$ the cluster of data point $i$ and $\mu_j$ the center of cluster $j$.

Algorithm After randomly initializing the cluster centroids $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$, the $k$-means algorithm repeats the following step until convergence:

\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{and}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]

Distortion function In order to see if the algorithm converges, we look at the distortion function defined as follows:

\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]

Hierarchical clustering

Algorithm It is a clustering algorithm with an agglomerative hierarchical approach that build nested clusters in a successive manner.

Types There are different sorts of hierarchical clustering algorithms that aims at optimizing different objective functions, which is summed up in the table below:

Ward linkage Average linkage Complete linkage Minimize within cluster distance Minimize average distance between cluster pairs Minimize maximum distance of between cluster pairs

Clustering assessment metrics

In an unsupervised learning setting, it is often hard to assess the performance of a model since we don't have the ground truth labels as was the case in the supervised learning setting.

Silhouette coefficient By noting $a$ and $b$ the mean distance between a sample and all other points in the same class, and between a sample and all other points in the next nearest cluster, the silhouette coefficient $s$ for a single sample is defined as follows:

\[\boxed{s=\frac{b-a}{\max(a,b)}}\]

Calinski-Harabaz index By noting $k$ the number of clusters, $B_k$ and $W_k$ the between and within-clustering dispersion matrices respectively defined as

\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]

\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]

Dimension reduction

Principal component analysis

It is a dimension reduction technique that finds the variance maximizing directions onto which to project the data.

Eigenvalue, eigenvector Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:

\[\boxed{Az=\lambda z}\]

Spectral theorem Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:

\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]

Remark: the eigenvector associated with the largest eigenvalue is called principal eigenvector of matrix $A$.

Algorithm The Principal Component Analysis (PCA) procedure is a dimension reduction technique that projects the data on $k$ dimensions by maximizing the variance of the data as follows:

Step 1 : Normalize the data to have a mean of 0 and standard deviation of 1. \[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{and}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]

: Normalize the data to have a mean of 0 and standard deviation of 1. Step 2 : Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues.

: Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues. Step 3 : Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues.

: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues. Step 4 : Project the data on $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.

This procedure maximizes the variance among all $k$-dimensional spaces.

Independent component analysis

It is a technique meant to find the underlying generating sources.

Assumptions We assume that our data $x$ has been generated by the $n$-dimensional source vector $s=(s_1,...,s_n)$, where $s_i$ are independent random variables, via a mixing and non-singular matrix $A$ as follows:

\[\boxed{x=As}\]

The goal is to find the unmixing matrix $W=A^{-1}$.

Bell and Sejnowski ICA algorithm This algorithm finds the unmixing matrix $W$ by following the steps below:

Write the probability of $x=As=W^{-1}s$ as: \[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]

Write the log likelihood given our training data $\{x^{(i)}, i\in[\![1,m]\!]\}$ and by noting $g$ the sigmoid function as: \[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]

\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksUnsupervised Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiIntroduction to Unsupervised LearningMotivation The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.
We have the following inequality:\[\boxed{E[f(X)]\geqslant f(E[X])}\]ClusteringExpectation-MaximizationLatent variables Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$.
If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$.
Step 3 : Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e.
: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e.","['matrix', 'algorithm', 'xi', 'variables', 'cluster', 'learning', 'unsupervised', 'cheatsheet', 'n', 'k', 'data', 'orthogonal']",en,Unsupervised Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Unsupervised Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Unsupervised Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#intro>Introduction</a></div> <div class=dropdown-container> <a href=#intro><span>Motivation</span></a> <a href=#intro><span>Jensen's inequality</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#clustering>Clustering</a></div> <div class=dropdown-container> <a href=#clustering><span>Expectation-Maximization</span></a> <a href=#clustering><span>k-means</span></a> <a href=#clustering><span>Hierarchical clustering</span></a> <a href=#clustering><span>Metrics</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#dimension-reduction>Dimension reduction</a></div> <div class=dropdown-container> <a href=#dimension-reduction><span>PCA</span></a> <a href=#dimension-reduction><span>ICA</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-unsupervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button><b>Unsupervised Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Unsupervised Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#intro id=intro></a>Introduction to Unsupervised Learning</h2>
<p><span class=""new-item item-b"">Motivation</span> The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.</p>
<br>
<p><span class=""new-item item-r"">Jensen's inequality</span> Let $f$ be a convex function and $X$ a random variable. We have the following inequality:</p>
<div class=mobile-container>
\[\boxed{E[f(X)]\geqslant f(E[X])}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#clustering id=clustering></a>Clustering</h2>
<h3>Expectation-Maximization</h3>
<p><span class=""new-item item-r"">Latent variables</span> Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$. Here are the most common settings where there are latent variables:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Setting</b></td>
<td align=center><b>Latent variable $z$</b></td>
<td align=center>$x|z$</td>
<td align=center><b>Comments</b></td>
</tr>
<tr>
<td align=center>Mixture of $k$ Gaussians</td>
<td align=center>$\textrm{Multinomial}(\phi)$</td>
<td align=center>$\mathcal{N}(\mu_j,\Sigma_j)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$</td>
</tr>
<tr>
<td align=center>Factor analysis</td>
<td align=center>$\mathcal{N}(0,I)$</td>
<td align=center>$\mathcal{N}(\mu+\Lambda z,\psi)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Algorithm</span> The Expectation-Maximization (EM) algorithm gives an efficient method at estimating the parameter $\theta$ through maximum likelihood estimation by repeatedly constructing a lower-bound on the likelihood (E-step) and optimizing that lower bound (M-step) as follows:
</p><ul>
<li><u>E-step</u>: Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows:
<div class=mobile-container>
\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]
</div>
</li><li><u>M-step</u>: Use the posterior probabilities $Q_i(z^{(i)})$ as cluster specific weights on data points $x^{(i)}$ to separately re-estimate each cluster model as follows:
<div class=mobile-container>
\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]<p></p>
</div>
</li></ul>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/expectation-maximization-en.png?ed72a10f73a6d201e2ad20e04d145e82>
</center>
<br>
<h3>$k$-means clustering</h3>
<p>We note $c^{(i)}$ the cluster of data point $i$ and $\mu_j$ the center of cluster $j$.</p>
<br>
<p><span class=""new-item item-g"">Algorithm</span> After randomly initializing the cluster centroids $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$, the $k$-means algorithm repeats the following step until convergence:</p>
<div class=mobile-container>
\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{and}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/k-means-en.png?9925605d814ddadebcae2ae4754ab0a4>
</center>
<br>
<p><span class=""new-item item-b"">Distortion function</span> In order to see if the algorithm converges, we look at the distortion function defined as follows:</p>
<div class=mobile-container>
\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]
</div>
<br>
<h3>Hierarchical clustering</h3>
<p><span class=""new-item item-g"">Algorithm</span> It is a clustering algorithm with an agglomerative hierarchical approach that build nested clusters in a successive manner.</p>
<br>
<p><span class=""new-item item-b"">Types</span> There are different sorts of hierarchical clustering algorithms that aims at optimizing different objective functions, which is summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Ward linkage</b></td>
<td align=center><b>Average linkage</b></td>
<td align=center><b>Complete linkage</b></td>
</tr>
<tr>
<td align=center>Minimize within cluster distance</td>
<td align=center>Minimize average distance between cluster pairs</td>
<td align=center>Minimize maximum distance of between cluster pairs</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Clustering assessment metrics</h3>
<p>In an unsupervised learning setting, it is often hard to assess the performance of a model since we don't have the ground truth labels as was the case in the supervised learning setting.</p>
<p><span class=""new-item item-b"">Silhouette coefficient</span> By noting $a$ and $b$ the mean distance between a sample and all other points in the same class, and between a sample and all other points in the next nearest cluster, the silhouette coefficient $s$ for a single sample is defined as follows:</p>
<div class=mobile-container>
\[\boxed{s=\frac{b-a}{\max(a,b)}}\]
</div>
<br>
<p><span class=""new-item item-b"">Calinski-Harabaz index</span> By noting $k$ the number of clusters, $B_k$ and $W_k$ the between and within-clustering dispersion matrices respectively defined as
</p><div class=mobile-container>
\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]
</div>
the Calinski-Harabaz index $s(k)$ indicates how well a clustering model defines its clusters, such that the higher the score, the more dense and well separated the clusters are. It is defined as follows:<p></p>
<div class=mobile-container>
\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#dimension-reduction id=dimension-reduction></a>Dimension reduction</h2>
<h3>Principal component analysis</h3>
<p>It is a dimension reduction technique that finds the variance maximizing directions onto which to project the data.</p>
<p><span class=""new-item item-b"">Eigenvalue, eigenvector</span> Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">Spectral theorem</span> Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]
</div>
<br>
<p><span class=remark>Remark: the eigenvector associated with the largest eigenvalue is called principal eigenvector of matrix $A$.</span></p>
<br>
<p><span class=""new-item item-g"">Algorithm</span> The Principal Component Analysis (PCA) procedure is a dimension reduction technique that projects the data on $k$ dimensions by maximizing the variance of the data as follows:
</p><ul>
<li><u>Step 1</u>: Normalize the data to have a mean of 0 and standard deviation of 1.
<div class=mobile-container>
\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{and}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]
</div>
</li><li><u>Step 2</u>: Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues.
</li><li><u>Step 3</u>: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues.
</li><li><u>Step 4</u>: Project the data on $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.
</li></ul><p></p>
<p>This procedure maximizes the variance among all $k$-dimensional spaces.</p>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/pca-en.png?4be4617788fd40f4e998b530b75f4149>
</center>
<br>
<h3>Independent component analysis</h3>
<p>It is a technique meant to find the underlying generating sources.</p>
<p><span class=""new-item item-r"">Assumptions</span> We assume that our data $x$ has been generated by the $n$-dimensional source vector $s=(s_1,...,s_n)$, where $s_i$ are independent random variables, via a mixing and non-singular matrix $A$ as follows:</p>
<div class=mobile-container>
\[\boxed{x=As}\]
</div>
<p>The goal is to find the unmixing matrix $W=A^{-1}$.</p>
<br>
<p><span class=""new-item item-g"">Bell and Sejnowski ICA algorithm</span> This algorithm finds the unmixing matrix $W$ by following the steps below:
</p><ul>
<li>Write the probability of $x=As=W^{-1}s$ as:
<div class=mobile-container>
\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]
</div>
</li><li>Write the log likelihood given our training data $\{x^{(i)}, i\in[\![1,m]\!]\}$ and by noting $g$ the sigmoid function as:
<div class=mobile-container>
\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]
</div>
</li></ul>
Therefore, the stochastic gradient ascent learning rule is such that for each training example $x^{(i)}$, we update $W$ as follows:
<div class=mobile-container>
\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]
</div>
<p></p>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
4,"تعلم آلي - CS ۲۲۹ العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

تعلّم موجَّه تعلم غير موجَّه تعلم متعمق نصائح وحيل

ملخص مختصر التعلم العميق

النص الأصلي بواسطة افشین عمیدی و شروین عمیدی

تمت الترجمة بواسطة امجد الخطابي. تمت المراجعة بواسطة زيد اليافعي.

الشبكة العصبونية الاصطناعية (neural networks)

الشبكة العصبونية الاصطناعيةهي عبارة عن نوع من النماذج يبنى من عدة طبقات , اكثر هذة الانواع استخداما هي الشبكات الالتفافية و الشبكات العصبونية المتكرره البنية المصطلحات حول بنية الشبكة العصبونية موضح في الشكل ادناة

عبر تدوين $i$ كالطبقة رقم $i$ و $j$ للدلالة على رقم الوحده الخفية في تلك الطبقة , نحصل على:

\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]

حيث نعرف $w, b, z$ كالوزن , و معامل التعديل , و الناتج حسب الترتيب.

دالة التفعيل (activation function) دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج. هنا بعض دوال التفعيل الشائعة Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$

و $\epsilon\ll1$

دالة الانتروبيا التقاطعية للخسارة (cross-entropy loss) في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:

\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]

معدل التعلم (learning rate) معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان. يمكن تثبيت هذا المعامل او تحديثة بشكل تأقلمي . حاليا اكثر النسب شيوعا تدعى Adam , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي $\alpha$ او $\eta$ ب ,

التغذية الخلفية (backpropagation) التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج. المشتقة بالنسبة للوزن $w$ يتم حسابها باستخدام قاعدة التسلسل و تكون عبر الشكل الاتي:

\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]

كنتيجة , الوزن سيتم تحديثة كالتالي:

\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]

تحديث الاوزان في الشبكات العصبونية , يتم تحديث الاوزان كما يلي:

- الخطوة 1 : خذ حزمة من بيانات التدريب

- الخطوة 2 : قم بعملية التغذيه الامامية لحساب الخسارة الناتجة

- الخطوة 3 : قم بتغذية خلفية للخساره للحصول على دالة الانحدار

- الخطوة 4 : استخدم قيم الانحدار لتحديث اوزان الشبكة

الاسقاط (dropout) الاسقاط هي طريقة الغرض منها منع التكيف الزائد للنموذج في بيانات التدريب عبر اسقاط بعض الواحدات في الشبكة العصبونية, العصبونات يتم اما اسقاطها باحتمالية $p$ او الحفاظ عليها باحتمالية $1-p$.

الشبكات العصبونية الالتفافية (CNN) احتياج الطبقة الالتفافية عبر رمز $W$ لحجم المدخل , $F$ حجم العصبونات للطبقة الالتفافية , $P$ عدد الحشوات الصفرية , فأن $N$ عدد العصبونات لكل حجم معطى يحسب عبر الاتي:

\[\boxed{N=\frac{W-F+2P}{S}+1}\]

تنظيم الحزمة (batch normalization) هي خطوه من قيم التحسين الخاصة $\gamma, \beta$ والتي تعدل الحزمة $\{x_i\}$. لنجعل $\mu_B, \sigma_B^2$ المتوسط و الانحراف للحزمة المعنية و نريد تصحيح هذه الحزمة, يتم ذلك كالتالي:

\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]

في الغالب تتم بعد الطبقة الالتفافية أو المتصلة كليا و قبل طبقة التغيرات الغير خطية و تهدف للسماح للسرعات التعليم العالية للتقليل من الاعتمادية القوية للقيم الاولية.

الشبكات العصبونية التكرارية (RNN) انواع البوابات هنا الانواع المختلفة التي ممكن مواجهتها في الشبكة العصبونية الاعتيادية: بوابة ادخال بوابة نسيان بوابة منفذ بوابة اخراج كتابة ام عدم كتابة الى الخلية؟ مسح ام عدم مسح الخلية؟ كمية الكتابة الى الخلية ؟ مدى الافصاح عن الخلية ؟

LSTM ذاكرة طويلة قصير الامد (long short-term memory) هي نوع من نموذج ال RNN تستخدم لتجنب مشكلة اختفاء الانحدار عبر اضافة بوابات النسيان.

التعلم و التحكم المعزز (reinforcement learning) الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة. تعريفات عملية ماركوف لاتخاذ القرار عملية ماركوف لاتخاذ القرار هي سلسلة خماسية $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ حيث

- $\mathcal{S}$ هي مجموعة من حالات البيئة

- $\mathcal{A}$ هي مجموعة من حالات الاجراءات

- $\{P_{sa}\}$ هو حالة احتمال الانتقال من الحالة $s\in\mathcal{S}$ و $a\in\mathcal{A}$

- $\gamma\in[0,1[$ هي عامل الخصم

- $R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ هي دالة المكافأة والتي تعمل الخوارزمية على جعلها اعلى قيمة

دالة القواعد دالة القواعد $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ هي التي تقوم بترجمة الحالات الى اجراءات. ملاحظة: نقول ان النموذج ينفذ القاعدة المعينه $\pi$ للحالة المعطاة $s$ ان نتخذ الاجراء$a=\pi(s)$.

دالة القاعدة لاي قاعدة معطاة $\pi$ و حالة $s$, نقوم بتعريف دالة القيمة $V^{\pi}$ كما يلي:

\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]

معادلة بيلمان معادلات بيلمان المثلى تشخص دالة القيمة دالة القيمة $V^{\pi^*}$ $\pi^*$:للقاعدة المثلى

\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]

$\pi^*$ للحالة المعطاه $s$ تعطى كاالتالي: ملاحظة: نلاحظ ان القاعدة المثلى

\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]

خوارزمية تكرار القيمة (value iteration algorithm) خوارزمية تكرار القيمة تكون في خطوتين: 1) نقوم بوضع قيمة اولية:

\[\boxed{V_0(s)=0}\]

2) نقوم بتكرير القيمة حسب القيم السابقة:

\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]

التعلم-$Q$ ($Q$-learning) هي طريقة غير منمذجة لتقدير $Q$, و تتم كالاتي:

\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]","تعلم آلي - CS ۲۲۹ العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 تعلّم موجَّه تعلم غير موجَّه تعلم متعمق نصائح وحيلملخص مختصر التعلم العميقالنص الأصلي بواسطة افشین عمیدی و شروین عمیدیتمت الترجمة بواسطة امجد الخطابي.
دالة التفعيل (activation function) دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج.
هنا بعض دوال التفعيل الشائعة Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$و $\epsilon\ll1$دالة الانتروبيا التقاطعية للخسارة (cross-entropy loss) في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]معدل التعلم (learning rate) معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان.
حاليا اكثر النسب شيوعا تدعى Adam , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي $\alpha$ او $\eta$ ب ,التغذية الخلفية (backpropagation) التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج.
التعلم و التحكم المعزز (reinforcement learning) الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة.","['عبر', 'بوابة', 'القيمة', 'يتم', 'العصبونية', 'التعلم', 'دالة', 'العميق', 'تعلم', 'طريقة', 'الالتفافية']",ar,التعلم العميق,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>التعلم العميق - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-deep-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلم متعمق</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#nn>الشبكة العصبونية الاصطناعية</a></div> <div class=dropdown-container> <a href=#nn><span>البنية </span></a> <a href=#nn><span>دالة التفعيل </span></a> <a href=#nn><span>التغذية الخلفية </span></a> <a href=#nn><span>الاسقاط </span></a> </div> </li> <li> <div class=dropdown-btn><a href=#cnn> الشبكة العصبونية الالتفافية </a></div> <div class=dropdown-container> <a href=#cnn><span>طبقة التفافية </span></a> <a href=#cnn><span>تنظيم الحزمة </span></a> </div> </li> <li> <div class=dropdown-btn><a href=#rnn>الشبكة العصبونية التكرارية </a></div> <div class=dropdown-container> <a href=#rnn><span>البوابات </span></a> <a href=#rnn><span><span class=ltr>LSTM</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#reinforcement>التعلم المعزز</a></div> <div class=dropdown-container> <a href=#reinforcement><span>عملية ماركوف لاتخاذ القرار</span></a> <a href=#reinforcement><span>تكرير القيمة / القاعدة</span></a> <a href=#reinforcement><span>البرمجة الديناميكية التقريبية</span></a> <a href=#reinforcement><span>بحث القاعدة</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-deep-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i></a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button><b>تعلم متعمق</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>ملخص مختصر التعلم العميق
</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة امجد الخطابي. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<h2><a aria-hidden=true class=anchor href=#nn id=nn></a><div dir=rtl>الشبكة العصبونية الاصطناعية <span class=""ltr stick-together"">(neural networks)</span></div></h2>
<div dir=rtl>
<p>الشبكة العصبونية الاصطناعيةهي عبارة عن نوع من النماذج يبنى من عدة طبقات , اكثر هذة الانواع استخداما هي الشبكات الالتفافية و الشبكات العصبونية المتكرره</p>
<p><span class=""new-item item-g"">البنية</span> المصطلحات حول بنية الشبكة العصبونية موضح في الشكل ادناة</p>
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/neural-network-ar.png?d70a0d6dba75023620ae6b1627790e47 style=width:100%;max-width:700px>
</center>
<div dir=rtl>
<p>عبر تدوين $i$ كالطبقة رقم $i$ و $j$ للدلالة على رقم الوحده الخفية في تلك الطبقة , نحصل على:</p>
</div>
<div class=mobile-container>
\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]
</div>
<div dir=rtl>
<p>حيث نعرف $w, b, z$ كالوزن , و معامل التعديل , و الناتج حسب الترتيب.</p>
<br>
<p><span class=""new-item item-b"">دالة التفعيل <span class=""ltr stick-together"">(activation function)</span></span> دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج. هنا بعض دوال التفعيل الشائعة</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b class=ltr>Sigmoid</b></td>
<td align=center><b class=ltr>Tanh</b></td>
<td align=center><b class=ltr>ReLU</b></td>
<td align=center><b class=ltr>Leaky ReLU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\displaystyle\frac{1}{1+e^{-z}}$</td>
<td align=center>$g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$</td>
<td align=center>$g(z)=\textrm{max}(0,z)$</td>
<td align=center>$g(z)=\textrm{max}(\epsilon z,z)$<br> و $\epsilon\ll1$</td>
</tr>
<tr>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/sigmoid.png?c91b6e5a7d4e78e95880bcf4e39889df>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/tanh.png?22ac27f27c510c6414e8a3bb4aca2d80>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/relu.png?6c1d78551355db5c6e4f6f8b5282cfa8>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e>
</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">دالة الانتروبيا التقاطعية للخسارة <span class=""ltr stick-together"">(cross-entropy loss)</span></span> في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-b"">معدل التعلم <span class=""ltr stick-together"">(learning rate)</span></span> معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان. يمكن تثبيت هذا المعامل او تحديثة بشكل تأقلمي . حاليا اكثر النسب شيوعا تدعى <span class=""ltr stick-together"">Adam</span> , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي    $\alpha$ او $\eta$ ب ,</p>
<br>
<p><span class=""new-item item-r"">التغذية الخلفية <span class=""ltr stick-together"">(backpropagation)</span></span> التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج. المشتقة بالنسبة للوزن $w$ يتم حسابها باستخدام قاعدة التسلسل و تكون عبر الشكل الاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]
</div>
<div dir=rtl>
<p>كنتيجة , الوزن سيتم تحديثة كالتالي:</p>
</div>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">تحديث الاوزان</span> في الشبكات العصبونية , يتم تحديث الاوزان كما يلي:
<br>- <u>الخطوة 1</u>: خذ حزمة من بيانات التدريب
<br>- <u>الخطوة 2</u>: قم بعملية التغذيه الامامية لحساب الخسارة الناتجة
<br>- <u>الخطوة 3</u>: قم بتغذية خلفية للخساره للحصول على دالة الانحدار
<br>- <u>الخطوة 4</u>: استخدم قيم الانحدار لتحديث اوزان الشبكة
</p>
<br>
<p><span class=""new-item item-g"">الاسقاط <span class=""ltr stick-together"">(dropout)</span></span> الاسقاط هي طريقة الغرض منها منع التكيف الزائد للنموذج في بيانات التدريب عبر اسقاط بعض الواحدات في الشبكة العصبونية, العصبونات يتم اما اسقاطها باحتمالية $p$ او الحفاظ عليها باحتمالية $1-p$.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#cnn id=cnn></a>الشبكات العصبونية الالتفافية <span class=""ltr stick-together"">(CNN)</span></h2>
<p><span class=""new-item item-r"">احتياج الطبقة الالتفافية</span> عبر رمز $W$ لحجم المدخل , $F$ حجم العصبونات للطبقة الالتفافية , $P$ عدد الحشوات الصفرية , فأن $N$ عدد العصبونات لكل حجم معطى يحسب عبر الاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{N=\frac{W-F+2P}{S}+1}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">تنظيم الحزمة <span class=""ltr stick-together"">(batch normalization)</span></span> هي خطوه من قيم التحسين الخاصة $\gamma, \beta$  والتي تعدل الحزمة $\{x_i\}$. لنجعل $\mu_B, \sigma_B^2$ المتوسط و الانحراف للحزمة المعنية و نريد تصحيح هذه الحزمة, يتم ذلك كالتالي:    </p>
</div>
<div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
<div dir=rtl>
<p>في الغالب تتم بعد الطبقة الالتفافية أو المتصلة كليا و قبل طبقة التغيرات الغير خطية و تهدف للسماح للسرعات التعليم العالية للتقليل من الاعتمادية القوية للقيم الاولية.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#rnn id=rnn></a>الشبكات العصبونية التكرارية <span class=""ltr stick-together"">(RNN)</span></h2>
<p><span class=""new-item item-r"">انواع البوابات</span> هنا الانواع المختلفة التي ممكن مواجهتها في الشبكة العصبونية الاعتيادية:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>بوابة ادخال</b></td>
<td align=center><b>بوابة نسيان</b></td>
<td align=center><b>بوابة منفذ</b></td>
<td align=center><b>بوابة اخراج </b></td>
</tr>
<tr>
<td align=center>كتابة ام عدم كتابة الى الخلية؟</td>
<td align=center>مسح ام عدم مسح الخلية؟</td>
<td align=center>كمية الكتابة الى الخلية ؟ </td>
<td align=center>مدى الافصاح عن الخلية ؟ </td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">LSTM</span> ذاكرة طويلة قصير الامد <span class=""ltr stick-together"">(long short-term memory)</span> هي نوع من نموذج ال <span class=""ltr stick-together"">RNN</span> تستخدم لتجنب مشكلة اختفاء الانحدار عبر اضافة بوابات النسيان.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#reinforcement id=reinforcement></a>التعلم و التحكم المعزز <span class=""ltr stick-together"">(reinforcement learning)</span></h2>
<p>الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة.</p>
<h3>تعريفات</h3>
<p><span class=""new-item item-b"">عملية ماركوف لاتخاذ القرار</span> عملية ماركوف لاتخاذ القرار هي سلسلة خماسية $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ حيث
<br>-  $\mathcal{S}$ هي مجموعة من حالات البيئة
<br>- $\mathcal{A}$ هي مجموعة من حالات الاجراءات
<br>- $\{P_{sa}\}$ هو حالة احتمال الانتقال من الحالة $s\in\mathcal{S}$ و $a\in\mathcal{A}$
<br>- $\gamma\in[0,1[$ هي عامل الخصم
<br>- $R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$  هي دالة المكافأة والتي تعمل الخوارزمية على جعلها اعلى قيمة</p>
<br>
<p><span class=""new-item item-b"">دالة القواعد</span> دالة القواعد $\pi:\mathcal{S}\longrightarrow\mathcal{A}$  هي التي تقوم بترجمة الحالات الى اجراءات.</p>
<p><span class=remark>ملاحظة: نقول ان النموذج ينفذ القاعدة المعينه $\pi$ للحالة المعطاة $s$ ان نتخذ الاجراء$a=\pi(s)$.  </span></p>
<br>
<p><span class=""new-item item-g"">دالة القاعدة</span> لاي قاعدة معطاة $\pi$ و حالة $s$, نقوم بتعريف دالة القيمة $V^{\pi}$  كما يلي:  </p>
</div>
<div class=mobile-container>
\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">معادلة بيلمان</span> معادلات بيلمان المثلى تشخص دالة القيمة دالة القيمة $V^{\pi^*}$  $\pi^*$:للقاعدة المثلى</p>
</div>
<div class=mobile-container>
\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]
</div>
<div dir=rtl>
<p><i>  $\pi^*$ للحالة المعطاه $s$ تعطى كاالتالي: ملاحظة: نلاحظ ان القاعدة المثلى</i></p>
</div>
<div class=mobile-container>
\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">خوارزمية تكرار القيمة <span class=""ltr stick-together"">(value iteration algorithm)</span></span> خوارزمية تكرار القيمة تكون في خطوتين:</p>
<p> 1) نقوم بوضع قيمة اولية:</p>
</div>
<div class=mobile-container>
\[\boxed{V_0(s)=0}\]
</div>
<div dir=rtl>
<p>2) نقوم بتكرير القيمة حسب القيم السابقة:</p>
</div>
<div class=mobile-container>
\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">التعلم-$Q$ <span class=""ltr stick-together"">($Q$-learning)</span></span> هي طريقة غير منمذجة لتقدير $Q$, و تتم كالاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]
</div>
<br>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
5,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Deep Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Neural Networks

Neural networks are a class of models that are built with layers. Commonly used types of neural networks include convolutional and recurrent neural networks.

Architecture The vocabulary around neural networks architectures is described in the figure below:

By noting $i$ the $i^{th}$ layer of the network and $j$ the $j^{th}$ hidden unit of the layer, we have:

\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]

where we note $w$, $b$, $z$ the weight, bias and output respectively.

Activation function Activation functions are used at the end of a hidden unit to introduce non-linear complexities to the model. Here are the most common ones:

Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$

with $\epsilon\ll1$

Cross-entropy loss In the context of neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:

\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]

Learning rate The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. This can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.

Backpropagation Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to weight $w$ is computed using chain rule and is of the following form:

\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]

As a result, the weight is updated as follows:

\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]

Updating weights In a neural network, weights are updated as follows:

Step 1 : Take a batch of training data.

: Take a batch of training data. Step 2 : Perform forward propagation to obtain the corresponding loss.

: Perform forward propagation to obtain the corresponding loss. Step 3 : Backpropagate the loss to get the gradients.

: Backpropagate the loss to get the gradients. Step 4 : Use the gradients to update the weights of the network.

Dropout Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network. In practice, neurons are either dropped with probability $p$ or kept with probability $1-p.$

Convolutional Neural Networks

Convolutional layer requirement By noting $W$ the input volume size, $F$ the size of the convolutional layer neurons, $P$ the amount of zero padding, then the number of neurons $N$ that fit in a given volume is such that:

\[\boxed{N=\frac{W-F+2P}{S}+1}\]

Batch normalization It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:

\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]

Recurrent Neural Networks

Types of gates Here are the different types of gates that we encounter in a typical recurrent neural network:

Input gate Forget gate Gate Output gate Write to cell or not? Erase a cell or not? How much to write to cell? How much to reveal cell?

LSTM A long short-term memory (LSTM) network is a type of RNN model that avoids the vanishing gradient problem by adding 'forget' gates.

For a more detailed overview of the concepts above, check out the Deep Learning cheatsheets

Reinforcement Learning and Control

The goal of reinforcement learning is for an agent to learn how to evolve in an environment.

Definitions

Markov decision processes A Markov decision process (MDP) is a 5-tuple $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ where:

$\mathcal{S}$ is the set of states

$\mathcal{A}$ is the set of actions

$\{P_{sa}\}$ are the state transition probabilities for $s\in\mathcal{S}$ and $a\in\mathcal{A}$

$\gamma\in[0,1[$ is the discount factor

$R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ is the reward function that the algorithm wants to maximize

Policy A policy $\pi$ is a function $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ that maps states to actions.

Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.

Value function For a given policy $\pi$ and a given state $s$, we define the value function $V^{\pi}$ as follows:

\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]

Bellman equation The optimal Bellman equations characterizes the value function $V^{\pi^*}$ of the optimal policy $\pi^*$:

\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]

Remark: we note that the optimal policy $\pi^*$ for a given state $s$ is such that:

\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]

Value iteration algorithm The value iteration algorithm is in two steps:

1) We initialize the value:

\[\boxed{V_0(s)=0}\]

2) We iterate the value based on the values before:

\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]

Maximum likelihood estimate The maximum likelihood estimates for the state transition probabilities are as follows:

\[\boxed{P_{sa}(s')=\frac{\#\textrm{times took action }a\textrm{ in state }s\textrm{ and got to }s'}{\#\textrm{times took action }a\textrm{ in state }s}}\]

Q-learning $Q$-learning is a model-free estimation of $Q$, which is done as follows:

\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksDeep Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiNeural NetworksNeural networks are a class of models that are built with layers.
Backpropagation Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output.
Dropout Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network.
For a more detailed overview of the concepts above, check out the Deep Learning cheatsheetsReinforcement Learning and ControlThe goal of reinforcement learning is for an agent to learn how to evolve in an environment.
Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.","['deep', 'value', 'function', 'loss', 'state', 'policy', 'given', 'learning', 'network', 'cheatsheet', 'neural', 'weights']",en,Deep Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Deep Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Deep Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#nn>Neural Networks</a></div> <div class=dropdown-container> <a href=#nn><span>Architecture</span></a> <a href=#nn><span>Activation function</span></a> <a href=#nn><span>Backpropagation</span></a> <a href=#nn><span>Dropout</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#cnn>Convolutional Neural Networks</a></div> <div class=dropdown-container> <a href=#cnn><span>Convolutional layer</span></a> <a href=#cnn><span>Batch normalization</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#rnn>Recurrent Neural Networks</a></div> <div class=dropdown-container> <a href=#rnn><span>Gates</span></a> <a href=#rnn><span>LSTM</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#reinforcement>Reinforcement learning</a></div> <div class=dropdown-container> <a href=#reinforcement><span>Markov decision processes</span></a> <a href=#reinforcement><span>Value/policy iteration</span></a> <a href=#reinforcement><span>Approximate dynamic     programming</span></a> <a href=#reinforcement><span>Policy search</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-deep-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button><b>Deep Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Deep Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#nn id=nn></a>Neural Networks</h2>
<p>Neural networks are a class of models that are built with layers. Commonly used types of neural networks include convolutional and recurrent neural networks.</p>
<p><span class=""new-item item-g"">Architecture</span> The vocabulary around neural networks architectures is described in the figure below:</p>
<center>
  <img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/neural-network-en.png?835862d448ad85bc5a038848d7d7df0b style=width:100%;max-width:700px>
</center>
<p>By noting $i$ the $i^{th}$ layer of the network and $j$ the $j^{th}$ hidden unit of the layer, we have:</p>
<div class=mobile-container>
\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]
</div>
<p>where we note $w$, $b$, $z$ the weight, bias and output respectively.</p>
<br>
<p><span class=""new-item item-b"">Activation function</span> Activation functions are used at the end of a hidden unit to introduce non-linear complexities to the model. Here are the most common ones:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Sigmoid</b></td>
<td align=center><b>Tanh</b></td>
<td align=center><b>ReLU</b></td>
<td align=center><b>Leaky ReLU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\displaystyle\frac{1}{1+e^{-z}}$</td>
<td align=center>$g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$</td>
<td align=center>$g(z)=\textrm{max}(0,z)$</td>
<td align=center>$g(z)=\textrm{max}(\epsilon z,z)$<br> with $\epsilon\ll1$</td>
</tr>
<tr>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/sigmoid.png?c91b6e5a7d4e78e95880bcf4e39889df>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/tanh.png?22ac27f27c510c6414e8a3bb4aca2d80>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/relu.png?6c1d78551355db5c6e4f6f8b5282cfa8>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e>
</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Cross-entropy loss</span> In the context of neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<p><span class=""new-item item-b"">Learning rate</span> The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. This can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.</p>
<br>
<p><span class=""new-item item-r"">Backpropagation</span> Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to weight $w$ is computed using chain rule and is of the following form:</p>
<div class=mobile-container>
\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]
</div>
<p>As a result, the weight is updated as follows:</p>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<p><span class=""new-item item-g"">Updating weights</span> In a neural network, weights are updated as follows:
</p><ul>
<li><u>Step 1</u>: Take a batch of training data.
</li><li><u>Step 2</u>: Perform forward propagation to obtain the corresponding loss.
</li><li><u>Step 3</u>: Backpropagate the loss to get the gradients.
</li><li><u>Step 4</u>: Use the gradients to update the weights of the network.
</li></ul>
<p></p>
<br>
<p><span class=""new-item item-g"">Dropout</span> Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network. In practice, neurons are either dropped with probability $p$ or kept with probability $1-p.$</p>
<br>
<h2><a aria-hidden=true class=anchor href=#cnn id=cnn></a>Convolutional Neural Networks</h2>
<p><span class=""new-item item-r"">Convolutional layer requirement</span> By noting $W$ the input volume size, $F$ the size of the convolutional layer neurons, $P$ the amount of zero padding, then the number of neurons $N$ that fit in a given volume is such that:</p>
<div class=mobile-container>
\[\boxed{N=\frac{W-F+2P}{S}+1}\]
</div>
<br>
<p><span class=""new-item item-g"">Batch normalization</span> It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:
</p><div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
It is usually done after a fully connected/convolutional layer and before a non-linearity layer and aims at allowing higher learning rates and reducing the strong dependence on initialization.<p></p>
<br>
<h2><a aria-hidden=true class=anchor href=#rnn id=rnn></a>Recurrent Neural Networks</h2>
<p><span class=""new-item item-r"">Types of gates</span> Here are the different types of gates that we encounter in a typical recurrent neural network:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Input gate</b></td>
<td align=center><b>Forget gate</b></td>
<td align=center><b>Gate</b></td>
<td align=center><b>Output gate</b></td>
</tr>
<tr>
<td align=center>Write to cell or not?</td>
<td align=center>Erase a cell or not?</td>
<td align=center>How much to write to cell?</td>
<td align=center>How much to reveal cell?</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">LSTM</span> A long short-term memory (LSTM) network is a type of RNN model that avoids the vanishing gradient problem by adding 'forget' gates.</p>
<br>
<div class=""alert alert-warning"" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link href=teaching/cs-230 onclick=trackOutboundLink(this);>Deep Learning cheatsheets</a>!</div>
<br>
<h2><a aria-hidden=true class=anchor href=#reinforcement id=reinforcement></a>Reinforcement Learning and Control</h2>
<p>The goal of reinforcement learning is for an agent to learn how to evolve in an environment.</p>
<h3>Definitions</h3>
<p><span class=""new-item item-b"">Markov decision processes</span> A Markov decision process (MDP) is a 5-tuple $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ where:
</p><ul>
<li>$\mathcal{S}$ is the set of states
</li><li>$\mathcal{A}$ is the set of actions
</li><li>$\{P_{sa}\}$ are the state transition probabilities for $s\in\mathcal{S}$ and $a\in\mathcal{A}$
</li><li>$\gamma\in[0,1[$ is the discount factor
</li><li>$R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ is the reward function that the algorithm wants to maximize
</li></ul><p></p>
<br>
<p><span class=""new-item item-b"">Policy</span> A policy $\pi$ is a function $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ that maps states to actions.</p>
<p><span class=remark>Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.</span></p>
<br>
<p><span class=""new-item item-g"">Value function</span> For a given policy $\pi$ and a given state $s$, we define the value function $V^{\pi}$ as follows:</p>
<div class=mobile-container>
\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]
</div>
<br>
<p><span class=""new-item item-r"">Bellman equation</span> The optimal Bellman equations characterizes the value function $V^{\pi^*}$ of the optimal policy $\pi^*$:</p>
<div class=mobile-container>
\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]
</div>
<p><span class=remark>Remark: we note that the optimal policy $\pi^*$ for a given state $s$ is such that:</span></p>
<div class=mobile-container>
\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]
</div>
<br>
<p><span class=""new-item item-g"">Value iteration algorithm</span> The value iteration algorithm is in two steps:</p>
<p>1) We initialize the value:</p>
<div class=mobile-container>
\[\boxed{V_0(s)=0}\]
</div>
<p>2) We iterate the value based on the values before:</p>
<div class=mobile-container>
\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]
</div>
<br>
<p><span class=""new-item item-r"">Maximum likelihood estimate</span> The maximum likelihood estimates for the state transition probabilities are as follows:</p>
<div class=mobile-container>
\[\boxed{P_{sa}(s')=\frac{\#\textrm{times took action }a\textrm{ in state }s\textrm{ and got to }s'}{\#\textrm{times took action }a\textrm{ in state }s}}\]
</div>
<br>
<p><span class=""new-item item-g"">Q-learning</span> $Q$-learning is a model-free estimation of $Q$, which is done as follows:</p>
<div class=mobile-container>
\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]
</div>
<br>
<div class=""alert alert-warning"" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link href=teaching/cs-221/cheatsheet-states-models onclick=trackOutboundLink(this);>States-based Models cheatsheets</a>!</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
6,"مصفوفة الدقّة (confusion matrix) تستخدم مصفوفة الدقّة لأخذ تصور شامل عند تقييم أداء النموذج. وهي تعرّف كالتالي:

في سياق التصنيف الثنائي، هذه المقاييس (metrics) المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.

منحنى دقّة الأداء (ROC) منحنى دقّة الآداء، ويطلق عليه ROC، هو رسمة لمعدل التصنيفات الإيجابية الصحيحة (TPR) مقابل معدل التصنيفات الإيجابية الخاطئة (FPR) باستخدام قيم حد (threshold) متغيرة. هذه المقاييس ملخصة في الجدول التالي:

المقاييس الأساسية المقاييس التالية تستخدم في العادة لتقييم أداء نماذج التصنيف:

المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى) (AUC) المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى)، ويطلق عليها AUC أو AUROC، هي المساحة تحت ROC كما هو موضح في الرسمة التالية:

مقاييس الانحدار

المقاييس الأساسية إذا كان لدينا نموذج الانحدار $f$، فإن المقاييس التالية غالباً ما تستخدم لتقييم أداء النموذج:

المجموع الكلي للمربعات مجموع المربعات المُفسَّر مجموع المربعات المتبقي $\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$

مُعامل التحديد (coefficient of determination) مُعامل التحديد، وغالباً يرمز له بـ $R^2$ أو $r^2$، يعطي قياس لمدى مطابقة النموذج للنتائج الملحوظة، ويعرف كما يلي:

\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]

المقاييس الرئيسية المقاييس التالية تستخدم غالباً لتقييم أداء نماذج الانحدار، وذلك بأن يتم الأخذ في الحسبان عدد المتغيرات $n$ المستخدمة فيها:

معيار معامل مالوس (Mallow's) AIC BIC Adjusted $R^2$ $\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$ $\displaystyle2\Big[(n+2)-\log(L)\Big]$ $\displaystyle\log(m)(n+2)-2\log(L)$ $\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$

حيث $L$ هو الأرجحية، و $\widehat{\sigma}^2$ تقدير التباين الخاص بكل نتيجة.

اختيار النموذج

مفردات عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:

مجموعة تدريب مجموعة تحقق مجموعة اختبار • يتم تدريب النموذج

• غالباً 80% من مجموعة البيانات • يتم تقييم النموذج

• غالباً 20% من مجموعة البيانات

• يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير • النموذج يعطي التوقعات

• بيانات لم يسبق رؤيتها من قبل

بمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل. كما هو موضح في الشكل التالي:

التحقق المتقاطع (cross-validation) التحقق المتقاطع، وكذلك يختصر بـ CV، هو طريقة تستخدم لاختيار نموذج بحيث لا يعتمد بشكل كبير على مجموعة بيانات التدريب المبدأية. أنواع التحقق المتقاطع المختلفة ملخصة في الجدول التالي:

k-fold Leave-p-out • التدريب على $k-1$ جزء والتقييم باستخدام الجزء الباقي

• بشكل عام $k=5$ أو 10 • التدريب على $n-p$ عينة والتقييم باستخدام الـ $p$ عينات المتبقية

• الحالة $p=1$ يطلق عليها الإبقاء على واحد (leave-one-out)

الطريقة الأكثر استخداماً يطلق عليها التحقق المتقاطع س جزء/أجزاء ($k$-fold)، ويتم فيها تقسيم البيانات إلى $k$ جزء، بحيث يتم تدريب النموذج باستخدام $k-1$ والتحقق باستخدام الجزء المتبقي، ويتم تكرار ذلك $k$ مرة. يتم بعد ذلك حساب معدل الأخطاء في الأجزاء $k$ ويسمى خطأ التحقق المتقاطع.

ضبط (regularization) عمليه الضبط تهدف إلى تفادي فرط التخصيص (overfit) للنموذج، وهو بذلك يتعامل مع مشاكل التباين العالي. الجدول التالي يلخص أنواع وطرق الضبط الأكثر استخداماً:

LASSO Ridge Elastic Net • يقلص المُعاملات إلى 0

• جيد لاختيار المتغيرات يجعل المُعاملات أصغر المفاضلة بين اختيار المتغيرات والمُعاملات الصغيرة $...+\lambda||\theta||_1$

$\lambda\in\mathbb{R}$ $...+\lambda||\theta||_2^2$

$\lambda\in\mathbb{R}$ $...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$

$\lambda\in\mathbb{R},\alpha\in[0,1]$

التشخيصات

الانحياز (bias) الانحياز للنموذج هو الفرق بين التنبؤ المتوقع والنموذج الحقيقي الذي نحاول تنبؤه للبيانات المعطاة.

التباين (variance) تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.

موازنة الانحياز/التباين (bias/variance tradeoff) كلما زادت بساطة النموذج، زاد الانحياز، وكلما زاد تعقيد النموذج، زاد التباين.



Underfitting Just right Overfitting الأعراض • خطأ التدريب عالي

• خطأ التدريب قريب من خطأ الاختبار

• انحياز عالي • خطأ التدريب أقل بقليل من خطأ الاختبار • خطأ التدريب منخفض جداً

• خطأ التدريب أقل بكثير من خطأ الاختبار

• تباين عالي توضيح الانحدار توضيح التصنيف توضيح التعلم العميق العلاجات الممكنة • زيادة تعقيد النموذج

• إضافة المزيد من الخصائص

• تدريب لمدة أطول • إجراء الضبط (regularization)

• الحصول على المزيد من البيانات

تحليل الخطأ تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.

تحليل استئصالي (ablative analysis) التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية (baseline).","وهي تعرّف كالتالي:في سياق التصنيف الثنائي، هذه المقاييس (metrics) المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.
اختيار النموذجمفردات عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:مجموعة تدريب مجموعة تحقق مجموعة اختبار • يتم تدريب النموذج• غالباً 80% من مجموعة البيانات • يتم تقييم النموذج• غالباً 20% من مجموعة البيانات• يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير • النموذج يعطي التوقعات• بيانات لم يسبق رؤيتها من قبلبمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل.
التباين (variance) تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.
Underfitting Just right Overfitting الأعراض • خطأ التدريب عالي• خطأ التدريب قريب من خطأ الاختبار• انحياز عالي • خطأ التدريب أقل بقليل من خطأ الاختبار • خطأ التدريب منخفض جداً• خطأ التدريب أقل بكثير من خطأ الاختبار• تباين عالي توضيح الانحدار توضيح التصنيف توضيح التعلم العميق العلاجات الممكنة • زيادة تعقيد النموذج• إضافة المزيد من الخصائص• تدريب لمدة أطول • إجراء الضبط (regularization)• الحصول على المزيد من البياناتتحليل الخطأ تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.
تحليل استئصالي (ablative analysis) التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية (baseline).","['النموذج', 'تستخدم', 'تحت', 'نصائح', 'باستخدام', 'المقاييس', 'التدريب', 'يتم', 'مجموعة', 'البيانات', 'وحيل', 'خطأ']",ar,نصائح وحيل,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>نصائح وحيل - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>نصائح وحيل</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#classification-metrics>مقاييس التصنيف</a></div> <div class=dropdown-container> <a href=#classification-metrics><span>مصفوفة الدقّة</span></a> <a href=#classification-metrics><span>الضبط <span class=ltr>(accuracy)</span></span></a> <a href=#classification-metrics><span>الدقة <span class=ltr>(precision)</span> ،الاستدعاء <span class=ltr>    (recall)</span></span></a> <a href=#classification-metrics><span>درجة <span class=ltr>F1</span></span></a> <a href=#classification-metrics><span><span class=ltr>ROC</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regression-metrics>مقاييس الانحدار</a></div> <div class=dropdown-container> <a href=#regression-metrics><span>مربع <span class=ltr>R</span></span></a> <a href=#regression-metrics><span>معيار معامل مالوس <span class=ltr>(Mallow's)</span></span></a> <a href=#regression-metrics><span>معيار آكياك المعلوماتي <span class=ltr>(AIC)</span>     معيار المعلومات البايزي <span class=ltr>(BIC)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#model-selection>اختيار النموذج</a></div> <div class=dropdown-container> <a href=#model-selection><span>التحقق المتقاطع</span></a> <a href=#model-selection><span>الضبط</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#diagnostics>التشخيصات</a></div> <div class=dropdown-container> <a href=#diagnostics><span>موازنة الانحياز/التباين</span></a> <a href=#diagnostics><span>تحليل الخطأ/التحليل الاستئصالي</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-machine-learning-tips-and-tricks.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button><b>نصائح وحيل</b></button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع لنصائح وحيل تعلّم الآلة</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة فارس القنيعير. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<h2><a aria-hidden=true class=anchor href=#classification-metrics id=classification-metrics></a><div dir=rtl>مقاييس التصنيف</div></h2>
<div dir=rtl>
<p>في سياق التصنيف الثنائي، هذه المقاييس <span class=""ltr stick-together"">(metrics)</span> المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.</p>
<p><span class=""new-item item-b"">مصفوفة الدقّة <span class=""ltr stick-together"">(confusion matrix)</span></span> تستخدم مصفوفة الدقّة لأخذ تصور شامل عند تقييم أداء النموذج. وهي تعرّف كالتالي:</p>
</div>
<div class=mobile-container>
<span class=""ltr stick-together"">
</span><span class=""ltr stick-together"">
</span><table style=""margin-left: 10%"">
<colgroup><col width=120px>
<col width=50px>
<col width=200px>
<col width=200px>
</colgroup><tbody>
<tr style=""border-top: 0px"">
<td align=center colspan=2 rowspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""></td>
<td align=center colspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""><b>التصنيف المتوقع</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>+</b></td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>-</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center rowspan=2 style=""border: 0px""><b>التصنيف الفعلي</b></td><td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>+</b></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b><span class=""ltr stick-together"">TP</span></b><br><span class=""ltr stick-together"">True Positives</span></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b><span class=""ltr stick-together"">FN</span></b><br><span class=""ltr stick-together"">False Negatives</span><br><span class=""ltr stick-together"">Type II error</span></td>
</tr>
<tr style=""border-top: 0px""><td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>-</b></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b><span class=""ltr stick-together"">FP</span></b><br><span class=""ltr stick-together"">False Positives</span><br><span class=""ltr stick-together"">Type I error</span></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b><span class=""ltr stick-together"">TN</span></b><br><span class=""ltr stick-together"">True Negatives</span></td>
</tr>
</tbody>
</table>
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">المقاييس الأساسية</span> المقاييس التالية تستخدم في العادة لتقييم أداء نماذج التصنيف:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>المقياس</b></td>
<td align=center><b>المعادلة</b></td>
<td align=center><b>التفسير</b></td>
</tr>
<tr>
<td align=center>الضبط <span class=""ltr stick-together"">(accuracy)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$</td>
<td align=right>الأداء العام للنموذج</td>
</tr>
<tr>
<td align=center>الدقة <span class=""ltr stick-together"">(precision)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$</td>
<td align=right>دقّة التوقعات الإيجابية <span class=""ltr stick-together"">(positive)</span></td>
</tr>
<tr>
<td align=center>الاستدعاء <span class=""ltr stick-together"">(recall, sensitivity)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=right>تغطية عينات التوقعات الإيجابية الفعلية</td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">Specificity</span></td>
<td align=center>$\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=right>تغطية عينات التوقعات السلبية الفعلية</td>
</tr>
<tr>
<td align=center>درجة <span class=""ltr stick-together"">F1</span></td>
<td align=center>$\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$</td>
<td align=right>مقياس هجين مفيد للأصناف غير المتوازنة <span class=""ltr stick-together"">(unbalanced)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">منحنى دقّة الأداء <span class=""ltr stick-together"">(ROC)</span></span> منحنى دقّة الآداء، ويطلق عليه <span class=""ltr stick-together"">ROC</span>، هو رسمة لمعدل التصنيفات الإيجابية الصحيحة <span class=""ltr stick-together"">(TPR)</span> مقابل معدل التصنيفات الإيجابية الخاطئة <span class=""ltr stick-together"">(FPR)</span> باستخدام قيم حد <span class=""ltr stick-together"">(threshold)</span> متغيرة. هذه المقاييس ملخصة في الجدول التالي:</p>
</div>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>المقياس</b></td>
<td align=center><b>المعادلة</b></td>
<td align=center><b>مرادف</b></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">True Positive Rate</span><br><span class=""ltr stick-together"">TPR</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left><span class=""ltr stick-together"">Recall, sensitivity</span></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">False Positive Rate</span><br><span class=""ltr stick-together"">FPR</span></td>
<td align=center>$\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left><span class=""ltr stick-together"">1-specificity</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى) <span class=""ltr stick-together"">(AUC)</span></span> المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى)، ويطلق عليها  <span class=""ltr stick-together"">AUC</span> أو <span class=""ltr stick-together"">AUROC</span>، هي المساحة تحت <span class=""ltr stick-together"">ROC</span> كما هو موضح في الرسمة التالية:</p>
</div>
<br>
<div class=mobile-container>
<center>
<img alt=""ROC AUC"" class=img-responsive src=teaching/cs-229/illustrations/roc-auc-ar.png?d9ee2f725f841dd8d59e7cad68529e5a style=width:100%;max-width:700px>
</center>
</div>
<br>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#regression-metrics id=regression-metrics></a>مقاييس الانحدار</h2>
<p><span class=""new-item item-b"">المقاييس الأساسية</span> إذا كان لدينا نموذج الانحدار $f$، فإن المقاييس التالية غالباً ما تستخدم لتقييم أداء النموذج:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>المجموع الكلي للمربعات</b></td>
<td align=center><b>مجموع المربعات المُفسَّر</b></td>
<td align=center><b>مجموع المربعات المتبقي</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">مُعامل التحديد <span class=""ltr stick-together"">(coefficient of determination)</span></span> مُعامل التحديد، وغالباً يرمز له بـ $R^2$ أو $r^2$، يعطي قياس لمدى مطابقة النموذج للنتائج الملحوظة، ويعرف كما يلي:</p>
<div class=mobile-container>
\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]
</div>
<br>
<p><span class=""new-item item-r"">المقاييس الرئيسية</span> المقاييس التالية تستخدم غالباً لتقييم أداء نماذج الانحدار، وذلك بأن يتم الأخذ في الحسبان عدد المتغيرات $n$ المستخدمة فيها:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>معيار معامل مالوس <span class=""ltr stick-together"">(Mallow's)</span></b></td>
<td align=center><b><span class=""ltr stick-together"">AIC</span></b></td>
<td align=center><b><span class=""ltr stick-together"">BIC</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Adjusted</span> $R^2$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$</td>
<td align=center>$\displaystyle2\Big[(n+2)-\log(L)\Big]$</td>
<td align=center>$\displaystyle\log(m)(n+2)-2\log(L)$</td>
<td align=center>$\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>حيث $L$ هو الأرجحية، و $\widehat{\sigma}^2$ تقدير التباين الخاص بكل نتيجة.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#model-selection id=model-selection></a>اختيار النموذج</h2>
<p><span class=""new-item item-b"">مفردات</span> عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>مجموعة تدريب</b></td>
<td align=center><b>مجموعة تحقق</b></td>
<td align=center><b>مجموعة اختبار</b></td>
</tr>
<tr>
<td align=right>• يتم تدريب النموذج<br>
                 • غالباً 80% من مجموعة البيانات</td>
<td align=right>• يتم تقييم النموذج<br>
                 • غالباً 20% من مجموعة البيانات<br>
                 • يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير</td>
<td align=right>• النموذج يعطي التوقعات<br>
                 • بيانات لم يسبق رؤيتها من قبل</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>بمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل. كما هو موضح في الشكل التالي:</p>
<div class=mobile-container>
<center>
<img alt=""Partition of the dataset"" class=img-responsive src=teaching/cs-229/illustrations/train-val-test-ar.png?f2b9792f76bcec48b27fab6f3030cba0 style=width:100%;max-width:550px>
</center>
</div>
<br>
<p><span class=""new-item item-g"">التحقق المتقاطع <span class=""ltr stick-together"">(cross-validation)</span></span> التحقق المتقاطع، وكذلك يختصر بـ <span class=""ltr stick-together"">CV</span>، هو طريقة تستخدم لاختيار نموذج بحيث لا يعتمد بشكل كبير على مجموعة بيانات التدريب المبدأية. أنواع التحقق المتقاطع المختلفة ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=50%>
<col width=50%>
</colgroup><tbody>
<tr>
<td align=center><b><span class=""ltr stick-together"">k-fold</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Leave-p-out</span></b></td>
</tr>
<tr>
<td align=right>• التدريب على $k-1$ جزء والتقييم باستخدام الجزء الباقي<br>
                 • بشكل عام $k=5$ أو 10</td>
<td align=right>• التدريب على $n-p$ عينة والتقييم باستخدام الـ $p$ عينات المتبقية<br>
                 • الحالة $p=1$ يطلق عليها الإبقاء على واحد <span class=""ltr stick-together"">(leave-one-out)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<p>الطريقة الأكثر استخداماً يطلق عليها التحقق المتقاطع س جزء/أجزاء <span class=""ltr stick-together"">($k$-fold)</span>، ويتم فيها تقسيم البيانات إلى $k$ جزء، بحيث يتم تدريب النموذج باستخدام $k-1$ والتحقق باستخدام الجزء المتبقي، ويتم تكرار ذلك $k$ مرة. يتم بعد ذلك حساب معدل الأخطاء في الأجزاء $k$ ويسمى خطأ التحقق المتقاطع.</p>
<div class=mobile-container>
<center>
<img alt=Cross-validation class=img-responsive src=teaching/cs-229/illustrations/cross-validation-ar.png?65754a34e4e452acfc7c1f35b31acbb4 style=width:100%;max-width:770px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">ضبط <span class=""ltr stick-together"">(regularization)</span></span> عمليه الضبط تهدف إلى تفادي فرط التخصيص <span class=""ltr stick-together"">(overfit)</span> للنموذج، وهو بذلك يتعامل مع مشاكل التباين العالي. الجدول التالي يلخص أنواع وطرق الضبط الأكثر استخداماً:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b><span class=""ltr stick-together"">LASSO</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Ridge</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Elastic Net</span></b></td>
</tr>
<tr>
<td align=right>• يقلص المُعاملات إلى 0<br>• جيد لاختيار المتغيرات</td>
<td align=right>يجعل المُعاملات أصغر</td>
<td align=right>المفاضلة بين اختيار المتغيرات والمُعاملات الصغيرة</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive src=teaching/cs-229/illustrations/lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive src=teaching/cs-229/illustrations/ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt=""Elastic Net"" class=img-responsive src=teaching/cs-229/illustrations/elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#diagnostics id=diagnostics></a>التشخيصات</h2>
<p><span class=""new-item item-b"">الانحياز <span class=""ltr stick-together"">(bias)</span></span> الانحياز للنموذج هو الفرق بين التنبؤ المتوقع والنموذج الحقيقي الذي نحاول تنبؤه للبيانات المعطاة.</p>
<br>
<p><span class=""new-item item-b"">التباين <span class=""ltr stick-together"">(variance)</span></span> تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.</p>
<br>
<p><span class=""new-item item-r"">موازنة الانحياز/التباين <span class=""ltr stick-together"">(bias/variance tradeoff)</span></span> كلما زادت بساطة النموذج، زاد الانحياز، وكلما زاد تعقيد النموذج، زاد التباين.</p>
<div class=mobile-container>
<center>
<br>
<table style=""table-layout:fixed; width:100%; min-width:735px;"">
<colgroup>
<col style=width:19%>
<col style=width:27%>
<col style=width:27%>
<col style=width:27%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b><span class=""ltr stick-together"">Underfitting</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Just right</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Overfitting</span></b></td>
</tr>
<tr>
<td align=center><b>الأعراض</b></td>
<td align=right>• خطأ التدريب عالي <br>• خطأ التدريب قريب من خطأ الاختبار <br>• انحياز عالي</td>
<td align=right style=vertical-align:top>• خطأ التدريب أقل بقليل من خطأ الاختبار</td>
<td align=right>• خطأ التدريب منخفض جداً <br>• خطأ التدريب أقل بكثير من خطأ الاختبار <br>• تباين عالي</td>
</tr>
<tr>
<td align=center><b>توضيح الانحدار</b></td>
<td align=center><img alt=""Underfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-underfit.png?cd7fd5e4d334aa31d323b7d3f994a9df></td>
<td align=center><img alt=""Right fit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-just-right.png?4018112cca66bdc10de14e7e59702a32></td>
<td align=center><img alt=""Overfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-overfit.png?4133157c77ba0baff93110d1d0e73382></td>
</tr>
<tr>
<td align=center><b>توضيح التصنيف</b></td>
<td align=center><img alt=""Underfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-underfit.png?1f014836b68bfc74da1d767ca32783a3></td>
<td align=center><img alt=""Right fit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-just-right.png?67a70eb8c5fb11dd75d8e5035714a435></td>
<td align=center><img alt=""Overfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-overfit.png?64516ea4ed89dad5b422380ea1f8f350></td>
</tr>
<tr>
<td align=center><b>توضيح التعلم العميق</b></td>
<td align=center><img alt=""Underfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-underfit-ar.png?80c4ecf7dd48df97b9b9ef106890df3f></td>
<td align=center><img alt=""Right fit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-just-right-ar.png?e8e82e3385a23a414a3b41c87506db0c></td>
<td align=center><img alt=""Overfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-overfit-ar.png?5410d108c608de79536791696e5659bc></td>
</tr>
<tr>
<td align=center><b>العلاجات الممكنة</b></td>
<td align=right>• زيادة تعقيد النموذج<br>• إضافة المزيد من الخصائص<br>• تدريب لمدة أطول</td>
<td align=center style=""background: rgba(234, 234, 234, 1);""></td>
<td align=right>• إجراء الضبط <span class=""ltr stick-together"">(regularization)</span><br>• الحصول على المزيد من البيانات</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">تحليل الخطأ</span> تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.</p>
<br>
<p><span class=""new-item item-b"">تحليل استئصالي <span class=""ltr stick-together"">(ablative analysis)</span></span> التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية <span class=""ltr stick-together"">(baseline)</span>.</p>
<br>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
7,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Machine Learning tips and tricks cheatsheet Star

By Afshine Amidi and Shervine Amidi

Classification metrics

In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.

Confusion matrix The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:

Predicted class + - Actual class + TP

True Positives FN

False Negatives

Type II error - FP

False Positives

Type I error TN

True Negatives

Main metrics The following metrics are commonly used to assess the performance of classification models:

Metric Formula Interpretation Accuracy $\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$ Overall performance of model Precision $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$ How accurate the positive predictions are Recall

Sensitivity $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$ Coverage of actual positive sample Specificity $\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$ Coverage of actual negative sample F1 score $\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$ Hybrid metric useful for unbalanced classes

ROC The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:

Metric Formula Equivalent True Positive Rate

TPR $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$ Recall, sensitivity False Positive Rate

FPR $\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$ 1-specificity

AUC The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure:

Regression metrics

Basic metrics Given a regression model $f$, the following metrics are commonly used to assess the performance of the model:

Total sum of squares Explained sum of squares Residual sum of squares $\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$

Coefficient of determination The coefficient of determination, often noted $R^2$ or $r^2$, provides a measure of how well the observed outcomes are replicated by the model and is defined as follows:

Main metrics The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables $n$ that they take into consideration:

Mallow's Cp AIC BIC Adjusted $R^2$ $\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$ $\displaystyle2\Big[(n+2)-\log(L)\Big]$ $\displaystyle\log(m)(n+2)-2\log(L)$ $\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$

where $L$ is the likelihood and $\widehat{\sigma}^2$ is an estimate of the variance associated with each response.

Model selection

Vocabulary When selecting a model, we distinguish 3 different parts of the data that we have as follows:

Training set Validation set Testing set • Model is trained

• Usually 80% of the dataset • Model is assessed

• Usually 20% of the dataset

• Also called hold-out or development set • Model gives predictions

• Unseen data

Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:

Cross-validation Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below:

k-fold Leave-p-out • Training on $k-1$ folds and assessment on the remaining one

• Generally $k=5$ or $10$ • Training on $n-p$ observations and assessment on the $p$ remaining ones

• Case $p=1$ is called leave-one-out

The most commonly used method is called $k$-fold cross-validation and splits the training data into $k$ folds to validate the model on one fold while training the model on the $k-1$ other folds, all of this $k$ times. The error is then averaged over the $k$ folds and is named cross-validation error.

Regularization The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques:

LASSO Ridge Elastic Net • Shrinks coefficients to 0

• Good for variable selection Makes coefficients smaller Tradeoff between variable selection and small coefficients $...+\lambda||\theta||_1$

$\lambda\in\mathbb{R}$ $...+\lambda||\theta||_2^2$

$\lambda\in\mathbb{R}$ $...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$

$\lambda\in\mathbb{R},\alpha\in[0,1]$

Diagnostics

Bias The bias of a model is the difference between the expected prediction and the correct model that we try to predict for given data points.

Variance The variance of a model is the variability of the model prediction for given data points.

Bias/variance tradeoff The simpler the model, the higher the bias, and the more complex the model, the higher the variance.



Underfitting Just right Overfitting Symptoms • High training error

• Training error close to test error

• High bias • Training error slightly lower than test error • Very low training error

• Training error much lower than test error

• High variance Regression illustration Classification illustration Deep learning illustration Possible remedies • Complexify model

• Add more features

• Train longer • Perform regularization

• Get more data

Error analysis Error analysis is analyzing the root cause of the difference in performance between the current and the perfect models.

Ablative analysis Ablative analysis is analyzing the root cause of the difference in performance between the current and the baseline models.","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksMachine Learning tips and tricks cheatsheet StarBy Afshine Amidi and Shervine AmidiClassification metricsIn a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.
Confusion matrix The confusion matrix is used to have a more complete picture when assessing the performance of a model.
Regularization The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues.
Variance The variance of a model is the variability of the model prediction for given data points.
Bias/variance tradeoff The simpler the model, the higher the bias, and the more complex the model, the higher the variance.","['metrics', 'set', 'tips', 'performance', 'tricks', 'error', 'training', 'following', 'learning', 'cheatsheet', 'used', 'machine', 'data', 'model']",en,Machine Learning Tips and Tricks Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Machine Learning Tips and Tricks Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Tips and tricks</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#classification-metrics>Classification metrics</a></div> <div class=dropdown-container> <a href=#classification-metrics><span>Confusion matrix</span></a> <a href=#classification-metrics><span>Accuracy</span></a> <a href=#classification-metrics><span>Precision, recall</span></a> <a href=#classification-metrics><span>F1 score</span></a> <a href=#classification-metrics><span>ROC</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regression-metrics>Regression metrics</a></div> <div class=dropdown-container> <a href=#regression-metrics><span>R squared</span></a> <a href=#regression-metrics><span>Mallow's CP</span></a> <a href=#regression-metrics><span>AIC, BIC</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#model-selection>Model selection</a></div> <div class=dropdown-container> <a href=#model-selection><span>Cross-validation</span></a> <a href=#model-selection><span>Regularization</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#diagnostics>Diagnostics</a></div> <div class=dropdown-container> <a href=#diagnostics><span>Bias/variance tradeoff</span></a> <a href=#diagnostics><span>Error/ablative analysis</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button><b>Tips and tricks</b></button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Machine Learning tips and tricks cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#classification-metrics id=classification-metrics></a>Classification metrics</h2>
<p>In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.</p>
<p><span class=""new-item item-b"">Confusion matrix</span> The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:</p>
<div class=mobile-container>
<table style=""margin-left: 10%"">
<colgroup><col width=120px>
<col width=50px>
<col width=200px>
<col width=200px>
</colgroup><tbody>
<tr style=""border-top: 0px"">
<td align=center colspan=2 rowspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""></td>
<td align=center colspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""><b>Predicted</b> class</td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>+</b></td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>-</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center rowspan=2 style=""border: 0px""><b>Actual</b> class</td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>+</b></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b>TP</b><br>True Positives</td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b>FN</b><br>False Negatives<br>Type II error</td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>-</b></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b>FP</b><br>False Positives<br>Type I error</td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b>TN</b><br>True Negatives</td>
</tr>
</tbody>
</table>
</div>
<br>
<p><span class=""new-item item-r"">Main metrics</span> The following metrics are commonly used to assess the performance of classification models:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Metric</b></td>
<td align=center><b>Formula</b></td>
<td align=center><b>Interpretation</b></td>
</tr>
<tr>
<td align=center>Accuracy</td>
<td align=center>$\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$</td>
<td align=left>Overall performance of model</td>
</tr>
<tr>
<td align=center>Precision</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$</td>
<td align=left>How accurate the positive predictions are</td>
</tr>
<tr>
<td align=center>Recall<br>Sensitivity</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left>Coverage of actual positive sample</td>
</tr>
<tr>
<td align=center>Specificity</td>
<td align=center>$\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left>Coverage of actual negative sample</td>
</tr>
<tr>
<td align=center>F1 score</td>
<td align=center>$\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$</td>
<td align=left>Hybrid metric useful for unbalanced classes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">ROC</span> The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Metric</b></td>
<td align=center><b>Formula</b></td>
<td align=center><b>Equivalent</b></td>
</tr>
<tr>
<td align=center>True Positive Rate<br>TPR</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left>Recall, sensitivity</td>
</tr>
<tr>
<td align=center>False Positive Rate<br>FPR</td>
<td align=center>$\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left>1-specificity</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">AUC</span> The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure:</p>
<br>
<div class=mobile-container>
<center>
<img alt=""ROC AUC"" class=img-responsive src=teaching/cs-229/illustrations/roc-auc-en.png?d2dda6ec6e15f3e05597c058de976702 style=width:100%;max-width:700px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#regression-metrics id=regression-metrics></a>Regression metrics</h2>
<p><span class=""new-item item-b"">Basic metrics</span> Given a regression model $f$, the following metrics are commonly used to assess the performance of the model:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Total sum of squares</b></td>
<td align=center><b>Explained sum of squares</b></td>
<td align=center><b>Residual sum of squares</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Coefficient of determination</span> The coefficient of determination, often noted $R^2$ or $r^2$, provides a measure of how well the observed outcomes are replicated by the model and is defined as follows:</p>
\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]
<br>
<p><span class=""new-item item-r"">Main metrics</span> The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables $n$ that they take into consideration:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Mallow's Cp</b></td>
<td align=center><b>AIC</b></td>
<td align=center><b>BIC</b></td>
<td align=center><b>Adjusted $R^2$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$</td>
<td align=center>$\displaystyle2\Big[(n+2)-\log(L)\Big]$</td>
<td align=center>$\displaystyle\log(m)(n+2)-2\log(L)$</td>
<td align=center>$\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>where $L$ is the likelihood and $\widehat{\sigma}^2$ is an estimate of the variance associated with each response.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#model-selection id=model-selection></a>Model selection</h2>
<p><span class=""new-item item-b"">Vocabulary</span> When selecting a model, we distinguish 3 different parts of the data that we have as follows:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Training set</b></td>
<td align=center><b>Validation set</b></td>
<td align=center><b>Testing set</b></td>
</tr>
<tr>
<td align=left>• Model is trained<br>
                 • Usually 80% of the dataset</td>
<td align=left>• Model is assessed<br>
                 • Usually 20% of the dataset<br>
                 • Also called hold-out or development set</td>
<td align=left>• Model gives predictions<br>
                 • Unseen data</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:</p>
<div class=mobile-container>
<center>
<img alt=""Partition of the dataset"" class=img-responsive src=teaching/cs-229/illustrations/train-val-test-en.png?0949795ac868562e193efdc249ae1066 style=width:100%;max-width:550px>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Cross-validation</span> Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=50%>
<col width=50%>
</colgroup><tbody>
<tr>
<td align=center><b>k-fold</b></td>
<td align=center><b>Leave-p-out</b></td>
</tr>
<tr>
<td align=left>• Training on $k-1$ folds and assessment on the remaining one<br>
                 • Generally $k=5$ or $10$</td>
<td align=left>• Training on $n-p$ observations and assessment on the $p$ remaining ones<br>
                 • Case $p=1$ is called leave-one-out</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>The most commonly used method is called $k$-fold cross-validation and splits the training data into $k$ folds to validate the model on one fold while training the model on the $k-1$ other folds, all of this $k$ times. The error is then averaged over the $k$ folds and is named cross-validation error.</p>
<div class=mobile-container>
<center>
<img alt=Cross-validation class=img-responsive src=teaching/cs-229/illustrations/cross-validation-en.png?0f7ada4dc141d0af6b12bb21cc431471 style=width:100%;max-width:770px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Regularization</span> The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
  <colgroup>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>LASSO</b></td>
<td align=center><b>Ridge</b></td>
<td align=center><b>Elastic Net</b></td>
</tr>
<tr>
<td align=left>• Shrinks coefficients to 0<br>• Good for variable selection</td>
<td align=left>Makes coefficients smaller</td>
<td align=left>Tradeoff between variable selection and small coefficients</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive src=teaching/cs-229/illustrations/lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive src=teaching/cs-229/illustrations/ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt=""Elastic Net"" class=img-responsive src=teaching/cs-229/illustrations/elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#diagnostics id=diagnostics></a>Diagnostics</h2>
<p><span class=""new-item item-b"">Bias</span> The bias of a model is the difference between the expected prediction and the correct model that we try to predict for given data points.</p>
<br>
<p><span class=""new-item item-b"">Variance</span> The variance of a model is the variability of the model prediction for given data points.</p>
<br>
<p><span class=""new-item item-r"">Bias/variance tradeoff</span> The simpler the model, the higher the bias, and the more complex the model, the higher the variance.</p>
<div class=mobile-container>
<center>
<br>
<table style=""table-layout:fixed; width:100%; min-width:735px;"">
  <colgroup>
    <col style=width:19%>
    <col style=width:27%>
    <col style=width:27%>
    <col style=width:27%>
  </colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>Underfitting</b></td>
<td align=center><b>Just right</b></td>
<td align=center><b>Overfitting</b></td>
</tr>
<tr>
<td align=center><b>Symptoms</b></td>
<td align=left>• High training error <br>• Training error close to test error <br>• High bias</td>
<td align=left style=vertical-align:top>• Training error slightly lower than test error</td>
<td align=left>• Very low training error <br>• Training error much lower than test error <br>• High variance</td>
</tr>
<tr>
<td align=center><b>Regression illustration</b></td>
<td align=center><img alt=""Underfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-underfit.png?cd7fd5e4d334aa31d323b7d3f994a9df></td>
<td align=center><img alt=""Right fit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-just-right.png?4018112cca66bdc10de14e7e59702a32></td>
<td align=center><img alt=""Overfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-overfit.png?4133157c77ba0baff93110d1d0e73382></td>
</tr>
<tr>
<td align=center><b>Classification illustration</b></td>
<td align=center><img alt=""Underfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-underfit.png?1f014836b68bfc74da1d767ca32783a3></td>
<td align=center><img alt=""Right fit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-just-right.png?67a70eb8c5fb11dd75d8e5035714a435></td>
<td align=center><img alt=""Overfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-overfit.png?64516ea4ed89dad5b422380ea1f8f350></td>
</tr>
<tr>
<td align=center><b>Deep learning illustration</b></td>
<td align=center><img alt=""Underfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-underfit-en.png?028697ac0c3ffff2a7a64edbab4dd61a></td>
<td align=center><img alt=""Right fit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-just-right-en.png?5accb2fc5bfed4b0e328fa798b1dd47c></td>
<td align=center><img alt=""Overfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-overfit-en.png?026ff9256072273492de106ed7a9857f></td>
</tr>
<tr>
<td align=center><b>Possible remedies</b></td>
<td align=left>• Complexify model<br>• Add more features<br>• Train longer</td>
<td align=center style=""background: rgba(234, 234, 234, 1);""></td>
<td align=left>• Perform regularization<br>• Get more data</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Error analysis</span> Error analysis is analyzing the root cause of the difference in performance between the current and the perfect models.</p>
<br>
<p><span class=""new-item item-b"">Ablative analysis</span> Ablative analysis is analyzing the root cause of the difference in performance between the current and the baseline models.</p>
<br>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
8,"مقدمة للتعلّم المُوَجَّه

إذا كان لدينا مجموعة من نقاط البيانات $\{x^{(1)}, ..., x^{(m)}\}$ مرتبطة بمجموعة مخرجات $\{y^{(1)}, ..., y^{(m)}\}$، نريد أن نبني مُصَنِّف يتعلم كيف يتوقع $y$ من $x$.

نوع التوقّع أنواع نماذج التوقّع المختلفة موضحة في الجدول التالي:

الانحدار (regression) التصنيف (classification) المُخرَج مستمر صنف أمثلة انحدار خطّي (linear regression) انحدار لوجستي (logistic regression) , آلة المتجهات الداعمة (SVM) , بايز البسيط (Naive Bayes)

نوع النموذج أنواع النماذج المختلفة موضحة في الجدول التالي:

نموذج تمييزي (discriminative) نموذج توليدي (generative) الهدف التقدير المباشر لـ $P(y|x)$ تقدير $P(x|y)$ ثم استنتاج $P(y|x)$ ماذا يتعلم حدود القرار التوزيع الاحتمالي للبيانات توضيح أمثلة الانحدار (regression) , آلة المتجهات الداعمة (SVM) GDA , بايز البسيط (Naive Bayes)

الرموز ومفاهيم أساسية

الفرضية (hypothesis) الفرضية، ويرمز لها بـ $h_\theta$، هي النموذج الذي نختاره. إذا كان لدينا المدخل $x^{(i)}$، فإن المخرج الذي سيتوقعه النموذج هو $h_\theta(x^{(i)})$.

دالة الخسارة (loss function) دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما. الجدول التالي يحتوي على بعض دوال الخسارة الشائعة:

خطأ أصغر تربيع

(least squared error) خسارة لوجستية

(logistic loss) خسارة مفصلية

(Hinge loss) الانتروبيا التقاطعية

(cross-entropy) $\displaystyle\frac{1}{2}(y-z)^2$ $\displaystyle\log(1+\exp(-yz))$ $\displaystyle\max(0,1-yz)$ $\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$ الانحدار الخطّي

(linear regression) الانحدار اللوجستي

(logistic regression) آلة المتجهات الداعمة

(SVM) الشبكات العصبية

(neural network)

دالة التكلفة (cost function) دالة التكلفة $J$ تستخدم عادة لتقييم أداء نموذج ما، ويتم تعريفها مع دالة الخسارة $L$ كالتالي:

\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]

النزول الاشتقاقي (gradient descent) لنعرّف معدل التعلّم $\alpha\in\mathbb{R}$، يمكن تعريف القانون الذي يتم تحديث خوارزمية النزول الاشتقاقي من خلاله باستخدام معدل التعلّم ودالة التكلفة $J$ كالتالي:

\[\boxed{\theta\longleftarrow\theta-\alpha

abla J(\theta)}\]

ملاحظة: في النزول الاشتقاقي العشوائي (stochastic gradient descent, SGD) يتم تحديث المُعاملات (parameters) بناءاً على كل عينة تدريب على حدة، بينما في النزول الاشتقاقي الحُزَمي (batch gradient descent) يتم تحديثها باستخدام حُزَم من عينات التدريب.

الأرجحية (likelihood) تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم (maximizing) الأرجحية. عملياً يتم استخدام الأرجحية اللوغاريثمية (log-likelihood) $\ell(\theta)=\log(L(\theta))$ حيث أنها أسهل في التحسين (optimize). فيكون لدينا:

\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]

خوارزمية نيوتن (Newton's algorithm) خوارزمية نيوتن هي طريقة حسابية للعثور على $\theta$ بحيث يكون $\ell'(\theta)=0$. قاعدة التحديث للخوارزمية كالتالي:

\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]

ملاحظة: هناك خوارزمية أعم وهي متعددة الأبعاد (multidimensional)، يطلق عليها خوارزمية نيوتن-رافسون (Newton-Raphson)، ويتم تحديثها عبر القانون التالي:

\[\theta\leftarrow\theta-\left(

abla_\theta^2\ell(\theta)\right)^{-1}

abla_\theta\ell(\theta)\]

النماذج الخطيّة (linear models)

الانحدار الخطّي (linear regression)

هنا نفترض أن $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$

المعادلة الطبيعية/الناظمية (normal) إذا كان لدينا المصفوفة $X$، القيمة $\theta$ التي تقلل من دالة التكلفة يمكن حلها رياضياً بشكل مغلق (closed-form) عن طريق:

\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]

خوارزمية أصغر معدل تربيع LMS إذا كان لدينا معدل التعلّم $\alpha$، فإن قانون التحديث لخوارزمية أصغر معدل تربيع (Least Mean Squares, LMS) لمجموعة بيانات من $m$ عينة، ويطلق عليه قانون تعلم ويدرو-هوف (Widrow-Hoff)، كالتالي:

\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]

ملاحظة: قانون التحديث هذا يعتبر حالة خاصة من النزول الاشتقاقي (gradient descent).

الانحدار الموزون محليّاً (LWR) الانحدار الموزون محليّاً (Locally Weighted Regression)، ويعرف بـ LWR، هو نوع من الانحدار الخطي يَزِن كل عينة تدريب أثناء حساب دالة التكلفة باستخدام $w^{(i)}(x)$، التي يمكن تعريفها باستخدام المُدخل (parameter) $\tau\in\mathbb{R}$ كالتالي:

\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]

التصنيف والانحدار اللوجستي

دالة سيجمويد (sigmoid) دالة سيجمويد $g$، وتعرف كذلك بالدالة اللوجستية، تعرّف كالتالي:

\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]

الانحدار اللوجستي (logistic regression) نفترض هنا أن $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. فيكون لدينا:

\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]

ملاحظة: ليس هناك حل رياضي مغلق للانحدار اللوجستي.

انحدار سوفت ماكس (softmax) ويطلق عليه الانحدار اللوجستي متعدد الأصناف (multiclass logistic regression)، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين. في العرف يتم تعيين $\theta_K=0$، بحيث تجعل مُدخل بيرنوللي (Bernoulli) $\phi_i$ لكل فئة $i$ يساوي:

\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]

النماذج الخطية العامة (Generalized Linear Models, GLM)

العائلة الأُسيّة (Exponential family) يطلق على صنف من التوزيعات (distributions) بأنها تنتمي إلى العائلة الأسيّة إذا كان يمكن كتابتها بواسطة مُدخل قانوني (canonical parameter) $\eta$، إحصاء كافٍ (sufficient statistic) $T(y)$، ودالة تجزئة لوغاريثمية $a(\eta)$، كالتالي:

\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]

ملاحظة: كثيراً ما سيكون $T(y)=y$. كذلك فإن $\exp(-a(\eta))$ يمكن أن تفسر كمُدخل تسوية (normalization) للتأكد من أن الاحتمالات يكون حاصل جمعها يساوي واحد.

تم تلخيص أكثر التوزيعات الأسيّة استخداماً في الجدول التالي:

التوزيع $\eta$ $T(y)$ $a(\eta)$ $b(y)$ بِرنوللي (Bernoulli) $\log\left(\frac{\phi}{1-\phi}\right)$ $y$ $\log(1+\exp(\eta))$ $1$ جاوسي (Gaussian) $\mu$ $y$ $\frac{\eta^2}{2}$ $\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$ بواسون (Poisson) $\log(\lambda)$ $y$ $e^{\eta}$ $\displaystyle\frac{1}{y!}$ هندسي (Geometric) $\log(1-\phi)$ $y$ $\log\left(\frac{e^\eta}{1-e^\eta}\right)$ $1$

افتراضات GLMs تهدف النماذج الخطيّة العامة (GLM) إلى توقع المتغير العشوائي $y$ كدالة لـ $x\in\mathbb{R}^{n+1}$، وتستند إلى ثلاثة افتراضات:

$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$ $(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$ $(3)\quad\boxed{\eta=\theta^Tx}$

ملاحظة: أصغر تربيع (least squares) الاعتيادي و الانحدار اللوجستي يعتبران من الحالات الخاصة للنماذج الخطيّة العامة.

آلة المتجهات الداعمة (Support Vector Machines)

تهدف آلة المتجهات الداعمة (SVM) إلى العثور على الخط الذي يعظم أصغر مسافة إليه:

مُصنِّف الهامش الأحسن (optimal margin classifier) يعرَّف مُصنِّف الهامش الأحسن $h$ كالتالي:

\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]

حيث $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ هو الحل لمشكلة التحسين (optimization) التالية:

\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\text{و }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]

ملاحظة: يتم تعريف الخط بهذه المعادلة $\boxed{w^Tx-b=0}$.

الخسارة المفصلية (Hinge loss) تستخدم الخسارة المفصلية في حل SVM ويعرف على النحو التالي:

\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]

النواة (kernel) إذا كان لدينا دالة ربط الخصائص (features) $\phi$، يمكننا تعريف النواة $K$ كالتالي:

\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]

عملياً، يمكن أن تُعَرَّف الدالة $K$ عن طريق المعادلة $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$، ويطلق عليها النواة الجاوسية (Gaussian kernel)، وهي تستخدم بكثرة.

ملاحظة: نقول أننا نستخدم ""حيلة النواة"" (kernel trick) لحساب دالة التكلفة عند استخدام النواة لأننا في الحقيقة لا نحتاج أن نعرف التحويل الصريح $\phi$، الذي يكون في الغالب شديد التعقيد. ولكن، نحتاج أن فقط أن نحسب القيم $K(x,z)$.

اللّاغرانجي (Lagrangian) يتم تعريف اللّاغرانجي $\mathcal{L}(w,b)$ على النحو التالي:

\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]

ملاحظة: المعامِلات (coefficients) $\beta_i$ يطلق عليها مضروبات لاغرانج (Lagrange multipliers).

التعلم التوليدي (generative learning)

النموذج التوليدي في البداية يحاول أن يتعلم كيف تم توليد البيانات عن طريق تقدير $P(x|y)$، التي يمكن حينها استخدامها لتقدير $P(y|x)$ باستخدام قانون بايز (Bayes' rule).

تحليل التمايز الجاوسي (Gaussian Discriminant Analysis)

الإطار تحليل التمايز الجاوسي يفترض أن $y$ و $x|y=0$ و $x|y=1$ بحيث يكونوا كالتالي:

$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$ $(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$ $(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$

التقدير الجدول التالي يلخص التقديرات التي يمكننا التوصل لها عند تعظيم الأرجحية (likelihood):

$\widehat{\phi}$ $\widehat{\mu_j}\quad{\small(j=0,1)}$ $\widehat{\Sigma}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$ $\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$

بايز البسيط (Naive Bayes)

الافتراض يفترض نموذج بايز البسيط أن جميع الخصائص لكل عينة بيانات مستقلة (independent):

\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]

الحل تعظيم الأرجحية اللوغاريثمية (log-likelihood) يعطينا الحلول التالية إذا كان $k\in\{0,1\},l\in[\![1,L]\!]$: $k\in\{0,1\},l\in[\![1,L]\!]$

\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ و }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ و }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]

ملاحظة: بايز البسيط يستخدم بشكل واسع لتصنيف النصوص واكتشاف البريد الإلكتروني المزعج.

الطرق الشجرية (tree-based) والتجميعية (ensemble)

هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار (regression) والتصنيف (classification).

التصنيف والانحدار الشجري (CART) والاسم الشائع له أشجار القرار (decision trees)، يمكن أن يمثل كأشجار ثنائية (binary trees). من المزايا لهذه الطريقة إمكانية تفسيرها بسهولة.

الغابة العشوائية (random forest) هي أحد الطرق الشجرية التي تستخدم عدداً كبيراً من أشجار القرار مبنية باستخدام مجموعة عشوائية من الخصائص. بخلاف شجرة القرار البسيطة لا يمكن تفسير النموذج بسهولة، ولكن أدائها العالي جعلها أحد الخوارزمية المشهورة.

ملاحظة: أشجار القرار نوع من الخوارزميات التجميعية (ensemble).

التعزيز (boosting) فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي. الطرق الأساسية ملخصة في الجدول التالي:

التعزيز التَكَيُّفي (adaptive boosting) التعزيز الاشتقاقي (gradient boosting) • يتم التركيز على مواطن الخطأ لتحسين النتيجة في الخطوة التالية. • يتم تدريب خوارزميات التعلم الضعيفة على الأخطاء المتبقية.

طرق أخرى غير بارامترية (non-parametric)

خوارزمية أقرب الجيران ($k$-nearest neighbors) تعتبر خوارزمية أقرب الجيران، وتعرف بـ $k$-NN، طريقة غير بارامترية، حيث يتم تحديد نتيجة عينة من البيانات من خلال عدد $k$ من البيانات المجاورة في مجموعة التدريب. ويمكن استخدامها للتصنيف والانحدار.

ملاحظة: كلما زاد المُدخل $k$، كلما زاد الانحياز (bias)، وكلما نقص $k$، زاد التباين (variance).

نظرية التعلُّم

حد الاتحاد (union bound) لنجعل $A_1, ..., A_k$ تمثل $k$ حدث. فيكون لدينا:

\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]

متراجحة هوفدينج (Hoeffding) لنجعل $Z_1, .., Z_m$ تمثل $m$ متغير مستقلة وموزعة بشكل مماثل (iid) مأخوذة من توزيع بِرنوللي (Bernoulli distribution) ذا مُدخل $\phi$. لنجعل $\widehat{\phi}$ متوسط العينة (sample mean) و $\gamma>0$ ثابت. فيكون لدينا:

\[\boxed{P(|\phi-\widehat{\phi}|>\gamma)\leqslant2\exp(-2\gamma^2m)}\]

ملاحظة: هذه المتراجحة تعرف كذلك بحد تشرنوف (Chernoff bound).

خطأ التدريب ليكن لدينا المُصنِّف $h$، يمكن تعريف خطأ التدريب $\widehat{\epsilon}(h)$، ويعرف كذلك بالخطر التجريبي أو الخطأ التجريبي، كالتالي:

\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})

eq y^{(i)}\}}}\]

تقريباً صحيح احتمالياً (Probably Approximately Correct, PAC) هو إطار يتم من خلاله إثبات العديد من نظريات التعلم، ويحتوي على الافتراضات التالية:

- مجموعتي التدريب والاختبار يتبعان نفس التوزيع.

- عينات التدريب تؤخذ بشكل مستقل.

مجموعة تكسيرية (shattering set) إذا كان لدينا المجموعة $S=\{x^{(1)},...,x^{(d)}\}$، ومجموعة مُصنٍّفات $\mathcal{H}$، نقول أن $\mathcal{H}$ تكسر $S$ (H shatters S) إذا كان لكل مجموعة علامات (labels) $\{y^{(1)}, ..., y^{(d)}\}$ لدينا:

\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]

مبرهنة الحد الأعلى (upper bound theorem) لنجعل $\mathcal{H}$ فئة فرضية محدودة (finite hypothesis class) بحيث $|\mathcal{H}|=k$، و $\delta$ وحجم العينة $m$ ثابتين. حينها سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:

\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]

بُعْد فابنيك تشرفونيكس (Vapnik-Chervonenkis, VC) لفئة فرضية غير محدودة (infinite hypothesis class) $\mathcal{H}$، ويرمز له بـ $\textrm{VC}(\mathcal{H})$، هو حجم أكبر مجموعة (set) التي تم تكسيرها بواسطة $\mathcal{H}$ (shattered by $\mathcal{H}$).

مبرهنة فابنيك (Vapnik theorem) ليكن لدينا $\mathcal{H}$، مع $\textrm{VC}(\mathcal{H})=d$ وعدد عيّنات التدريب $m$. سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:

\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]","دالة الخسارة (loss function) دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما.
الأرجحية (likelihood) تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم (maximizing) الأرجحية.
انحدار سوفت ماكس (softmax) ويطلق عليه الانحدار اللوجستي متعدد الأصناف (multiclass logistic regression)، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين.
الطرق الشجرية (tree-based) والتجميعية (ensemble)هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار (regression) والتصنيف (classification).
التعزيز (boosting) فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي.","['لدينا', 'regression', 'أن', 'إذا', 'الانحدار', 'يتم', 'y', 'تعلم', 'دالة', 'الجدول', 'باستخدام', 'موجه']",ar,تعلّم موجَّه,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>تعلّم موجَّه - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-supervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلّم موجَّه</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>مقدمة</a></div> <div class=dropdown-container> <a href=#introduction><span>نوع التوقع</span></a> <a href=#introduction><span>نوع النموذج</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#notations>الرموز ومفاهيم أساسية</a></div> <div class=dropdown-container> <a href=#notations><span>دالة الخسارة</span></a> <a href=#notations><span>النزول الاشتقاقي</span></a> <a href=#notations><span>الأرجحية</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#linear-models>النماذج الخطيّة</a></div> <div class=dropdown-container> <a href=#linear-models><span>الانحدار الخطّي</span></a> <a href=#linear-models><span>الانحدار اللوجستي</span></a> <a href=#linear-models><span>النماذج الخطية العامة</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#svm>آلة المتجهات الداعمة <span class=ltr>(SVM)</span></a></div> <div class=dropdown-container> <a href=#svm><span>مُصنِّف الهامش الأحسن</span></a> <a href=#svm><span>الفرق المفصلي</span></a> <a href=#svm><span>النواة</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#generative-learning>التعلم التوليدي</a></div> <div class=dropdown-container> <a href=#generative-learning><span>تحليل التمايز الجاوسي</span></a> <a href=#generative-learning><span>بايز البسيط</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#tree>الطرق الشجرية والتجميعية</a></div> <div class=dropdown-container> <a href=#tree><span>التصنيف والانحدار الشجري    <span class=ltr>(CART)</span></span></a> <a href=#tree><span>الغابة العشوائية <span class=ltr>(random forest)</span></span></a> <a href=#tree><span>التعزيز <span class=ltr>(boosting)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#other>طرق أخرى</a></div> <div class=dropdown-container> <a href=#other><span>خوارزمية أقرب الجيران <span class=ltr>(k-NN)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#learning-theory>نظرية التعلُّم</a></div> <div class=dropdown-container> <a href=#learning-theory><span>متراجحة هوفدنك</span></a> <a href=#learning-theory><span>تقريباً صحيح احتمالياً <span class=ltr>(PAC)</span></span></a> <a href=#learning-theory><span>بُعْد فابنيك-تشرفونيكس <span class=ltr>(VC     dimension)</span></span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-supervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button><b>تعلّم موجَّه</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع للتعلّم المُوَجَّه
</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة فارس القنيعير. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>مقدمة للتعلّم المُوَجَّه</h2>
<p>إذا كان لدينا مجموعة من نقاط البيانات $\{x^{(1)}, ..., x^{(m)}\}$ مرتبطة بمجموعة مخرجات $\{y^{(1)}, ..., y^{(m)}\}$، نريد أن نبني مُصَنِّف يتعلم كيف يتوقع $y$ من $x$.</p>
<p><span class=""new-item item-b"">نوع التوقّع</span> أنواع نماذج التوقّع المختلفة موضحة في الجدول التالي:</p>
<div class=mobile-container>
<center>
  <table style=""table-layout:fixed; width:100%; min-width:300px;"">
  <colgroup>
  <col style=width:120px>
  <col style=width:50%>
  <col style=width:50%>
  </colgroup>
<tbody>
<tr>
<td align=center><b></b></td>
<td align=center><b>الانحدار <span class=""ltr stick-together"">(regression)</span></b></td>
<td align=center><b>التصنيف <span class=""ltr stick-together"">(classification)</span></b></td>
</tr>
<tr>
<td align=center><b>المُخرَج</b></td>
<td align=center>مستمر</td>
<td align=center>صنف</td>
</tr>
<tr>
<td align=center><b>أمثلة</b></td>
<td align=center>انحدار خطّي <span class=""ltr stick-together"">(linear regression)</span></td>
<td align=center>انحدار لوجستي <span class=""ltr stick-together"">(logistic regression)</span>, آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span>, بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">نوع النموذج</span> أنواع النماذج المختلفة موضحة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:300px;"">
<colgroup>
<col style=width:120px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>نموذج تمييزي <span class=""ltr stick-together"">(discriminative)</span></b></td>
<td align=center><b>نموذج توليدي <span class=""ltr stick-together"">(generative)</span></b></td>
</tr>
<tr>
<td align=center><b>الهدف</b></td>
<td align=right>التقدير المباشر لـ $P(y|x)$</td>
<td align=right>تقدير $P(x|y)$ ثم استنتاج $P(y|x)$</td>
</tr>
<tr>
<td align=center><b>ماذا يتعلم</b></td>
<td align=right>حدود القرار</td>
<td align=right>التوزيع الاحتمالي للبيانات</td>
</tr>
<tr>
<td align=center><b>توضيح</b></td>
<td align=center style=""width: 41%;""><img alt=""Discriminative model"" class=img-responsive src=teaching/cs-229/illustrations/discriminative-model.png?767b34c21d43a4fd8b59683578e132f9></td>
<td align=center style=""width: 41%;""><img alt=""Generative model"" class=img-responsive src=teaching/cs-229/illustrations/generative-model.png?df0642cec6e99ac162cd4848d26f41c3></td>
</tr>
<tr>
<td align=center><b>أمثلة</b></td>
<td align=right>الانحدار <span class=""ltr stick-together"">(regression)</span>, آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span></td>
<td align=right><span class=""ltr stick-together"">GDA</span>, بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>الرموز ومفاهيم أساسية</h2>
<p><span class=""new-item item-b"">الفرضية <span class=""ltr stick-together"">(hypothesis)</span></span> الفرضية، ويرمز لها بـ $h_\theta$، هي النموذج الذي نختاره. إذا كان لدينا المدخل $x^{(i)}$، فإن المخرج الذي سيتوقعه النموذج هو $h_\theta(x^{(i)})$.</p>
<br>
<p><span class=""new-item item-r"">دالة الخسارة <span class=""ltr stick-together"">(loss function)</span></span> دالة الخسارة هي الدالة $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ التي تأخذ كمدخلات القيمة المتوقعة $z$ والقيمة الحقيقية $y$ وتعطينا الاختلاف بينهما. الجدول التالي يحتوي على بعض دوال الخسارة الشائعة:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:820px;"">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>خطأ أصغر تربيع <br><span class=""ltr stick-together"">(least squared error)</span></b></td>
<td align=center><b>خسارة لوجستية <br><span class=""ltr stick-together"">(logistic loss)</span></b></td>
<td align=center><b>خسارة مفصلية <br><span class=""ltr stick-together"">(Hinge loss)</span></b></td>
<td align=center><b>الانتروبيا التقاطعية <br><span class=""ltr stick-together"">(cross-entropy)</span></b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{2}(y-z)^2$</td>
<td align=center>$\displaystyle\log(1+\exp(-yz))$</td>
<td align=center>$\displaystyle\max(0,1-yz)$</td>
<td align=center style=vertical-align:middle><div id=some_math style=font-size:75%>$\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$</div></td>
</tr>
<tr>
<td align=center style=""width: 25%;""><img alt=""Least squared error"" class=img-responsive src=teaching/cs-229/illustrations/least-square-error.png?63fef2552284b0dc15f27d1ef0b79fea></td>
<td align=center style=""width: 25%;""><img alt=""Logistic loss"" class=img-responsive src=teaching/cs-229/illustrations/logistic-loss.png?1bc1cb6d682c1bbfb978ec894afdf588></td>
<td align=center style=""width: 25%;""><img alt=""Hinge loss"" class=img-responsive src=teaching/cs-229/illustrations/hinge-loss.png?3f1b26410c446f52885dcc5266937c84></td>
<td align=center style=""width: 25%;""><img alt=""Cross entropy"" class=img-responsive src=teaching/cs-229/illustrations/cross-entropy.png?037ea4073873c9be4a7de099dac6d3b5></td>
</tr>
<tr>
<td align=center>الانحدار الخطّي <br><span class=""ltr stick-together"">(linear regression)</span></td>
<td align=center>الانحدار اللوجستي <br><span class=""ltr stick-together"">(logistic regression)</span></td>
<td align=center>آلة المتجهات الداعمة <br><span class=""ltr stick-together"">(SVM)</span></td>
<td align=center>الشبكات العصبية <br><span class=""ltr stick-together"">(neural network)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">دالة التكلفة <span class=""ltr stick-together"">(cost function)</span></span> دالة التكلفة $J$ تستخدم عادة لتقييم أداء نموذج ما، ويتم تعريفها مع دالة الخسارة $L$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]
</div>
<br>
<p><span class=""new-item item-r"">النزول الاشتقاقي <span class=""ltr stick-together"">(gradient descent)</span></span> لنعرّف معدل التعلّم $\alpha\in\mathbb{R}$، يمكن تعريف القانون الذي يتم تحديث خوارزمية النزول الاشتقاقي من خلاله باستخدام معدل التعلّم ودالة التكلفة $J$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{\theta\longleftarrow\theta-\alpha\nabla J(\theta)}\]
</div>
<br>
<center>
<img alt=""Gradient descent"" class=img-responsive src=teaching/cs-229/illustrations/gradient-descent.png?01662c4a8147a55ba09f4f5c047641ba style=width:100%;max-width:500px>
</center>
<br>
<p><span class=remark>ملاحظة: في النزول الاشتقاقي العشوائي <span class=""ltr stick-together"">(stochastic gradient descent, SGD)</span> يتم تحديث المُعاملات <span class=""ltr stick-together"">(parameters)</span> بناءاً على كل عينة تدريب على حدة، بينما في النزول الاشتقاقي الحُزَمي <span class=""ltr stick-together"">(batch gradient descent)</span> يتم تحديثها باستخدام حُزَم من عينات التدريب.</span></p>
<br>
<p><span class=""new-item item-b"">الأرجحية <span class=""ltr stick-together"">(likelihood)</span></span> تستخدم أرجحية النموذج $L(\theta)$، حيث أن $\theta$ هي المُدخلات، للبحث عن المُدخلات $\theta$ الأحسن عن طريق تعظيم <span class=""ltr stick-together"">(maximizing)</span> الأرجحية. عملياً يتم استخدام الأرجحية اللوغاريثمية <span class=""ltr stick-together"">(log-likelihood)</span> $\ell(\theta)=\log(L(\theta))$ حيث أنها أسهل في التحسين (optimize). فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]
</div>
<br>
<p><span class=""new-item item-r"">خوارزمية نيوتن <span class=""ltr stick-together"">(Newton's algorithm)</span></span> خوارزمية نيوتن هي طريقة حسابية للعثور على $\theta$ بحيث يكون $\ell'(\theta)=0$. قاعدة التحديث للخوارزمية كالتالي:</p>
<div class=mobile-container>
\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]
</div>
<p><span class=remark>ملاحظة: هناك خوارزمية أعم وهي متعددة الأبعاد <span class=""ltr stick-together"">(multidimensional)</span>، يطلق عليها خوارزمية نيوتن-رافسون <span class=""ltr stick-together"">(Newton-Raphson)</span>، ويتم تحديثها عبر القانون التالي:</span></p>
<div class=mobile-container>
\[\theta\leftarrow\theta-\left(\nabla_\theta^2\ell(\theta)\right)^{-1}\nabla_\theta\ell(\theta)\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#linear-models id=linear-models></a>النماذج الخطيّة <span class=""ltr stick-together"">(linear models)</span></h2>
<h3>الانحدار الخطّي <span class=""ltr stick-together"">(linear regression)</span></h3>
<p>هنا نفترض أن $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$</p>
<p><span class=""new-item item-g"">المعادلة الطبيعية/الناظمية <span class=""ltr stick-together"">(normal)</span></span> إذا كان لدينا المصفوفة $X$، القيمة $\theta$ التي تقلل من دالة التكلفة يمكن حلها رياضياً بشكل مغلق <span class=""ltr stick-together"">(closed-form)</span> عن طريق:</p>
<div class=mobile-container>
\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]
</div>
<br>
<p><span class=""new-item item-g"">خوارزمية أصغر معدل تربيع <span class=""ltr stick-together"">LMS</span></span> إذا كان لدينا معدل التعلّم $\alpha$، فإن قانون التحديث لخوارزمية أصغر معدل تربيع <span class=""ltr stick-together"">(Least Mean Squares, LMS)</span> لمجموعة بيانات من $m$ عينة، ويطلق عليه قانون تعلم ويدرو-هوف <span class=""ltr stick-together"">(Widrow-Hoff)</span>، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]
</div>
<p><span class=remark>ملاحظة: قانون التحديث هذا يعتبر حالة خاصة من النزول الاشتقاقي <span class=""ltr stick-together"">(gradient descent)</span>.</span></p>
<br>
<p><span class=""new-item item-b"">الانحدار الموزون محليّاً <span class=""ltr stick-together"">(LWR)</span></span> الانحدار الموزون محليّاً <span class=""ltr stick-together"">(Locally Weighted Regression)</span>، ويعرف بـ <span class=""ltr stick-together"">LWR</span>، هو نوع من الانحدار الخطي يَزِن كل عينة تدريب أثناء حساب دالة التكلفة باستخدام $w^{(i)}(x)$، التي يمكن تعريفها باستخدام المُدخل <span class=""ltr stick-together"">(parameter)</span> $\tau\in\mathbb{R}$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]
</div>
<br>
<h3>التصنيف والانحدار اللوجستي</h3>
<p><span class=""new-item item-b"">دالة سيجمويد <span class=""ltr stick-together"">(sigmoid)</span></span> دالة سيجمويد $g$، وتعرف كذلك بالدالة اللوجستية، تعرّف كالتالي:</p>
<div class=mobile-container>
\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]
</div>
<br>
<p><span class=""new-item item-b"">الانحدار اللوجستي <span class=""ltr stick-together"">(logistic regression)</span></span> نفترض هنا أن  $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]
</div>
<p><span class=remark>ملاحظة: ليس هناك حل رياضي مغلق للانحدار اللوجستي.</span></p>
<br>
<p><span class=""new-item item-b"">انحدار سوفت ماكس <span class=""ltr stick-together"">(softmax)</span></span> ويطلق عليه الانحدار اللوجستي متعدد الأصناف <span class=""ltr stick-together"">(multiclass logistic regression)</span>، يستخدم لتعميم الانحدار اللوجستي إذا كان لدينا أكثر من صنفين. في العرف يتم تعيين $\theta_K=0$، بحيث تجعل مُدخل بيرنوللي <span class=""ltr stick-together"">(Bernoulli)</span> $\phi_i$ لكل فئة $i$ يساوي:</p>
<div class=mobile-container>
\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]
</div>
<br>
<h3>النماذج الخطية العامة <span class=""ltr stick-together"">(Generalized Linear Models, GLM)</span></h3>
<p><span class=""new-item item-r"">العائلة الأُسيّة <span class=""ltr stick-together"">(Exponential family)</span></span> يطلق على صنف من التوزيعات <span class=""ltr stick-together"">(distributions)</span> بأنها تنتمي إلى العائلة الأسيّة إذا كان يمكن كتابتها بواسطة مُدخل قانوني <span class=""ltr stick-together"">(canonical parameter)</span> $\eta$، إحصاء كافٍ <span class=""ltr stick-together"">(sufficient statistic)</span> $T(y)$، ودالة تجزئة لوغاريثمية $a(\eta)$، كالتالي:</p>
<div class=mobile-container>
\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]
</div>
<p><span class=remark>ملاحظة: كثيراً ما سيكون $T(y)=y$. كذلك فإن $\exp(-a(\eta))$ يمكن أن تفسر كمُدخل تسوية <span class=""ltr stick-together"">(normalization)</span> للتأكد من أن الاحتمالات يكون حاصل جمعها يساوي واحد.</span></p>
<p>تم تلخيص أكثر التوزيعات الأسيّة استخداماً في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>التوزيع</b></td>
<td align=center><b>$\eta$</b></td>
<td align=center><b>$T(y)$</b></td>
<td align=center><b>$a(\eta)$</b></td>
<td align=center><b>$b(y)$</b></td>
</tr>
<tr>
<td align=center>بِرنوللي <span class=""ltr stick-together"">(Bernoulli)</span></td>
<td align=center>$\log\left(\frac{\phi}{1-\phi}\right)$</td>
<td align=center>$y$</td>
<td align=center>$\log(1+\exp(\eta))$</td>
<td align=center>$1$</td>
</tr>
<tr>
<td align=center>جاوسي <span class=""ltr stick-together"">(Gaussian)</span></td>
<td align=center>$\mu$</td>
<td align=center>$y$</td>
<td align=center>$\frac{\eta^2}{2}$</td>
<td align=center>$\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$</td>
</tr>
<tr>
<td align=center>بواسون <span class=""ltr stick-together"">(Poisson)</span></td>
<td align=center>$\log(\lambda)$</td>
<td align=center>$y$</td>
<td align=center>$e^{\eta}$</td>
<td align=center>$\displaystyle\frac{1}{y!}$</td>
</tr>
<tr>
<td align=center>هندسي <span class=""ltr stick-together"">(Geometric)</span></td>
<td align=center>$\log(1-\phi)$</td>
<td align=center>$y$</td>
<td align=center>$\log\left(\frac{e^\eta}{1-e^\eta}\right)$</td>
<td align=center>$1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">افتراضات <span class=""ltr stick-together"">GLMs</span></span> تهدف النماذج الخطيّة العامة <span class=""ltr stick-together"">(GLM)</span> إلى توقع المتغير العشوائي $y$ كدالة لـ $x\in\mathbb{R}^{n+1}$، وتستند إلى ثلاثة افتراضات:
</p>
<div class=row>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(3)\quad\boxed{\eta=\theta^Tx}$</div>
</div>
<br>
<p><span class=remark>ملاحظة: أصغر تربيع <span class=""ltr stick-together"">(least squares)</span> الاعتيادي و الانحدار اللوجستي يعتبران من الحالات الخاصة للنماذج الخطيّة العامة.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#svm id=svm></a>آلة المتجهات الداعمة <span class=""ltr stick-together"">(Support Vector Machines)</span></h2>
<p>تهدف آلة المتجهات الداعمة <span class=""ltr stick-together"">(SVM)</span> إلى العثور على الخط الذي يعظم أصغر مسافة إليه:</p>
<p><span class=""new-item item-b"">مُصنِّف الهامش الأحسن <span class=""ltr stick-together"">(optimal margin classifier)</span></span> يعرَّف مُصنِّف الهامش الأحسن $h$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]
</div>
<p>حيث $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ هو الحل لمشكلة التحسين <span class=""ltr stick-together"">(optimization)</span> التالية:</p>
<div class=mobile-container>
\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\text{و }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]
</div>
<center>
<img alt=SVM class=img-responsive src=teaching/cs-229/illustrations/svm-ar.png?7780eef79aa94961ada7f3bebb5be22a style=width:100%;max-width:600px>
</center>
<p><span class=remark>ملاحظة: يتم تعريف الخط بهذه المعادلة <span style=""font-family: monospace !important;"">$\boxed{w^Tx-b=0}$</span>.</span></p>
<br>
<p><span class=""new-item item-b"">الخسارة المفصلية <span class=""ltr stick-together"">(Hinge loss)</span></span> تستخدم الخسارة المفصلية في حل <span class=""ltr stick-together"">SVM</span> ويعرف على النحو التالي:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]
</div>
<br>
<p><span class=""new-item item-b"">النواة <span class=""ltr stick-together"">(kernel)</span></span> إذا كان لدينا دالة ربط الخصائص <span class=""ltr stick-together"">(features)</span> $\phi$، يمكننا تعريف النواة $K$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]
</div>
<p>عملياً، يمكن أن تُعَرَّف الدالة $K$ عن طريق المعادلة $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$، ويطلق عليها النواة الجاوسية <span class=""ltr stick-together"">(Gaussian kernel)</span>، وهي تستخدم بكثرة.</p>
<center>
<img alt=""SVM kernel"" class=img-responsive src=teaching/cs-229/illustrations/svm-kernel-ar.png?2bd4e3e7bf624b23c1640ed04e234f44>
</center>
<br>
<p><span class=remark>ملاحظة: نقول أننا نستخدم ""حيلة النواة"" <span class=""ltr stick-together"">(kernel trick)</span> لحساب دالة التكلفة عند استخدام النواة لأننا في الحقيقة لا نحتاج أن نعرف التحويل الصريح $\phi$، الذي يكون في الغالب شديد التعقيد. ولكن، نحتاج أن فقط أن نحسب القيم $K(x,z)$.</span></p>
<br>
<p><span class=""new-item item-r"">اللّاغرانجي <span class=""ltr stick-together"">(Lagrangian)</span></span> يتم تعريف اللّاغرانجي $\mathcal{L}(w,b)$ على النحو التالي:</p>
<div class=mobile-container>
\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]
</div>
<p><span class=remark>ملاحظة: المعامِلات <span class=""ltr stick-together"">(coefficients)</span> $\beta_i$ يطلق عليها مضروبات لاغرانج <span class=""ltr stick-together"">(Lagrange multipliers)</span>.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#generative-learning id=generative-learning></a>التعلم التوليدي <span class=""ltr stick-together"">(generative learning)</span></h2>
<p>النموذج التوليدي في البداية يحاول أن يتعلم كيف تم توليد البيانات عن طريق تقدير $P(x|y)$، التي يمكن حينها استخدامها لتقدير $P(y|x)$ باستخدام قانون بايز <span class=""ltr stick-together"">(Bayes' rule)</span>.</p>
<h3>تحليل التمايز الجاوسي <span class=""ltr stick-together"">(Gaussian Discriminant Analysis)</span></h3>
<p><span class=""new-item item-b"">الإطار</span> تحليل التمايز الجاوسي يفترض أن $y$ و $x|y=0$ و $x|y=1$ بحيث يكونوا كالتالي:</p>
<div class=row>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$</div>
<div class=col-sm-4 style=""font-family: monospace !important;"">$(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$</div>
</div>
<br>
<p><span class=""new-item item-b"">التقدير</span> الجدول التالي يلخص التقديرات التي يمكننا التوصل لها عند تعظيم الأرجحية <span class=""ltr stick-together"">(likelihood)</span>:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>$\widehat{\phi}$</b></td>
<td align=right><b>$\widehat{\mu_j}\quad{\small(j=0,1)}$</b></td>
<td align=center><b>$\widehat{\Sigma}$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$</td>
<td align=center>$\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$</td>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>بايز البسيط <span class=""ltr stick-together"">(Naive Bayes)</span></h3>
<p><span class=""new-item item-b"">الافتراض</span> يفترض نموذج بايز البسيط أن جميع الخصائص لكل عينة بيانات مستقلة <span class=""ltr stick-together"">(independent)</span>:</p>
<div class=mobile-container>
\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]
</div>
<br>
<p><span class=""new-item item-r"">الحل</span> تعظيم الأرجحية اللوغاريثمية <span class=""ltr stick-together"">(log-likelihood)</span> يعطينا الحلول التالية إذا كان $k\in\{0,1\},l\in[\![1,L]\!]$: $k\in\{0,1\},l\in[\![1,L]\!]$ </p>
<div class=mobile-container>
\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ و }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ و }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]
</div>
<p><span class=remark>ملاحظة: بايز البسيط يستخدم بشكل واسع لتصنيف النصوص واكتشاف البريد الإلكتروني المزعج.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#tree id=tree></a>الطرق الشجرية <span class=""ltr stick-together"">(tree-based)</span> والتجميعية <span class=""ltr stick-together"">(ensemble)</span></h2>
<p>هذه الطرق يمكن استخدامها لكلٍ من مشاكل الانحدار <span class=""ltr stick-together"">(regression)</span> والتصنيف <span class=""ltr stick-together"">(classification)</span>.</p>
<p><span class=""new-item item-b"">التصنيف والانحدار الشجري <span class=""ltr stick-together"">(CART)</span></span> والاسم الشائع له أشجار القرار <span class=""ltr stick-together"">(decision trees)</span>، يمكن أن يمثل كأشجار ثنائية <span class=""ltr stick-together"">(binary trees)</span>. من المزايا لهذه الطريقة إمكانية تفسيرها بسهولة.</p>
<br>
<p><span class=""new-item item-b"">الغابة العشوائية <span class=""ltr stick-together"">(random forest)</span></span> هي أحد الطرق الشجرية التي تستخدم عدداً كبيراً من أشجار القرار مبنية باستخدام مجموعة عشوائية من الخصائص. بخلاف شجرة القرار البسيطة لا يمكن تفسير النموذج بسهولة، ولكن أدائها العالي جعلها أحد الخوارزمية المشهورة.</p>
<p><span class=remark>ملاحظة: أشجار القرار نوع من الخوارزميات التجميعية <span class=""ltr stick-together"">(ensemble)</span>.</span></p>
<br>
<p><span class=""new-item item-b"">التعزيز <span class=""ltr stick-together"">(boosting)</span></span> فكرة خوارزميات التعزيز هي دمج عدة خوارزميات تعلم ضعيفة لتكوين نموذج قوي. الطرق الأساسية ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>التعزيز التَكَيُّفي <span class=""ltr stick-together"">(adaptive boosting)</span></b></td>
<td align=center><b>التعزيز الاشتقاقي <span class=""ltr stick-together"">(gradient boosting)</span></b></td>
</tr>
<tr>
<td align=right>• يتم التركيز على مواطن الخطأ لتحسين النتيجة في الخطوة التالية.</td>
<td align=right>• يتم تدريب خوارزميات التعلم الضعيفة على الأخطاء المتبقية.</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#other id=other></a>طرق أخرى غير بارامترية <span class=""ltr stick-together"">(non-parametric)</span></h2>
<p><span class=""new-item item-b"">خوارزمية أقرب الجيران <span class=""ltr stick-together"">($k$-nearest neighbors)</span></span> تعتبر خوارزمية أقرب الجيران، وتعرف بـ <span class=""ltr stick-together"">$k$-NN</span>، طريقة غير بارامترية، حيث يتم تحديد نتيجة عينة من البيانات من خلال عدد $k$ من البيانات المجاورة في مجموعة التدريب. ويمكن استخدامها للتصنيف والانحدار.</p>
<p><span class=remark>ملاحظة: كلما زاد المُدخل $k$، كلما زاد الانحياز <span class=""ltr stick-together"">(bias)</span>، وكلما نقص $k$، زاد التباين <span class=""ltr stick-together"">(variance)</span>.</span></p>
<div class=mobile-container>
<center>
<img alt=""k nearest neighbors"" class=img-responsive src=teaching/cs-229/illustrations/k-nearest-neighbors.png?02f80a524bb11e2b7a70b58c9ed3b0f4 style=width:100%;max-width:740px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#learning-theory id=learning-theory></a>نظرية التعلُّم</h2>
<p><span class=""new-item item-r"">حد الاتحاد <span class=""ltr stick-together"">(union bound)</span></span> لنجعل $A_1, ..., A_k$ تمثل $k$ حدث. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]
</div>
<center>
<img alt=""Union bound"" class=img-responsive src=teaching/cs-229/illustrations/union-bound.png?aab917859fa8e260e865def69a2889b8 style=width:100%;max-width:700px>
</center>
<br>
<p><span class=""new-item item-r"">متراجحة هوفدينج <span class=""ltr stick-together"">(Hoeffding)</span></span> لنجعل $Z_1, .., Z_m$ تمثل $m$ متغير مستقلة وموزعة بشكل مماثل <span class=""ltr stick-together"">(iid)</span> مأخوذة من توزيع بِرنوللي <span class=""ltr stick-together"">(Bernoulli distribution)</span> ذا مُدخل $\phi$. لنجعل $\widehat{\phi}$ متوسط العينة <span class=""ltr stick-together"">(sample mean)</span> و $\gamma&gt;0$ ثابت. فيكون لدينا:</p>
<div class=mobile-container>
\[\boxed{P(|\phi-\widehat{\phi}|&gt;\gamma)\leqslant2\exp(-2\gamma^2m)}\]
</div>
<p><span class=remark>ملاحظة: هذه المتراجحة تعرف كذلك بحد تشرنوف <span class=""ltr stick-together"">(Chernoff bound)</span>.</span></p>
<br>
<p><span class=""new-item item-g"">خطأ التدريب</span> ليكن لدينا المُصنِّف $h$، يمكن تعريف خطأ التدريب $\widehat{\epsilon}(h)$، ويعرف كذلك بالخطر التجريبي أو الخطأ التجريبي، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})\neq y^{(i)}\}}}\]
</div>
<br>
<p><span class=""new-item item-g"">تقريباً صحيح احتمالياً <span class=""ltr stick-together"">(Probably Approximately Correct, PAC)</span></span> هو إطار يتم من خلاله إثبات العديد من نظريات التعلم، ويحتوي على الافتراضات التالية:
<br>- مجموعتي التدريب والاختبار يتبعان نفس التوزيع.
<br>- عينات التدريب تؤخذ بشكل مستقل.</p>
<br>
<p><span class=""new-item item-g"">مجموعة تكسيرية <span class=""ltr stick-together"">(shattering set)</span></span> إذا كان لدينا المجموعة $S=\{x^{(1)},...,x^{(d)}\}$، ومجموعة مُصنٍّفات $\mathcal{H}$، نقول أن $\mathcal{H}$ تكسر $S$ <span class=""ltr stick-together"">(H shatters S)</span> إذا كان لكل مجموعة علامات <span class=""ltr stick-together"">(labels)</span> $\{y^{(1)}, ..., y^{(d)}\}$ لدينا:</p>
<div class=mobile-container>
\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]
</div>
<br>
<p><span class=""new-item item-r"">مبرهنة الحد الأعلى <span class=""ltr stick-together"">(upper bound theorem)</span></span> لنجعل $\mathcal{H}$ فئة فرضية محدودة <span class=""ltr stick-together"">(finite hypothesis class)</span> بحيث $|\mathcal{H}|=k$، و $\delta$ وحجم العينة $m$ ثابتين. حينها سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]
</div>
<br>
<p><span class=""new-item item-g"">بُعْد فابنيك</span> تشرفونيكس <span class=""ltr stick-together"">(Vapnik-Chervonenkis, VC)</span> لفئة فرضية غير محدودة <span class=""ltr stick-together"">(infinite hypothesis class)</span> $\mathcal{H}$، ويرمز له بـ $\textrm{VC}(\mathcal{H})$، هو حجم أكبر مجموعة <span class=""ltr stick-together"">(set)</span> التي تم تكسيرها بواسطة $\mathcal{H}$ <span class=""ltr stick-together"">(shattered by $\mathcal{H}$)</span>.</p>
<center>
<img alt=""VC dimension"" class=img-responsive src=teaching/cs-229/illustrations/vc-dimension.png?73859dedcc66a0e47526936f801b7b56>
</center>
<br>
<p><span class=""new-item item-r"">مبرهنة فابنيك <span class=""ltr stick-together"">(Vapnik theorem)</span></span> ليكن لدينا $\mathcal{H}$، مع $\textrm{VC}(\mathcal{H})=d$ وعدد عيّنات التدريب $m$. سيكون لدينا، مع احتمال على الأقل $1-\delta$، التالي:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]
</div>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
9,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Supervised Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Introduction to Supervised Learning

Given a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.

Type of prediction The different types of predictive models are summed up in the table below:

Regression Classification Outcome Continuous Class Examples Linear regression Logistic regression, SVM, Naive Bayes

Type of model The different models are summed up in the table below:

Discriminative model Generative model Goal Directly estimate $P(y|x)$ Estimate $P(x|y)$ to then deduce $P(y|x)$ What's learned Decision boundary Probability distributions of the data Illustration Examples Regressions, SVMs GDA, Naive Bayes

Notations and general concepts

Hypothesis The hypothesis is noted $h_\theta$ and is the model that we choose. For a given input data $x^{(i)}$ the model prediction output is $h_\theta(x^{(i)})$.

Loss function A loss function is a function $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ that takes as inputs the predicted value $z$ corresponding to the real data value $y$ and outputs how different they are. The common loss functions are summed up in the table below:

Least squared error Logistic loss Hinge loss Cross-entropy $\displaystyle\frac{1}{2}(y-z)^2$ $\displaystyle\log(1+\exp(-yz))$ $\displaystyle\max(0,1-yz)$ $\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$ Linear regression Logistic regression SVM Neural Network

Cost function The cost function $J$ is commonly used to assess the performance of a model, and is defined with the loss function $L$ as follows:

\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]

Gradient descent By noting $\alpha\in\mathbb{R}$ the learning rate, the update rule for gradient descent is expressed with the learning rate and the cost function $J$ as follows:

\[\boxed{\theta\longleftarrow\theta-\alpha

abla J(\theta)}\]

Remark: Stochastic gradient descent (SGD) is updating the parameter based on each training example, and batch gradient descent is on a batch of training examples.

Likelihood The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization. We have:

\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]

Remark: in practice, we use the log-likelihood $\ell(\theta)=\log(L(\theta))$ which is easier to optimize.

Newton's algorithm Newton's algorithm is a numerical method that finds $\theta$ such that $\ell'(\theta)=0$. Its update rule is as follows:

\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]

Remark: the multidimensional generalization, also known as the Newton-Raphson method, has the following update rule:

\[\theta\leftarrow\theta-\left(

abla_\theta^2\ell(\theta)\right)^{-1}

abla_\theta\ell(\theta)\]

Linear models

Linear regression

We assume here that $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$

Normal equations By noting $X$ the design matrix, the value of $\theta$ that minimizes the cost function is a closed-form solution such that:

\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]

LMS algorithm By noting $\alpha$ the learning rate, the update rule of the Least Mean Squares (LMS) algorithm for a training set of $m$ data points, which is also known as the Widrow-Hoff learning rule, is as follows:

\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]

Remark: the update rule is a particular case of the gradient ascent.

LWR Locally Weighted Regression, also known as LWR, is a variant of linear regression that weights each training example in its cost function by $w^{(i)}(x)$, which is defined with parameter $\tau\in\mathbb{R}$ as:

\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]

Classification and logistic regression

Sigmoid function The sigmoid function $g$, also known as the logistic function, is defined as follows:

\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]

Logistic regression We assume here that $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. We have the following form:

\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]

Remark: logistic regressions do not have closed form solutions.

Softmax regression A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes. By convention, we set $\theta_K=0$, which makes the Bernoulli parameter $\phi_i$ of each class $i$ be such that:

\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]

Generalized Linear Models

Exponential family A class of distributions is said to be in the exponential family if it can be written in terms of a natural parameter, also called the canonical parameter or link function, $\eta$, a sufficient statistic $T(y)$ and a log-partition function $a(\eta)$ as follows:

\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]

Remark: we will often have $T(y)=y$. Also, $\exp(-a(\eta))$ can be seen as a normalization parameter that will make sure that the probabilities sum to one.

The most common exponential distributions are summed up in the following table:

Distribution $\eta$ $T(y)$ $a(\eta)$ $b(y)$ Bernoulli $\log\left(\frac{\phi}{1-\phi}\right)$ $y$ $\log(1+\exp(\eta))$ $1$ Gaussian $\mu$ $y$ $\frac{\eta^2}{2}$ $\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$ Poisson $\log(\lambda)$ $y$ $e^{\eta}$ $\displaystyle\frac{1}{y!}$ Geometric $\log(1-\phi)$ $y$ $\log\left(\frac{e^\eta}{1-e^\eta}\right)$ $1$

Assumptions of GLMs Generalized Linear Models (GLM) aim at predicting a random variable $y$ as a function of $x\in\mathbb{R}^{n+1}$ and rely on the following 3 assumptions:

$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$ $(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$ $(3)\quad\boxed{\eta=\theta^Tx}$

Remark: ordinary least squares and logistic regression are special cases of generalized linear models.

Support Vector Machines

The goal of support vector machines is to find the line that maximizes the minimum distance to the line.

Optimal margin classifier The optimal margin classifier $h$ is such that:

\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]

where $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ is the solution of the following optimization problem:

\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\textrm{such that }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]

Remark: the decision boundary is defined as $\boxed{w^Tx-b=0}$.

Hinge loss The hinge loss is used in the setting of SVMs and is defined as follows:

\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]

Kernel Given a feature mapping $\phi$, we define the kernel $K$ as follows:

\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]

In practice, the kernel $K$ defined by $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$ is called the Gaussian kernel and is commonly used.

Remark: we say that we use the ""kernel trick"" to compute the cost function using the kernel because we actually don't need to know the explicit mapping $\phi$, which is often very complicated. Instead, only the values $K(x,z)$ are needed.

Lagrangian We define the Lagrangian $\mathcal{L}(w,b)$ as follows:

\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]

Remark: the coefficients $\beta_i$ are called the Lagrange multipliers.

Generative Learning

A generative model first tries to learn how the data is generated by estimating $P(x|y)$, which we can then use to estimate $P(y|x)$ by using Bayes' rule.

Gaussian Discriminant Analysis

Setting The Gaussian Discriminant Analysis assumes that $y$ and $x|y=0$ and $x|y=1$ are such that:

$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$ $(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$ $(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$

Estimation The following table sums up the estimates that we find when maximizing the likelihood:

$\widehat{\phi}$ $\widehat{\mu_j}\quad{\small(j=0,1)}$ $\widehat{\Sigma}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$ $\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$ $\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$

Naive Bayes

Assumption The Naive Bayes model supposes that the features of each data point are all independent:

\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]

Solutions Maximizing the log-likelihood gives the following solutions:

\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ and }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ and }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]

Remark: Naive Bayes is widely used for text classification and spam detection.

Tree-based and ensemble methods

These methods can be used for both regression and classification problems.

CART Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable.

Random forest It is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm.

Remark: random forests are a type of ensemble methods.

Boosting The idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below:

Adaptive boosting Gradient boosting • High weights are put on errors to improve at the next boosting step

• Known as Adaboost • Weak learners are trained on residuals

• Examples include XGBoost

Other non-parametric approaches

$k$-nearest neighbors The $k$-nearest neighbors algorithm, commonly known as $k$-NN, is a non-parametric approach where the response of a data point is determined by the nature of its $k$ neighbors from the training set. It can be used in both classification and regression settings.

Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.

Learning Theory

Union bound Let $A_1, ..., A_k$ be $k$ events. We have:

\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]

Hoeffding inequality Let $Z_1, .., Z_m$ be $m$ iid variables drawn from a Bernoulli distribution of parameter $\phi$. Let $\widehat{\phi}$ be their sample mean and $\gamma>0$ fixed. We have:

\[\boxed{P(|\phi-\widehat{\phi}|>\gamma)\leqslant2\exp(-2\gamma^2m)}\]

Remark: this inequality is also known as the Chernoff bound.

Training error For a given classifier $h$, we define the training error $\widehat{\epsilon}(h)$, also known as the empirical risk or empirical error, to be as follows:

\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})

eq y^{(i)}\}}}\]

Probably Approximately Correct (PAC) PAC is a framework under which numerous results on learning theory were proved, and has the following set of assumptions:

the training and testing sets follow the same distribution

the training examples are drawn independently

Shattering Given a set $S=\{x^{(1)},...,x^{(d)}\}$, and a set of classifiers $\mathcal{H}$, we say that $\mathcal{H}$ shatters $S$ if for any set of labels $\{y^{(1)}, ..., y^{(d)}\}$, we have:

\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]

Upper bound theorem Let $\mathcal{H}$ be a finite hypothesis class such that $|\mathcal{H}|=k$ and let $\delta$ and the sample size $m$ be fixed. Then, with probability of at least $1-\delta$, we have:

\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]

VC dimension The Vapnik-Chervonenkis (VC) dimension of a given infinite hypothesis class $\mathcal{H}$, noted $\textrm{VC}(\mathcal{H})$ is the size of the largest set that is shattered by $\mathcal{H}$.

Remark: the VC dimension of ${\small\mathcal{H}=\{\textrm{set of linear classifiers in 2 dimensions}\}}$ is 3.

Theorem (Vapnik) Let $\mathcal{H}$ be given, with $\textrm{VC}(\mathcal{H})=d$ and $m$ the number of training examples. With probability at least $1-\delta$, we have:

\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]","Would you like to see this cheatsheet in your native language?
CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksSupervised Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiIntroduction to Supervised LearningGiven a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.
Likelihood The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization.
Softmax regression A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes.
Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.","['supervised', 'set', 'function', 'model', 'logistic', 'training', 'learning', 'cheatsheet', 'parameter', 'y', 'known', 'regression']",en,Supervised Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Supervised Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Supervised Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>Introduction</a></div> <div class=dropdown-container> <a href=#introduction><span>Type of prediction</span></a> <a href=#introduction><span>Type of model</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#notations>Notations and general concepts</a></div> <div class=dropdown-container> <a href=#notations><span>Loss function</span></a> <a href=#notations><span>Gradient descent</span></a> <a href=#notations><span>Likelihood</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#linear-models>Linear models</a></div> <div class=dropdown-container> <a href=#linear-models><span>Linear regression</span></a> <a href=#linear-models><span>Logisitic regression</span></a> <a href=#linear-models><span>Generalized linear models</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#svm>Support Vector Machines</a></div> <div class=dropdown-container> <a href=#svm><span>Optimal margin classifier</span></a> <a href=#svm><span>Hinge loss</span></a> <a href=#svm><span>Kernel</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#generative-learning>Generative learning</a></div> <div class=dropdown-container> <a href=#generative-learning><span>Gaussian Discriminant Analysis</span></a> <a href=#generative-learning><span>Naive Bayes</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#tree>Trees and ensemble methods</a></div> <div class=dropdown-container> <a href=#tree><span>CART</span></a> <a href=#tree><span>Random forest</span></a> <a href=#tree><span>Boosting</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#other>Other methods</a></div> <div class=dropdown-container> <a href=#other><span>k-NN</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#learning-theory>Learning Theory</a></div> <div class=dropdown-container> <a href=#learning-theory><span>Hoeffding inequality</span></a> <a href=#learning-theory><span>PAC</span></a> <a href=#learning-theory><span>VC dimension</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button><b>Supervised Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Supervised Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>Introduction to Supervised Learning</h2>
<p>Given a set of data points $\{x^{(1)}, ..., x^{(m)}\}$ associated to a set of outcomes $\{y^{(1)}, ..., y^{(m)}\}$, we want to build a classifier that learns how to predict $y$ from $x$.</p>
<p><span class=""new-item item-b"">Type of prediction</span> The different types of predictive models are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b></b></td>
<td align=center><b>Regression</b></td>
<td align=center><b>Classification</b></td>
</tr>
<tr>
<td align=center><b>Outcome</b></td>
<td align=center>Continuous</td>
<td align=center>Class</td>
</tr>
<tr>
<td align=center><b>Examples</b></td>
<td align=center>Linear regression</td>
<td align=center>Logistic regression, SVM, Naive Bayes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Type of model</span> The different models are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:300px;"">
  <colgroup>
    <col style=width:120px>
    <col style=width:50%>
    <col style=width:50%>
  </colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>Discriminative model</b></td>
<td align=center><b>Generative model</b></td>
</tr>
<tr>
<td align=center><b>Goal</b></td>
<td align=left>Directly estimate $P(y|x)$</td>
<td align=left>Estimate $P(x|y)$ to then deduce $P(y|x)$</td>
</tr>
<tr>
<td align=center><b>What's learned</b></td>
<td align=left>Decision boundary</td>
<td align=left>Probability distributions of the data</td>
</tr>
<tr>
<td align=center><b>Illustration</b></td>
<td align=center style=""width: 41%;""><img alt=""Discriminative model"" class=img-responsive src=teaching/cs-229/illustrations/discriminative-model.png?767b34c21d43a4fd8b59683578e132f9></td>
<td align=center style=""width: 41%;""><img alt=""Generative model"" class=img-responsive src=teaching/cs-229/illustrations/generative-model.png?df0642cec6e99ac162cd4848d26f41c3></td>
</tr>
<tr>
<td align=center><b>Examples</b></td>
<td align=left>Regressions, SVMs</td>
<td align=left>GDA, Naive Bayes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>Notations and general concepts</h2>
<p><span class=""new-item item-b"">Hypothesis</span> The hypothesis is noted $h_\theta$ and is the model that we choose. For a given input data $x^{(i)}$ the model prediction output is $h_\theta(x^{(i)})$.</p>
<br>
<p><span class=""new-item item-r"">Loss function</span> A loss function is a function $L:(z,y)\in\mathbb{R}\times Y\longmapsto L(z,y)\in\mathbb{R}$ that takes as inputs the predicted value $z$ corresponding to the real data value $y$ and outputs how different they are. The common loss functions are summed up in the table below:</p>
<div class=mobile-container>
<center>
  <table style=""table-layout:fixed; width:100%; min-width:820px;"">
    <colgroup>
      <col style=width:25%>
      <col style=width:25%>
      <col style=width:25%>
      <col style=width:25%>
    </colgroup>
<tbody>
<tr>
<td align=center><b>Least squared error</b></td>
<td align=center><b>Logistic loss</b></td>
<td align=center><b>Hinge loss</b></td>
<td align=center><b>Cross-entropy</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{2}(y-z)^2$</td>
<td align=center>$\displaystyle\log(1+\exp(-yz))$</td>
<td align=center>$\displaystyle\max(0,1-yz)$</td>
<td align=center style=vertical-align:middle><div id=some_math style=font-size:75%>$\displaystyle-\Big[y\log(z)+(1-y)\log(1-z)\Big]$</div></td>
</tr>
<tr>
<td align=center style=""width: 25%;""><img alt=""Least squared error"" class=img-responsive src=teaching/cs-229/illustrations/least-square-error.png?63fef2552284b0dc15f27d1ef0b79fea></td>
<td align=center style=""width: 25%;""><img alt=""Logistic loss"" class=img-responsive src=teaching/cs-229/illustrations/logistic-loss.png?1bc1cb6d682c1bbfb978ec894afdf588></td>
<td align=center style=""width: 25%;""><img alt=""Hinge loss"" class=img-responsive src=teaching/cs-229/illustrations/hinge-loss.png?3f1b26410c446f52885dcc5266937c84></td>
<td align=center style=""width: 25%;""><img alt=""Cross entropy"" class=img-responsive src=teaching/cs-229/illustrations/cross-entropy.png?037ea4073873c9be4a7de099dac6d3b5></td>
</tr>
<tr>
<td align=center>Linear regression</td>
<td align=center>Logistic regression</td>
<td align=center>SVM</td>
<td align=center>Neural Network</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Cost function</span> The cost function $J$ is commonly used to assess the performance of a model, and is defined with the loss function $L$ as follows:</p>
<div class=mobile-container>
\[\boxed{J(\theta)=\sum_{i=1}^mL(h_\theta(x^{(i)}), y^{(i)})}\]
</div>
<br>
<p><span class=""new-item item-r"">Gradient descent</span> By noting $\alpha\in\mathbb{R}$ the learning rate, the update rule for gradient descent is expressed with the learning rate and the cost function $J$ as follows:</p>
<div class=mobile-container>
\[\boxed{\theta\longleftarrow\theta-\alpha\nabla J(\theta)}\]
</div>
<br>
<center>
  <img alt=""Gradient descent"" class=img-responsive src=teaching/cs-229/illustrations/gradient-descent.png?01662c4a8147a55ba09f4f5c047641ba style=width:100%;max-width:500px>
</center>
<br>
<p><span class=remark>Remark: Stochastic gradient descent (SGD) is updating the parameter based on each training example, and batch gradient descent is on a batch of training examples.</span></p>
<br>
<p><span class=""new-item item-b"">Likelihood</span> The likelihood of a model $L(\theta)$ given parameters $\theta$ is used to find the optimal parameters $\theta$ through likelihood maximization. We have:</p>
<div class=mobile-container>
\[\boxed{\theta^{\textrm{opt}}=\underset{\theta}{\textrm{arg max }}L(\theta)}\]
</div>
<p><span class=remark>Remark: in practice, we use the log-likelihood $\ell(\theta)=\log(L(\theta))$ which is easier to optimize.</span></p>
<br>
<p><span class=""new-item item-r"">Newton's algorithm</span> Newton's algorithm is a numerical method that finds $\theta$ such that $\ell'(\theta)=0$. Its update rule is as follows:</p>
<div class=mobile-container>
\[\boxed{\theta\leftarrow\theta-\frac{\ell'(\theta)}{\ell''(\theta)}}\]
</div>
<p><span class=remark>Remark: the multidimensional generalization, also known as the Newton-Raphson method, has the following update rule:</span></p>
<div class=mobile-container>
\[\theta\leftarrow\theta-\left(\nabla_\theta^2\ell(\theta)\right)^{-1}\nabla_\theta\ell(\theta)\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#linear-models id=linear-models></a>Linear models</h2>
<h3>Linear regression</h3>
<p>We assume here that $y|x;\theta\sim\mathcal{N}(\mu,\sigma^2)$</p>
<p><span class=""new-item item-g"">Normal equations</span> By noting $X$ the design matrix, the value of $\theta$ that minimizes the cost function is a closed-form solution such that:</p>
<div class=mobile-container>
\[\boxed{\theta=(X^TX)^{-1}X^Ty}\]
</div>
<br>
<p><span class=""new-item item-g"">LMS algorithm</span> By noting $\alpha$ the learning rate, the update rule of the Least Mean Squares (LMS) algorithm for a training set of $m$ data points, which is also known as the Widrow-Hoff learning rule, is as follows:</p>
<div class=mobile-container>
\[\boxed{\forall j,\quad \theta_j \leftarrow \theta_j+\alpha\sum_{i=1}^m\left[y^{(i)}-h_\theta(x^{(i)})\right]x_j^{(i)}}\]
</div>
<p><span class=remark>Remark: the update rule is a particular case of the gradient ascent.</span></p>
<br>
<p><span class=""new-item item-b"">LWR</span> Locally Weighted Regression, also known as LWR, is a variant of linear regression that weights each training example in its cost function by $w^{(i)}(x)$, which is defined with parameter $\tau\in\mathbb{R}$ as:</p>
<div class=mobile-container>
\[\boxed{w^{(i)}(x)=\exp\left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)}\]
</div>
<br>
<h3>Classification and logistic regression</h3>
<p><span class=""new-item item-b"">Sigmoid function</span> The sigmoid function $g$, also known as the logistic function, is defined as follows:</p>
<div class=mobile-container>
\[\forall z\in\mathbb{R},\quad\boxed{g(z)=\frac{1}{1+e^{-z}}\in]0,1[}\]
</div>
<br>
<p><span class=""new-item item-b"">Logistic regression</span> We assume here that $y|x;\theta\sim\textrm{Bernoulli}(\phi)$. We have the following form:</p>
<div class=mobile-container>
\[\boxed{\phi=p(y=1|x;\theta)=\frac{1}{1+\exp(-\theta^Tx)}=g(\theta^Tx)}\]
</div>
<p><span class=remark>Remark: logistic regressions do not have closed form solutions.</span></p>
<br>
<p><span class=""new-item item-b"">Softmax regression</span> A softmax regression, also called a multiclass logistic regression, is used to generalize logistic regression when there are more than 2 outcome classes. By convention, we set $\theta_K=0$, which makes the Bernoulli parameter $\phi_i$ of each class $i$ be such that:</p>
<div class=mobile-container>
\[\boxed{\displaystyle\phi_i=\frac{\exp(\theta_i^Tx)}{\displaystyle\sum_{j=1}^K\exp(\theta_j^Tx)}}\]
</div>
<br>
<h3>Generalized Linear Models</h3>
<p><span class=""new-item item-r"">Exponential family</span> A class of distributions is said to be in the exponential family if it can be written in terms of a natural parameter, also called the canonical parameter or link function, $\eta$, a sufficient statistic $T(y)$ and a log-partition function $a(\eta)$ as follows:</p>
<div class=mobile-container>
\[\boxed{p(y;\eta)=b(y)\exp(\eta T(y)-a(\eta))}\]
</div>
<p><span class=remark>Remark: we will often have $T(y)=y$. Also, $\exp(-a(\eta))$ can be seen as a normalization parameter that will make sure that the probabilities sum to one.</span></p>
<p>The most common exponential distributions are summed up in the following table:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Distribution</b></td>
<td align=center><b>$\eta$</b></td>
<td align=center><b>$T(y)$</b></td>
<td align=center><b>$a(\eta)$</b></td>
<td align=center><b>$b(y)$</b></td>
</tr>
<tr>
<td align=center>Bernoulli</td>
<td align=center>$\log\left(\frac{\phi}{1-\phi}\right)$</td>
<td align=center>$y$</td>
<td align=center>$\log(1+\exp(\eta))$</td>
<td align=center>$1$</td>
</tr>
<tr>
<td align=center>Gaussian</td>
<td align=center>$\mu$</td>
<td align=center>$y$</td>
<td align=center>$\frac{\eta^2}{2}$</td>
<td align=center>$\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{y^2}{2}\right)$</td>
</tr>
<tr>
<td align=center>Poisson</td>
<td align=center>$\log(\lambda)$</td>
<td align=center>$y$</td>
<td align=center>$e^{\eta}$</td>
<td align=center>$\displaystyle\frac{1}{y!}$</td>
</tr>
<tr>
<td align=center>Geometric</td>
<td align=center>$\log(1-\phi)$</td>
<td align=center>$y$</td>
<td align=center>$\log\left(\frac{e^\eta}{1-e^\eta}\right)$</td>
<td align=center>$1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Assumptions of GLMs</span> Generalized Linear Models (GLM) aim at predicting a random variable $y$ as a function of $x\in\mathbb{R}^{n+1}$ and rely on the following 3 assumptions:</p>
<div class=row>
 <div class=col-sm-4>$(1)\quad\boxed{y|x;\theta\sim\textrm{ExpFamily}(\eta)}$</div>
 <div class=col-sm-4>$(2)\quad\boxed{h_\theta(x)=E[y|x;\theta]}$</div>
 <div class=col-sm-4>$(3)\quad\boxed{\eta=\theta^Tx}$</div>
</div>
<br>
<p><span class=remark>Remark: ordinary least squares and logistic regression are special cases of generalized linear models.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#svm id=svm></a>Support Vector Machines</h2>
<p>The goal of support vector machines is to find the line that maximizes the minimum distance to the line.</p>
<p><span class=""new-item item-b"">Optimal margin classifier</span> The optimal margin classifier $h$ is such that:</p>
<div class=mobile-container>
\[\boxed{h(x)=\textrm{sign}(w^Tx-b)}\]
</div>
<p>where $(w, b)\in\mathbb{R}^n\times\mathbb{R}$ is the solution of the following optimization problem:</p>
<div class=mobile-container>
\[\boxed{\min\frac{1}{2}||w||^2}\quad\quad\textrm{such that }\quad \boxed{y^{(i)}(w^Tx^{(i)}-b)\geqslant1}\]
</div>
<center>
  <img alt=SVM class=img-responsive src=teaching/cs-229/illustrations/svm-en.png?d23456fe589935f26cf32c1664c90851 style=width:100%;max-width:600px>
</center>
<p><span class=remark>Remark: the decision boundary is defined as $\boxed{w^Tx-b=0}$.</span></p>
<br>
<p><span class=""new-item item-b"">Hinge loss</span> The hinge loss is used in the setting of SVMs and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=[1-yz]_+=\max(0,1-yz)}\]
</div>
<br>
<p><span class=""new-item item-b"">Kernel</span> Given a feature mapping $\phi$, we define the kernel $K$ as follows:</p>
<div class=mobile-container>
\[\boxed{K(x,z)=\phi(x)^T\phi(z)}\]
</div>
<p>In practice, the kernel $K$ defined by $K(x,z)=\exp\left(-\frac{||x-z||^2}{2\sigma^2}\right)$ is called the Gaussian kernel and is commonly used.</p>
<center>
  <img alt=""SVM kernel"" class=img-responsive src=teaching/cs-229/illustrations/svm-kernel-en.png?43f2af419ba926948a5bbf3289f2cf39>
</center>
<br>
<p><span class=remark>Remark: we say that we use the ""kernel trick"" to compute the cost function using the kernel because we actually don't need to know the explicit mapping $\phi$, which is often very complicated. Instead, only the values $K(x,z)$ are needed.</span></p>
<br>
<p><span class=""new-item item-r"">Lagrangian</span> We define the Lagrangian $\mathcal{L}(w,b)$ as follows:</p>
<div class=mobile-container>
\[\boxed{\mathcal{L}(w,b)=f(w)+\sum_{i=1}^l\beta_ih_i(w)}\]
</div>
<p><span class=remark>Remark: the coefficients $\beta_i$ are called the Lagrange multipliers.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#generative-learning id=generative-learning></a>Generative Learning</h2>
<p>A generative model first tries to learn how the data is generated by estimating $P(x|y)$, which we can then use to estimate $P(y|x)$ by using Bayes' rule.</p>
<h3>Gaussian Discriminant Analysis</h3>
<p><span class=""new-item item-b"">Setting</span> The Gaussian Discriminant Analysis assumes that $y$ and $x|y=0$ and $x|y=1$ are such that:</p>
<div class=row>
 <div class=col-sm-4>$(1)\quad\boxed{y\sim\textrm{Bernoulli}(\phi)}$</div>
 <div class=col-sm-4>$(2)\quad\boxed{x|y=0\sim\mathcal{N}(\mu_0,\Sigma)}$</div>
 <div class=col-sm-4>$(3)\quad\boxed{x|y=1\sim\mathcal{N}(\mu_1,\Sigma)}$</div>
</div>
<br>
<p><span class=""new-item item-b"">Estimation</span> The following table sums up the estimates that we find when maximizing the likelihood:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>$\widehat{\phi}$</b></td>
<td align=right><b>$\widehat{\mu_j}\quad{\small(j=0,1)}$</b></td>
<td align=center><b>$\widehat{\Sigma}$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m1_{\{y^{(i)}=1\}}$</td>
<td align=center>$\displaystyle\frac{\sum_{i=1}^m1_{\{y^{(i)}=j\}}x^{(i)}}{\sum_{i=1}^m1_{\{y^{(i)}=j\}}}$</td>
<td align=center>$\displaystyle\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Naive Bayes</h3>
<p><span class=""new-item item-b"">Assumption</span> The Naive Bayes model supposes that the features of each data point are all independent:</p>
<div class=mobile-container>
\[\boxed{P(x|y)=P(x_1,x_2,...|y)=P(x_1|y)P(x_2|y)...=\prod_{i=1}^nP(x_i|y)}\]
</div>
<br>
<p><span class=""new-item item-r"">Solutions</span> Maximizing the log-likelihood gives the following solutions:
</p><div class=mobile-container>
\[\boxed{P(y=k)=\frac{1}{m}\times\#\{j|y^{(j)}=k\}}\quad\textrm{ and }\quad\boxed{P(x_i=l|y=k)=\frac{\#\{j|y^{(j)}=k\textrm{ and }x_i^{(j)}=l\}}{\#\{j|y^{(j)}=k\}}}\]
</div>
with $k\in\{0,1\}$ and $l\in[\![1,L]\!]$<p></p>
<p><span class=remark>Remark: Naive Bayes is widely used for text classification and spam detection.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#tree id=tree></a>Tree-based and ensemble methods</h2>
<p>These methods can be used for both regression and classification problems.</p>
<p><span class=""new-item item-b"">CART</span> Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable.</p>
<br>
<p><span class=""new-item item-b"">Random forest</span> It is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm.</p>
<p><span class=remark>Remark: random forests are a type of ensemble methods.</span></p>
<br>
<p><span class=""new-item item-b"">Boosting</span> The idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Adaptive boosting</b></td>
<td align=center><b>Gradient boosting</b></td>
</tr>
<tr>
<td align=left>• High weights are put on errors to improve at the next boosting step<br>
• Known as Adaboost</td>
<td align=left>• Weak learners are trained on residuals<br>
• Examples include XGBoost</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#other id=other></a>Other non-parametric approaches</h2>
<p><span class=""new-item item-b"">$k$-nearest neighbors</span> The $k$-nearest neighbors algorithm, commonly known as $k$-NN, is a non-parametric approach where the response of a data point is determined by the nature of its $k$ neighbors from the training set. It can be used in both classification and regression settings.</p>
<p><span class=remark>Remark: the higher the parameter $k$, the higher the bias, and the lower the parameter $k$, the higher the variance.</span></p>
<div class=mobile-container>
<center>
  <img alt=""k nearest neighbors"" class=img-responsive src=teaching/cs-229/illustrations/k-nearest-neighbors.png?02f80a524bb11e2b7a70b58c9ed3b0f4 style=width:100%;max-width:740px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#learning-theory id=learning-theory></a>Learning Theory</h2>
<p><span class=""new-item item-r"">Union bound</span> Let $A_1, ..., A_k$ be $k$ events. We have:</p>
<div class=mobile-container>
\[\boxed{P(A_1\cup ...\cup A_k)\leqslant P(A_1)+...+P(A_k)}\]
</div>
<center>
<img alt=""Union bound"" class=img-responsive src=teaching/cs-229/illustrations/union-bound.png?aab917859fa8e260e865def69a2889b8 style=width:100%;max-width:700px>
</center>
<br>
<p><span class=""new-item item-r"">Hoeffding inequality</span> Let $Z_1, .., Z_m$ be $m$ iid variables drawn from a Bernoulli distribution of parameter $\phi$. Let $\widehat{\phi}$ be their sample mean and $\gamma&gt;0$ fixed. We have:</p>
<div class=mobile-container>
\[\boxed{P(|\phi-\widehat{\phi}|&gt;\gamma)\leqslant2\exp(-2\gamma^2m)}\]
</div>
<p><span class=remark>Remark: this inequality is also known as the Chernoff bound.</span></p>
<br>
<p><span class=""new-item item-g"">Training error</span> For a given classifier $h$, we define the training error $\widehat{\epsilon}(h)$, also known as the empirical risk or empirical error, to be as follows:</p>
<div class=mobile-container>
\[\boxed{\widehat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^m1_{\{h(x^{(i)})\neq y^{(i)}\}}}\]
</div>
<br>
<p><span class=""new-item item-g"">Probably Approximately Correct (PAC)</span> PAC is a framework under which numerous results on learning theory were proved, and has the following set of assumptions:</p>
<ul>
	<li>the training and testing sets follow the same distribution</li>
	<li>the training examples are drawn independently</li>
</ul>
<br>
<p><span class=""new-item item-g"">Shattering</span> Given a set $S=\{x^{(1)},...,x^{(d)}\}$, and a set of classifiers $\mathcal{H}$, we say that $\mathcal{H}$ shatters $S$ if for any set of labels $\{y^{(1)}, ..., y^{(d)}\}$, we have:</p>
<div class=mobile-container>
\[\boxed{\exists h\in\mathcal{H}, \quad \forall i\in[\![1,d]\!],\quad h(x^{(i)})=y^{(i)}}\]
</div>
<br>
<p><span class=""new-item item-r"">Upper bound theorem</span> Let $\mathcal{H}$ be a finite hypothesis class such that $|\mathcal{H}|=k$ and let $\delta$ and the sample size $m$ be fixed. Then, with probability of at least $1-\delta$, we have:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant\left(\min_{h\in\mathcal{H}}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}\log\left(\frac{2k}{\delta}\right)}}\]
</div>
<br>
<p><span class=""new-item item-g"">VC dimension</span> The Vapnik-Chervonenkis (VC) dimension of a given infinite hypothesis class $\mathcal{H}$, noted $\textrm{VC}(\mathcal{H})$ is the size of the largest set that is shattered by $\mathcal{H}$.</p>
<p><span class=remark>Remark: the VC dimension of ${\small\mathcal{H}=\{\textrm{set of linear classifiers in 2 dimensions}\}}$ is 3.</span></p>
<center>
  <img alt=""VC dimension"" class=img-responsive src=teaching/cs-229/illustrations/vc-dimension.png?73859dedcc66a0e47526936f801b7b56>
</center>
<br>
<p><span class=""new-item item-r"">Theorem (Vapnik)</span> Let $\mathcal{H}$ be given, with $\textrm{VC}(\mathcal{H})=d$ and $m$ the number of training examples. With probability at least $1-\delta$, we have:</p>
<div class=mobile-container>
\[\boxed{\epsilon(\widehat{h})\leqslant \left(\min_{h\in\mathcal{H}}\epsilon(h)\right) + O\left(\sqrt{\frac{d}{m}\log\left(\frac{m}{d}\right)+\frac{1}{m}\log\left(\frac{1}{\delta}\right)}\right)}\]
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
10,"مرجع سريع للتعلّم غير المُوَجَّه

مقدمة للتعلّم غير المُوَجَّه

الحافز الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.

متباينة جينسن لتكن $f$ دالة محدبة و $X$ متغير عشوائي. لدينا المتباينة التالية:

\[\boxed{E[f(X)]\geqslant f(E[X])}\]

التجميع

تعظيم القيمة المتوقعة (Expectation-Maximization)

المتغيرات الكامنة المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$. في مايلي الإعدادات الشائعة التي تحتوي على متغيرات كامنة:

الإعداد المتغير الكامن $z$ $x|z$ ملاحظات خليط من $k$ توزيع جاوسي $\textrm{Multinomial}(\phi)$ $\mathcal{N}(\mu_j,\Sigma_j)$ $\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$ تحليل عاملي $\mathcal{N}(0,I)$ $\mathcal{N}(\mu+\Lambda z,\psi)$ $\mu_j\in\mathbb{R}^n$

خوارزمية تعظيم القيمة المتوقعة (Expectation-Maximization) هي عبارة عن طريقة فعالة لتقدير المُدخل $\theta$ عبر تقدير تقدير الأرجحية الأعلى (maximum likelihood estimation)، ويتم ذلك بشكل تكراري حيث يتم إيجاد حد أدنى للأرجحية (الخطوة M)، ثم يتم تحسين (optimizing) ذلك الحد الأدنى (الخطوة E)، كما يلي:

- الخطوة E : حساب الاحتمال البعدي $Q_{i}(z^{(i)})$ بأن تصدر كل نقطة $x^{(i)}$ من مجموعة (cluster) $z^{(i)}$ كما يلي:

\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]

- الخطوة M : يتم استعمال الاحتمالات البعدية $Q_i(z^{(i)})$ كأوزان خاصة لكل مجموعة (cluster) على النقط $x^{(i)}$، لكي يتم تقدير نموذج لكل مجموعة بشكل منفصل، و ذلك كما يلي:

\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]

التجميع بالمتوسطات $k$ (k means clustering)

نرمز لمجموعة النقط $i$ بـ $c^{(i)}$، ونرمز بـ $\mu_j$ مركز المجموعات $j$.

خوارزمية بعد الاستهلال العشوائي للنقاط المركزية (centroids) للمجوعات $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$، التجميع بالمتوسطات $k$ تكرر الخطوة التالية حتى التقارب:

\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{و}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]

دالة التحريف (distortion function) لكي نتأكد من أن الخوارزمية تقاربت، ننظر إلى دالة التحريف المعرفة كما يلي:

\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]

التجميع الهرمي

خوارزمية هي عبارة عن خوارزمية تجميع تعتمد على طريقة تجميع هرمية تبني مجموعات متداخلة بشكل متتال.

الأنواع هنالك عدة أنواع من خوارزميات التجميع الهرمي التي ترمي إلى تحسين دوال هدف (objective function) مختلفة، هذه الأنواع ملخصة في الجدول التالي:

ربط وارْد (ward linkage) الربط المتوسط الربط الكامل تصغير المسافة داخل المجموعة تصغير متوسط المسافة بين أزواج المجموعات تصغير المسافة العظمى بين أزواج المجموعات

مقاييس تقدير المجموعات

في التعلّم غير المُوَجَّه من الصعب غالباً تقدير أداء نموذج ما، لأن القيم الحقيقية تكون غير متوفرة كما هو الحال في التعلًم المُوَجَّه.

معامل الظّل (silhouette coefficient) إذا رمزنا $a$ و $b$ لمتوسط المسافة بين عينة وكل النقط المنتمية لنفس الصنف، و بين عينة وكل النقط المنتمية لأقرب مجموعة، المعامل الظِلِّي $s$ لعينة واحدة معرف كالتالي:

\[\boxed{s=\frac{b-a}{\max(a,b)}}\]

مؤشر كالينسكي-هارباز (Calinski-Harabaz index) إذا رمزنا بـ $k$ لعدد المجموعات، فإن $B_k$ و $W_k$ مصفوفتي التشتت بين المجموعات وداخلها تعرف كالتالي:

\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]

مؤشر كالينسكي-هارباز $s(k)$ يشير إلى جودة نموذج تجميعي في تعريف مجموعاته، بحيث كلما كانت النتيجة أعلى كلما دل ذلك على أن المجموعات أكثر كثافة وأكثر انفصالاً فيما بينها. هذا المؤشر معرّف كالتالي:

\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]

تقليص الأبعاد

تحليل المكون الرئيس

إنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.

قيمة ذاتية (eigenvalue)، متجه ذاتي (eigenvector) لتكن $A\in\mathbb{R}^{n\times n}$ مصفوفة، نقول أن $\lambda$ قيمة ذاتية للمصفوفة $A$ إذا وُجِد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجهاً ذاتياً، بحيث:

\[\boxed{Az=\lambda z}\]

مبرهنة الطّيف (spectral theorem) لتكن $A\in\mathbb{R}^{n\times n}$. إذا كانت $A$ متناظرة فإنها يمكن أن تكون شبه قطرية عن طريق مصفوفة متعامدة حقيقية $U\in\mathbb{R}^{n\times n}$. إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:

\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]

ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي (principal eigenvector) للمصفوفة $A$.

خوارزمية تحليل المكون الرئيس (Principal Component Analysis, PCA) طريقة لخفض الأبعاد تهدف إلى إسقاط البيانات على $k$ بُعد بحيث يتم تعطيم التباين (variance)، خطواتها كالتالي:

- الخطوة 1 : تسوية البيانات بحيث تصبح ذات متوسط يساوي صفر وانحراف معياري يساوي واحد.

\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{و}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]

- الخطوة 2 : حساب $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$، وهي متناظرة وذات قيم ذاتية حقيقية.

- الخطوة 3 : حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.

- الخطوة 4 : إسقاط البيانات على $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.

هذا الإجراء يعظم التباين بين كل الفضاءات البُعدية.

تحليل المكونات المستقلة

هي طريقة تهدف إلى إيجاد المصادر التوليدية الكامنة.

افتراضات لنفترض أن بياناتنا $x$ تم توليدها عن طريق المتجه المصدر $s=(s_1,...,s_n)$ ذا $n$ بُعد، حيث $s_i$ متغيرات عشوائية مستقلة، وذلك عبر مصفوفة خلط غير منفردة (mixing and non-singular) $A$ كالتالي:

\[\boxed{x=As}\]

الهدف هو العثور على مصفوفة الفصل $W=A^{-1}$.

خوارزمية تحليل المكونات المستقلة (ICA) لبيل وسجنوسكي (Bell and Sejnowski) هذه الخوارزمية تجد مصفوفة الفصل $W$ عن طريق الخطوات التالية:

- اكتب الاحتمال لـ $x=As=W^{-1}s$ كالتالي:

\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]

- لتكن $\{x^{(i)}, i\in[\![1,m]\!]\}$ بيانات التمرن و $g$ دالة سيجمويد، اكتب الأرجحية اللوغاريتمية (log likelihood) كالتالي:

\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]

هكذا، باستخدام الصعود الاشتقاقي العشوائي (stochastic gradient ascent)، لكل عينة تدريب $x^{(i)}$ نقوم بتحديث $W$ كما يلي:

\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]","مرجع سريع للتعلّم غير المُوَجَّهمقدمة للتعلّم غير المُوَجَّهالحافز الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.
لدينا المتباينة التالية:\[\boxed{E[f(X)]\geqslant f(E[X])}\]التجميعتعظيم القيمة المتوقعة (Expectation-Maximization)المتغيرات الكامنة المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$.
هذا المؤشر معرّف كالتالي:\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]تقليص الأبعادتحليل المكون الرئيسإنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.
إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي (principal eigenvector) للمصفوفة $A$.
- الخطوة 3 : حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.","['إلى', 'المجموعات', 'الخطوة', 'تقدير', 'البيانات', 'إذا', 'مصفوفة', 'يتم', 'تعلم', 'k', 'طريقة', 'موجه']",ar,تعلم غير موجَّه,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>تعلم غير موجَّه - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-unsupervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلم غير موجَّه</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#intro>مقدمة</a></div> <div class=dropdown-container> <a href=#intro><span>الحافز</span></a> <a href=#intro><span>متباينة جينسن</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#clustering>التجميع</a></div> <div class=dropdown-container> <a href=#clustering><span>تعظيم القيمة المتوقعة</span></a> <a href=#clustering><span>تجميع <span class=ltr>k</span>-متوسطات</span></a> <a href=#clustering><span>التجميع الهرمي</span></a> <a href=#clustering><span>مقاييس</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#dimension-reduction>تقليص الأبعاد</a></div> <div class=dropdown-container> <a href=#dimension-reduction><span>تحليل المكون الرئيس <span class=ltr>(PCA)</span></span></a> <a href=#dimension-reduction><span>تحليل المكونات المستقلة <span class=ltr>(ICA)</span></span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-unsupervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button><b>تعلم غير موجَّه</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع للتعلّم غير المُوَجَّه</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة رضوان لغوينسات. تمت المراجعة بواسطة فارس القنيعير.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#intro id=intro></a>مقدمة للتعلّم غير المُوَجَّه</h2>
<p><span class=""new-item item-b"">الحافز</span> الهدف من التعلّم غير المُوَجَّه هو إيجاد الأنماط الخفية في البيانات غير المٌعلمّة $\{x^{(1)},...,x^{(m)}\}$.</p>
<br>
<p><span class=""new-item item-r"">متباينة جينسن</span> لتكن $f$ دالة محدبة و $X$ متغير عشوائي. لدينا المتباينة التالية:</p>
<div class=mobile-container>
\[\boxed{E[f(X)]\geqslant f(E[X])}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#clustering id=clustering></a>التجميع</h2>
<h3>تعظيم القيمة المتوقعة <span class=""ltr stick-together"">(Expectation-Maximization)</span></h3>
<p><span class=""new-item item-r"">المتغيرات الكامنة</span> المتغيرات الكامنة هي متغيرات مخفية/غير معاينة تزيد من صعوبة مشاكل التقدير، غالباً ما ترمز بالحرف $z$. في مايلي الإعدادات الشائعة التي تحتوي على متغيرات كامنة:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>الإعداد</b></td>
<td align=center><b>المتغير الكامن $z$</b></td>
<td align=center>$x|z$</td>
<td align=center><b>ملاحظات</b></td>
</tr>
<tr>
<td align=center>خليط من $k$ توزيع جاوسي</td>
<td align=center>$\textrm{Multinomial}(\phi)$</td>
<td align=center>$\mathcal{N}(\mu_j,\Sigma_j)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$</td>
</tr>
<tr>
<td align=center>تحليل عاملي</td>
<td align=center>$\mathcal{N}(0,I)$</td>
<td align=center>$\mathcal{N}(\mu+\Lambda z,\psi)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> تعظيم القيمة المتوقعة <span class=""ltr stick-together"">(Expectation-Maximization)</span> هي عبارة عن طريقة فعالة لتقدير المُدخل $\theta$ عبر تقدير تقدير الأرجحية الأعلى <span class=""ltr stick-together"">(maximum likelihood estimation)</span>، ويتم ذلك بشكل تكراري حيث يتم إيجاد حد أدنى للأرجحية (الخطوة <span class=""ltr stick-together"">M</span>)، ثم يتم تحسين <span class=""ltr stick-together"">(optimizing)</span> ذلك الحد الأدنى (الخطوة <span class=""ltr stick-together"">E</span>)، كما يلي:</p>
<br><p>- <u>الخطوة <span class=""ltr stick-together"">E</span> </u>: حساب الاحتمال البعدي $Q_{i}(z^{(i)})$ بأن تصدر كل نقطة $x^{(i)}$ من مجموعة <span class=""ltr stick-together"">(cluster)</span> $z^{(i)}$ كما يلي:</p>
<div class=mobile-container>
\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]
</div>
<p>- <u>  الخطوة <span class=""ltr stick-together"">M</span> </u>: يتم استعمال الاحتمالات البعدية $Q_i(z^{(i)})$ كأوزان خاصة لكل مجموعة <span class=""ltr stick-together"">(cluster)</span> على النقط $x^{(i)}$، لكي يتم تقدير نموذج لكل مجموعة بشكل منفصل، و ذلك كما يلي:</p>
<div class=mobile-container>
\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/expectation-maximization-ar.png?648fa970fe475c6ad81fba10453d562a>
</center>
<br>
<h3>التجميع بالمتوسطات $k$ <span class=""ltr stick-together"">(k means clustering)</span></h3>
<p>نرمز لمجموعة النقط $i$ بـ $c^{(i)}$، ونرمز بـ $\mu_j$ مركز المجموعات $j$.</p>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> بعد الاستهلال العشوائي للنقاط المركزية <span class=""ltr stick-together"">(centroids)</span> للمجوعات $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$، التجميع بالمتوسطات $k$ تكرر الخطوة التالية حتى التقارب:</p>
<div class=mobile-container>
\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{و}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/k-means-ar.png?3dfcdd31f92a900fef44fb3d507c1f39>
</center>
<br>
<p><span class=""new-item item-b"">دالة التحريف <span class=""ltr stick-together"">(distortion function)</span></span> لكي نتأكد من أن الخوارزمية تقاربت، ننظر إلى دالة التحريف المعرفة كما يلي:</p>
<div class=mobile-container>
\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]
</div>
<br>
<h3>التجميع الهرمي</h3>
<p><span class=""new-item item-g"">خوارزمية</span> هي عبارة عن خوارزمية تجميع تعتمد على طريقة تجميع هرمية تبني مجموعات متداخلة بشكل متتال.</p>
<br>
<p><span class=""new-item item-b"">الأنواع</span> هنالك عدة أنواع من خوارزميات التجميع الهرمي التي ترمي إلى تحسين دوال هدف <span class=""ltr stick-together"">(objective function)</span> مختلفة، هذه الأنواع ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>ربط وارْد <span class=""ltr stick-together"">(ward linkage)</span></b></td>
<td align=center><b>الربط المتوسط</b></td>
<td align=center><b>الربط الكامل</b></td>
</tr>
<tr>
<td align=center>تصغير المسافة داخل المجموعة</td>
<td align=center>تصغير متوسط المسافة بين أزواج المجموعات</td>
<td align=center>تصغير المسافة العظمى بين أزواج المجموعات</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>مقاييس تقدير المجموعات</h3>
<p>في التعلّم غير المُوَجَّه من الصعب غالباً تقدير أداء نموذج ما، لأن القيم الحقيقية تكون غير متوفرة كما هو الحال في التعلًم المُوَجَّه.</p>
<p><span class=""new-item item-b"">معامل الظّل <span class=""ltr stick-together"">(silhouette coefficient)</span></span> إذا رمزنا $a$ و $b$ لمتوسط المسافة بين عينة وكل النقط المنتمية لنفس الصنف، و بين عينة وكل النقط المنتمية لأقرب مجموعة، المعامل الظِلِّي $s$ لعينة واحدة معرف كالتالي:</p>
<div class=mobile-container>
\[\boxed{s=\frac{b-a}{\max(a,b)}}\]
</div>
<br>
<p><span class=""new-item item-b"">مؤشر كالينسكي-هارباز <span class=""ltr stick-together"">(Calinski-Harabaz index)</span></span> إذا رمزنا بـ $k$ لعدد المجموعات، فإن $B_k$ و $W_k$ مصفوفتي التشتت بين المجموعات وداخلها تعرف كالتالي:</p>
<div class=mobile-container>
\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]
</div>
<p>مؤشر كالينسكي-هارباز $s(k)$ يشير إلى جودة نموذج تجميعي في تعريف مجموعاته، بحيث كلما كانت النتيجة أعلى كلما دل ذلك على أن المجموعات أكثر كثافة وأكثر انفصالاً فيما بينها. هذا المؤشر معرّف كالتالي:</p>
<div class=mobile-container>
\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#dimension-reduction id=dimension-reduction></a>تقليص الأبعاد</h2>
<h3>تحليل المكون الرئيس</h3>
<p>إنها طريقة لتقليص الأبعاد ترمي إلى إيجاد الاتجاهات المعظمة للتباين من أجل إسقاط البيانات عليها.</p>
<p><span class=""new-item item-b"">قيمة ذاتية <span class=""ltr stick-together"">(eigenvalue)</span>، متجه ذاتي <span class=""ltr stick-together"">(eigenvector)</span></span> لتكن $A\in\mathbb{R}^{n\times n}$ مصفوفة، نقول أن $\lambda$ قيمة ذاتية للمصفوفة $A$ إذا وُجِد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجهاً ذاتياً، بحيث:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">مبرهنة الطّيف <span class=""ltr stick-together"">(spectral theorem)</span></span> لتكن $A\in\mathbb{R}^{n\times n}$. إذا كانت $A$ متناظرة فإنها يمكن أن تكون شبه قطرية عن طريق مصفوفة متعامدة حقيقية $U\in\mathbb{R}^{n\times n}$. إذا رمزنا $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ ، لدينا:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda,\quad A=U\Lambda U^T}\]
</div>
<br>
<p><i>ملحوظة: المتجه الذاتي المرتبط بأكبر قيمة ذاتية يسمى بالمتجه الذاتي الرئيسي <span class=""ltr stick-together"">(principal eigenvector)</span> للمصفوفة $A$.</i></p>
<br>
<p><span class=""new-item item-g"">خوارزمية</span> تحليل المكون الرئيس <span class=""ltr stick-together"">(Principal Component Analysis, PCA)</span> طريقة لخفض الأبعاد تهدف إلى إسقاط البيانات على $k$ بُعد بحيث يتم تعطيم التباين <span class=""ltr stick-together"">(variance)</span>، خطواتها كالتالي:</p>
<br><p>- <u>الخطوة 1</u>: تسوية البيانات بحيث تصبح ذات متوسط يساوي صفر وانحراف معياري يساوي واحد.</p>
<div class=mobile-container>
\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{و}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]
</div>
<br><p>- <u>الخطوة 2</u>: حساب $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$، وهي متناظرة وذات قيم ذاتية حقيقية.
<br>- <u>الخطوة 3</u>: حساب $u_1, ..., u_k\in\mathbb{R}^n$ المتجهات الذاتية الرئيسية المتعامدة لـ $\Sigma$ وعددها $k$ ، بعبارة أخرى، $k$ من المتجهات الذاتية المتعامدة ذات القيم الذاتية الأكبر.
<br>- <u>الخطوة 4</u>: إسقاط البيانات على $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.</p>
<p>هذا الإجراء يعظم التباين بين كل الفضاءات البُعدية.</p>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/pca-ar.png?700b7fcad5a743233edf410818b4a45e>
</center>
<br>
<h3>تحليل المكونات المستقلة</h3>
<p>هي طريقة تهدف إلى إيجاد المصادر التوليدية الكامنة.</p>
<p><span class=""new-item item-r"">افتراضات</span> لنفترض أن بياناتنا $x$ تم توليدها عن طريق المتجه المصدر $s=(s_1,...,s_n)$ ذا $n$ بُعد، حيث $s_i$ متغيرات عشوائية مستقلة، وذلك عبر مصفوفة خلط غير منفردة <span class=""ltr stick-together"">(mixing and non-singular)</span> $A$ كالتالي:</p>
<div class=mobile-container>
\[\boxed{x=As}\]
</div>
<p>الهدف هو العثور على مصفوفة الفصل $W=A^{-1}$.</p>
<br>
<p><span class=""new-item item-g"">خوارزمية تحليل المكونات المستقلة <span class=""ltr stick-together"">(ICA)</span> لبيل وسجنوسكي <span class=""ltr stick-together"">(Bell and Sejnowski)</span></span> هذه الخوارزمية تجد مصفوفة الفصل $W$ عن طريق الخطوات التالية:
<br>- اكتب الاحتمال لـ $x=As=W^{-1}s$ كالتالي:</p>
<div class=mobile-container>
\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]
</div>
<br><p>- لتكن $\{x^{(i)}, i\in[\![1,m]\!]\}$ بيانات التمرن و $g$ دالة سيجمويد، اكتب الأرجحية اللوغاريتمية <span class=""ltr stick-together"">(log likelihood)</span> كالتالي:</p>
<div class=mobile-container>
\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]
</div>
<p>هكذا، باستخدام الصعود الاشتقاقي العشوائي <span class=""ltr stick-together"">(stochastic gradient ascent)</span>، لكل عينة تدريب $x^{(i)}$ نقوم بتحديث $W$ كما يلي:</p>
<div class=mobile-container>
\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]
</div>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
11,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Unsupervised Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Introduction to Unsupervised Learning

Motivation The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.

Jensen's inequality Let $f$ be a convex function and $X$ a random variable. We have the following inequality:

\[\boxed{E[f(X)]\geqslant f(E[X])}\]

Clustering

Expectation-Maximization

Latent variables Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$. Here are the most common settings where there are latent variables:

Setting Latent variable $z$ $x|z$ Comments Mixture of $k$ Gaussians $\textrm{Multinomial}(\phi)$ $\mathcal{N}(\mu_j,\Sigma_j)$ $\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$ Factor analysis $\mathcal{N}(0,I)$ $\mathcal{N}(\mu+\Lambda z,\psi)$ $\mu_j\in\mathbb{R}^n$

Algorithm The Expectation-Maximization (EM) algorithm gives an efficient method at estimating the parameter $\theta$ through maximum likelihood estimation by repeatedly constructing a lower-bound on the likelihood (E-step) and optimizing that lower bound (M-step) as follows:

E-step : Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows: \[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]

: Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows: M-step : Use the posterior probabilities $Q_i(z^{(i)})$ as cluster specific weights on data points $x^{(i)}$ to separately re-estimate each cluster model as follows: \[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]

$k$-means clustering

We note $c^{(i)}$ the cluster of data point $i$ and $\mu_j$ the center of cluster $j$.

Algorithm After randomly initializing the cluster centroids $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$, the $k$-means algorithm repeats the following step until convergence:

\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{and}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]

Distortion function In order to see if the algorithm converges, we look at the distortion function defined as follows:

\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]

Hierarchical clustering

Algorithm It is a clustering algorithm with an agglomerative hierarchical approach that build nested clusters in a successive manner.

Types There are different sorts of hierarchical clustering algorithms that aims at optimizing different objective functions, which is summed up in the table below:

Ward linkage Average linkage Complete linkage Minimize within cluster distance Minimize average distance between cluster pairs Minimize maximum distance of between cluster pairs

Clustering assessment metrics

In an unsupervised learning setting, it is often hard to assess the performance of a model since we don't have the ground truth labels as was the case in the supervised learning setting.

Silhouette coefficient By noting $a$ and $b$ the mean distance between a sample and all other points in the same class, and between a sample and all other points in the next nearest cluster, the silhouette coefficient $s$ for a single sample is defined as follows:

\[\boxed{s=\frac{b-a}{\max(a,b)}}\]

Calinski-Harabaz index By noting $k$ the number of clusters, $B_k$ and $W_k$ the between and within-clustering dispersion matrices respectively defined as

\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]

\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]

Dimension reduction

Principal component analysis

It is a dimension reduction technique that finds the variance maximizing directions onto which to project the data.

Eigenvalue, eigenvector Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:

\[\boxed{Az=\lambda z}\]

Spectral theorem Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:

\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]

Remark: the eigenvector associated with the largest eigenvalue is called principal eigenvector of matrix $A$.

Algorithm The Principal Component Analysis (PCA) procedure is a dimension reduction technique that projects the data on $k$ dimensions by maximizing the variance of the data as follows:

Step 1 : Normalize the data to have a mean of 0 and standard deviation of 1. \[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{and}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]

: Normalize the data to have a mean of 0 and standard deviation of 1. Step 2 : Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues.

: Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues. Step 3 : Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues.

: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues. Step 4 : Project the data on $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.

This procedure maximizes the variance among all $k$-dimensional spaces.

Independent component analysis

It is a technique meant to find the underlying generating sources.

Assumptions We assume that our data $x$ has been generated by the $n$-dimensional source vector $s=(s_1,...,s_n)$, where $s_i$ are independent random variables, via a mixing and non-singular matrix $A$ as follows:

\[\boxed{x=As}\]

The goal is to find the unmixing matrix $W=A^{-1}$.

Bell and Sejnowski ICA algorithm This algorithm finds the unmixing matrix $W$ by following the steps below:

Write the probability of $x=As=W^{-1}s$ as: \[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]

Write the log likelihood given our training data $\{x^{(i)}, i\in[\![1,m]\!]\}$ and by noting $g$ the sigmoid function as: \[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]

\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksUnsupervised Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiIntroduction to Unsupervised LearningMotivation The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.
We have the following inequality:\[\boxed{E[f(X)]\geqslant f(E[X])}\]ClusteringExpectation-MaximizationLatent variables Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$.
If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$.
Step 3 : Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e.
: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e.","['matrix', 'algorithm', 'xi', 'variables', 'cluster', 'learning', 'unsupervised', 'cheatsheet', 'n', 'k', 'data', 'orthogonal']",en,Unsupervised Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Unsupervised Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Unsupervised Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#intro>Introduction</a></div> <div class=dropdown-container> <a href=#intro><span>Motivation</span></a> <a href=#intro><span>Jensen's inequality</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#clustering>Clustering</a></div> <div class=dropdown-container> <a href=#clustering><span>Expectation-Maximization</span></a> <a href=#clustering><span>k-means</span></a> <a href=#clustering><span>Hierarchical clustering</span></a> <a href=#clustering><span>Metrics</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#dimension-reduction>Dimension reduction</a></div> <div class=dropdown-container> <a href=#dimension-reduction><span>PCA</span></a> <a href=#dimension-reduction><span>ICA</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-unsupervised-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button><b>Unsupervised Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Unsupervised Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#intro id=intro></a>Introduction to Unsupervised Learning</h2>
<p><span class=""new-item item-b"">Motivation</span> The goal of unsupervised learning is to find hidden patterns in unlabeled data $\{x^{(1)},...,x^{(m)}\}$.</p>
<br>
<p><span class=""new-item item-r"">Jensen's inequality</span> Let $f$ be a convex function and $X$ a random variable. We have the following inequality:</p>
<div class=mobile-container>
\[\boxed{E[f(X)]\geqslant f(E[X])}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#clustering id=clustering></a>Clustering</h2>
<h3>Expectation-Maximization</h3>
<p><span class=""new-item item-r"">Latent variables</span> Latent variables are hidden/unobserved variables that make estimation problems difficult, and are often denoted $z$. Here are the most common settings where there are latent variables:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Setting</b></td>
<td align=center><b>Latent variable $z$</b></td>
<td align=center>$x|z$</td>
<td align=center><b>Comments</b></td>
</tr>
<tr>
<td align=center>Mixture of $k$ Gaussians</td>
<td align=center>$\textrm{Multinomial}(\phi)$</td>
<td align=center>$\mathcal{N}(\mu_j,\Sigma_j)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n, \phi\in\mathbb{R}^k$</td>
</tr>
<tr>
<td align=center>Factor analysis</td>
<td align=center>$\mathcal{N}(0,I)$</td>
<td align=center>$\mathcal{N}(\mu+\Lambda z,\psi)$</td>
<td align=center>$\mu_j\in\mathbb{R}^n$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Algorithm</span> The Expectation-Maximization (EM) algorithm gives an efficient method at estimating the parameter $\theta$ through maximum likelihood estimation by repeatedly constructing a lower-bound on the likelihood (E-step) and optimizing that lower bound (M-step) as follows:
</p><ul>
<li><u>E-step</u>: Evaluate the posterior probability $Q_{i}(z^{(i)})$ that each data point $x^{(i)}$ came from a particular cluster $z^{(i)}$ as follows:
<div class=mobile-container>
\[\boxed{Q_i(z^{(i)})=P(z^{(i)}|x^{(i)};\theta)}\]
</div>
</li><li><u>M-step</u>: Use the posterior probabilities $Q_i(z^{(i)})$ as cluster specific weights on data points $x^{(i)}$ to separately re-estimate each cluster model as follows:
<div class=mobile-container>
\[\boxed{\theta_i=\underset{\theta}{\textrm{argmax }}\sum_i\int_{z^{(i)}}Q_i(z^{(i)})\log\left(\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right)dz^{(i)}}\]<p></p>
</div>
</li></ul>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/expectation-maximization-en.png?ed72a10f73a6d201e2ad20e04d145e82>
</center>
<br>
<h3>$k$-means clustering</h3>
<p>We note $c^{(i)}$ the cluster of data point $i$ and $\mu_j$ the center of cluster $j$.</p>
<br>
<p><span class=""new-item item-g"">Algorithm</span> After randomly initializing the cluster centroids $\mu_1,\mu_2,...,\mu_k\in\mathbb{R}^n$, the $k$-means algorithm repeats the following step until convergence:</p>
<div class=mobile-container>
\[\boxed{c^{(i)}=\underset{j}{\textrm{arg min}}||x^{(i)}-\mu_j||^2}\quad\textrm{and}\quad\boxed{\mu_j=\frac{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}x^{(i)}}{\displaystyle\sum_{i=1}^m1_{\{c^{(i)}=j\}}}}\]
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/k-means-en.png?9925605d814ddadebcae2ae4754ab0a4>
</center>
<br>
<p><span class=""new-item item-b"">Distortion function</span> In order to see if the algorithm converges, we look at the distortion function defined as follows:</p>
<div class=mobile-container>
\[\boxed{J(c,\mu)=\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2}\]
</div>
<br>
<h3>Hierarchical clustering</h3>
<p><span class=""new-item item-g"">Algorithm</span> It is a clustering algorithm with an agglomerative hierarchical approach that build nested clusters in a successive manner.</p>
<br>
<p><span class=""new-item item-b"">Types</span> There are different sorts of hierarchical clustering algorithms that aims at optimizing different objective functions, which is summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Ward linkage</b></td>
<td align=center><b>Average linkage</b></td>
<td align=center><b>Complete linkage</b></td>
</tr>
<tr>
<td align=center>Minimize within cluster distance</td>
<td align=center>Minimize average distance between cluster pairs</td>
<td align=center>Minimize maximum distance of between cluster pairs</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Clustering assessment metrics</h3>
<p>In an unsupervised learning setting, it is often hard to assess the performance of a model since we don't have the ground truth labels as was the case in the supervised learning setting.</p>
<p><span class=""new-item item-b"">Silhouette coefficient</span> By noting $a$ and $b$ the mean distance between a sample and all other points in the same class, and between a sample and all other points in the next nearest cluster, the silhouette coefficient $s$ for a single sample is defined as follows:</p>
<div class=mobile-container>
\[\boxed{s=\frac{b-a}{\max(a,b)}}\]
</div>
<br>
<p><span class=""new-item item-b"">Calinski-Harabaz index</span> By noting $k$ the number of clusters, $B_k$ and $W_k$ the between and within-clustering dispersion matrices respectively defined as
</p><div class=mobile-container>
\[B_k=\sum_{j=1}^kn_{c^{(i)}}(\mu_{c^{(i)}}-\mu)(\mu_{c^{(i)}}-\mu)^T,\quad\quad W_k=\sum_{i=1}^m(x^{(i)}-\mu_{c^{(i)}})(x^{(i)}-\mu_{c^{(i)}})^T\]
</div>
the Calinski-Harabaz index $s(k)$ indicates how well a clustering model defines its clusters, such that the higher the score, the more dense and well separated the clusters are. It is defined as follows:<p></p>
<div class=mobile-container>
\[\boxed{s(k)=\frac{\textrm{Tr}(B_k)}{\textrm{Tr}(W_k)}\times\frac{N-k}{k-1}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#dimension-reduction id=dimension-reduction></a>Dimension reduction</h2>
<h3>Principal component analysis</h3>
<p>It is a dimension reduction technique that finds the variance maximizing directions onto which to project the data.</p>
<p><span class=""new-item item-b"">Eigenvalue, eigenvector</span> Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">Spectral theorem</span> Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]
</div>
<br>
<p><span class=remark>Remark: the eigenvector associated with the largest eigenvalue is called principal eigenvector of matrix $A$.</span></p>
<br>
<p><span class=""new-item item-g"">Algorithm</span> The Principal Component Analysis (PCA) procedure is a dimension reduction technique that projects the data on $k$ dimensions by maximizing the variance of the data as follows:
</p><ul>
<li><u>Step 1</u>: Normalize the data to have a mean of 0 and standard deviation of 1.
<div class=mobile-container>
\[\boxed{x_j^{(i)}\leftarrow\frac{x_j^{(i)}-\mu_j}{\sigma_j}}\quad\textrm{where}\quad\boxed{\mu_j = \frac{1}{m}\sum_{i=1}^mx_j^{(i)}}\quad\textrm{and}\quad\boxed{\sigma_j^2=\frac{1}{m}\sum_{i=1}^m(x_j^{(i)}-\mu_j)^2}\]
</div>
</li><li><u>Step 2</u>: Compute $\displaystyle\Sigma=\frac{1}{m}\sum_{i=1}^mx^{(i)}{x^{(i)}}^T\in\mathbb{R}^{n\times n}$, which is symmetric with real eigenvalues.
</li><li><u>Step 3</u>: Compute $u_1, ..., u_k\in\mathbb{R}^n$ the $k$ orthogonal principal eigenvectors of $\Sigma$, i.e. the orthogonal eigenvectors of the $k$ largest eigenvalues.
</li><li><u>Step 4</u>: Project the data on $\textrm{span}_\mathbb{R}(u_1,...,u_k)$.
</li></ul><p></p>
<p>This procedure maximizes the variance among all $k$-dimensional spaces.</p>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/pca-en.png?4be4617788fd40f4e998b530b75f4149>
</center>
<br>
<h3>Independent component analysis</h3>
<p>It is a technique meant to find the underlying generating sources.</p>
<p><span class=""new-item item-r"">Assumptions</span> We assume that our data $x$ has been generated by the $n$-dimensional source vector $s=(s_1,...,s_n)$, where $s_i$ are independent random variables, via a mixing and non-singular matrix $A$ as follows:</p>
<div class=mobile-container>
\[\boxed{x=As}\]
</div>
<p>The goal is to find the unmixing matrix $W=A^{-1}$.</p>
<br>
<p><span class=""new-item item-g"">Bell and Sejnowski ICA algorithm</span> This algorithm finds the unmixing matrix $W$ by following the steps below:
</p><ul>
<li>Write the probability of $x=As=W^{-1}s$ as:
<div class=mobile-container>
\[p(x)=\prod_{i=1}^np_s(w_i^Tx)\cdot|W|\]
</div>
</li><li>Write the log likelihood given our training data $\{x^{(i)}, i\in[\![1,m]\!]\}$ and by noting $g$ the sigmoid function as:
<div class=mobile-container>
\[l(W)=\sum_{i=1}^m\left(\sum_{j=1}^n\log\Big(g'(w_j^Tx^{(i)})\Big)+\log|W|\right)\]
</div>
</li></ul>
Therefore, the stochastic gradient ascent learning rule is such that for each training example $x^{(i)}$, we update $W$ as follows:
<div class=mobile-container>
\[\boxed{W\longleftarrow W+\alpha\left(\begin{pmatrix}1-2g(w_1^Tx^{(i)})\\1-2g(w_2^Tx^{(i)})\\\vdots\\1-2g(w_n^Tx^{(i)})\end{pmatrix}{x^{(i)}}^T+(W^T)^{-1}\right)}\]
</div>
<p></p>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
12,"تعلم آلي - CS ۲۲۹ العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

تعلّم موجَّه تعلم غير موجَّه تعلم متعمق نصائح وحيل

ملخص مختصر التعلم العميق

النص الأصلي بواسطة افشین عمیدی و شروین عمیدی

تمت الترجمة بواسطة امجد الخطابي. تمت المراجعة بواسطة زيد اليافعي.

الشبكة العصبونية الاصطناعية (neural networks)

الشبكة العصبونية الاصطناعيةهي عبارة عن نوع من النماذج يبنى من عدة طبقات , اكثر هذة الانواع استخداما هي الشبكات الالتفافية و الشبكات العصبونية المتكرره البنية المصطلحات حول بنية الشبكة العصبونية موضح في الشكل ادناة

عبر تدوين $i$ كالطبقة رقم $i$ و $j$ للدلالة على رقم الوحده الخفية في تلك الطبقة , نحصل على:

\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]

حيث نعرف $w, b, z$ كالوزن , و معامل التعديل , و الناتج حسب الترتيب.

دالة التفعيل (activation function) دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج. هنا بعض دوال التفعيل الشائعة Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$

و $\epsilon\ll1$

دالة الانتروبيا التقاطعية للخسارة (cross-entropy loss) في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:

\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]

معدل التعلم (learning rate) معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان. يمكن تثبيت هذا المعامل او تحديثة بشكل تأقلمي . حاليا اكثر النسب شيوعا تدعى Adam , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي $\alpha$ او $\eta$ ب ,

التغذية الخلفية (backpropagation) التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج. المشتقة بالنسبة للوزن $w$ يتم حسابها باستخدام قاعدة التسلسل و تكون عبر الشكل الاتي:

\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]

كنتيجة , الوزن سيتم تحديثة كالتالي:

\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]

تحديث الاوزان في الشبكات العصبونية , يتم تحديث الاوزان كما يلي:

- الخطوة 1 : خذ حزمة من بيانات التدريب

- الخطوة 2 : قم بعملية التغذيه الامامية لحساب الخسارة الناتجة

- الخطوة 3 : قم بتغذية خلفية للخساره للحصول على دالة الانحدار

- الخطوة 4 : استخدم قيم الانحدار لتحديث اوزان الشبكة

الاسقاط (dropout) الاسقاط هي طريقة الغرض منها منع التكيف الزائد للنموذج في بيانات التدريب عبر اسقاط بعض الواحدات في الشبكة العصبونية, العصبونات يتم اما اسقاطها باحتمالية $p$ او الحفاظ عليها باحتمالية $1-p$.

الشبكات العصبونية الالتفافية (CNN) احتياج الطبقة الالتفافية عبر رمز $W$ لحجم المدخل , $F$ حجم العصبونات للطبقة الالتفافية , $P$ عدد الحشوات الصفرية , فأن $N$ عدد العصبونات لكل حجم معطى يحسب عبر الاتي:

\[\boxed{N=\frac{W-F+2P}{S}+1}\]

تنظيم الحزمة (batch normalization) هي خطوه من قيم التحسين الخاصة $\gamma, \beta$ والتي تعدل الحزمة $\{x_i\}$. لنجعل $\mu_B, \sigma_B^2$ المتوسط و الانحراف للحزمة المعنية و نريد تصحيح هذه الحزمة, يتم ذلك كالتالي:

\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]

في الغالب تتم بعد الطبقة الالتفافية أو المتصلة كليا و قبل طبقة التغيرات الغير خطية و تهدف للسماح للسرعات التعليم العالية للتقليل من الاعتمادية القوية للقيم الاولية.

الشبكات العصبونية التكرارية (RNN) انواع البوابات هنا الانواع المختلفة التي ممكن مواجهتها في الشبكة العصبونية الاعتيادية: بوابة ادخال بوابة نسيان بوابة منفذ بوابة اخراج كتابة ام عدم كتابة الى الخلية؟ مسح ام عدم مسح الخلية؟ كمية الكتابة الى الخلية ؟ مدى الافصاح عن الخلية ؟

LSTM ذاكرة طويلة قصير الامد (long short-term memory) هي نوع من نموذج ال RNN تستخدم لتجنب مشكلة اختفاء الانحدار عبر اضافة بوابات النسيان.

التعلم و التحكم المعزز (reinforcement learning) الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة. تعريفات عملية ماركوف لاتخاذ القرار عملية ماركوف لاتخاذ القرار هي سلسلة خماسية $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ حيث

- $\mathcal{S}$ هي مجموعة من حالات البيئة

- $\mathcal{A}$ هي مجموعة من حالات الاجراءات

- $\{P_{sa}\}$ هو حالة احتمال الانتقال من الحالة $s\in\mathcal{S}$ و $a\in\mathcal{A}$

- $\gamma\in[0,1[$ هي عامل الخصم

- $R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ هي دالة المكافأة والتي تعمل الخوارزمية على جعلها اعلى قيمة

دالة القواعد دالة القواعد $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ هي التي تقوم بترجمة الحالات الى اجراءات. ملاحظة: نقول ان النموذج ينفذ القاعدة المعينه $\pi$ للحالة المعطاة $s$ ان نتخذ الاجراء$a=\pi(s)$.

دالة القاعدة لاي قاعدة معطاة $\pi$ و حالة $s$, نقوم بتعريف دالة القيمة $V^{\pi}$ كما يلي:

\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]

معادلة بيلمان معادلات بيلمان المثلى تشخص دالة القيمة دالة القيمة $V^{\pi^*}$ $\pi^*$:للقاعدة المثلى

\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]

$\pi^*$ للحالة المعطاه $s$ تعطى كاالتالي: ملاحظة: نلاحظ ان القاعدة المثلى

\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]

خوارزمية تكرار القيمة (value iteration algorithm) خوارزمية تكرار القيمة تكون في خطوتين: 1) نقوم بوضع قيمة اولية:

\[\boxed{V_0(s)=0}\]

2) نقوم بتكرير القيمة حسب القيم السابقة:

\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]

التعلم-$Q$ ($Q$-learning) هي طريقة غير منمذجة لتقدير $Q$, و تتم كالاتي:

\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]","تعلم آلي - CS ۲۲۹ العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 تعلّم موجَّه تعلم غير موجَّه تعلم متعمق نصائح وحيلملخص مختصر التعلم العميقالنص الأصلي بواسطة افشین عمیدی و شروین عمیدیتمت الترجمة بواسطة امجد الخطابي.
دالة التفعيل (activation function) دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج.
هنا بعض دوال التفعيل الشائعة Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$و $\epsilon\ll1$دالة الانتروبيا التقاطعية للخسارة (cross-entropy loss) في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]معدل التعلم (learning rate) معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان.
حاليا اكثر النسب شيوعا تدعى Adam , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي $\alpha$ او $\eta$ ب ,التغذية الخلفية (backpropagation) التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج.
التعلم و التحكم المعزز (reinforcement learning) الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة.","['عبر', 'بوابة', 'القيمة', 'يتم', 'العصبونية', 'التعلم', 'دالة', 'العميق', 'تعلم', 'طريقة', 'الالتفافية']",ar,التعلم العميق,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>التعلم العميق - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-deep-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>تعلم متعمق</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#nn>الشبكة العصبونية الاصطناعية</a></div> <div class=dropdown-container> <a href=#nn><span>البنية </span></a> <a href=#nn><span>دالة التفعيل </span></a> <a href=#nn><span>التغذية الخلفية </span></a> <a href=#nn><span>الاسقاط </span></a> </div> </li> <li> <div class=dropdown-btn><a href=#cnn> الشبكة العصبونية الالتفافية </a></div> <div class=dropdown-container> <a href=#cnn><span>طبقة التفافية </span></a> <a href=#cnn><span>تنظيم الحزمة </span></a> </div> </li> <li> <div class=dropdown-btn><a href=#rnn>الشبكة العصبونية التكرارية </a></div> <div class=dropdown-container> <a href=#rnn><span>البوابات </span></a> <a href=#rnn><span><span class=ltr>LSTM</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#reinforcement>التعلم المعزز</a></div> <div class=dropdown-container> <a href=#reinforcement><span>عملية ماركوف لاتخاذ القرار</span></a> <a href=#reinforcement><span>تكرير القيمة / القاعدة</span></a> <a href=#reinforcement><span>البرمجة الديناميكية التقريبية</span></a> <a href=#reinforcement><span>بحث القاعدة</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-deep-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i></a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button><b>تعلم متعمق</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>نصائح وحيل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>ملخص مختصر التعلم العميق
</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة امجد الخطابي. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<h2><a aria-hidden=true class=anchor href=#nn id=nn></a><div dir=rtl>الشبكة العصبونية الاصطناعية <span class=""ltr stick-together"">(neural networks)</span></div></h2>
<div dir=rtl>
<p>الشبكة العصبونية الاصطناعيةهي عبارة عن نوع من النماذج يبنى من عدة طبقات , اكثر هذة الانواع استخداما هي الشبكات الالتفافية و الشبكات العصبونية المتكرره</p>
<p><span class=""new-item item-g"">البنية</span> المصطلحات حول بنية الشبكة العصبونية موضح في الشكل ادناة</p>
</div>
<center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/neural-network-ar.png?d70a0d6dba75023620ae6b1627790e47 style=width:100%;max-width:700px>
</center>
<div dir=rtl>
<p>عبر تدوين $i$ كالطبقة رقم $i$ و $j$ للدلالة على رقم الوحده الخفية في تلك الطبقة , نحصل على:</p>
</div>
<div class=mobile-container>
\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]
</div>
<div dir=rtl>
<p>حيث نعرف $w, b, z$ كالوزن , و معامل التعديل , و الناتج حسب الترتيب.</p>
<br>
<p><span class=""new-item item-b"">دالة التفعيل <span class=""ltr stick-together"">(activation function)</span></span> دالة التفعيل تستخدم في نهاية الوحده الخفية لتضمن المكونات الغير خطية للنموذج. هنا بعض دوال التفعيل الشائعة</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b class=ltr>Sigmoid</b></td>
<td align=center><b class=ltr>Tanh</b></td>
<td align=center><b class=ltr>ReLU</b></td>
<td align=center><b class=ltr>Leaky ReLU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\displaystyle\frac{1}{1+e^{-z}}$</td>
<td align=center>$g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$</td>
<td align=center>$g(z)=\textrm{max}(0,z)$</td>
<td align=center>$g(z)=\textrm{max}(\epsilon z,z)$<br> و $\epsilon\ll1$</td>
</tr>
<tr>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/sigmoid.png?c91b6e5a7d4e78e95880bcf4e39889df>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/tanh.png?22ac27f27c510c6414e8a3bb4aca2d80>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/relu.png?6c1d78551355db5c6e4f6f8b5282cfa8>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e>
</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">دالة الانتروبيا التقاطعية للخسارة <span class=""ltr stick-together"">(cross-entropy loss)</span></span> في سياق الشبكات العصبونية, دالة الأنتروبيا $L(z,y)$ تستخدم و تعرف كالاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-b"">معدل التعلم <span class=""ltr stick-together"">(learning rate)</span></span> معدل التعلم, يرمز , و هو مؤشر في اي تجاة يتم تحديث الاوزان. يمكن تثبيت هذا المعامل او تحديثة بشكل تأقلمي . حاليا اكثر النسب شيوعا تدعى <span class=""ltr stick-together"">Adam</span> , وهي طريقة تجعل هذه النسبة سرعة التعلم بشكل تأقلمي    $\alpha$ او $\eta$ ب ,</p>
<br>
<p><span class=""new-item item-r"">التغذية الخلفية <span class=""ltr stick-together"">(backpropagation)</span></span> التغذية الخلفية هي طريقة لتحديث الاوزان في الشبكة العصبونية عبر اعتبار القيم الحقيقة للناتج مع القيمة المطلوبة للخرج. المشتقة بالنسبة للوزن $w$ يتم حسابها باستخدام قاعدة التسلسل و تكون عبر الشكل الاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]
</div>
<div dir=rtl>
<p>كنتيجة , الوزن سيتم تحديثة كالتالي:</p>
</div>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">تحديث الاوزان</span> في الشبكات العصبونية , يتم تحديث الاوزان كما يلي:
<br>- <u>الخطوة 1</u>: خذ حزمة من بيانات التدريب
<br>- <u>الخطوة 2</u>: قم بعملية التغذيه الامامية لحساب الخسارة الناتجة
<br>- <u>الخطوة 3</u>: قم بتغذية خلفية للخساره للحصول على دالة الانحدار
<br>- <u>الخطوة 4</u>: استخدم قيم الانحدار لتحديث اوزان الشبكة
</p>
<br>
<p><span class=""new-item item-g"">الاسقاط <span class=""ltr stick-together"">(dropout)</span></span> الاسقاط هي طريقة الغرض منها منع التكيف الزائد للنموذج في بيانات التدريب عبر اسقاط بعض الواحدات في الشبكة العصبونية, العصبونات يتم اما اسقاطها باحتمالية $p$ او الحفاظ عليها باحتمالية $1-p$.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#cnn id=cnn></a>الشبكات العصبونية الالتفافية <span class=""ltr stick-together"">(CNN)</span></h2>
<p><span class=""new-item item-r"">احتياج الطبقة الالتفافية</span> عبر رمز $W$ لحجم المدخل , $F$ حجم العصبونات للطبقة الالتفافية , $P$ عدد الحشوات الصفرية , فأن $N$ عدد العصبونات لكل حجم معطى يحسب عبر الاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{N=\frac{W-F+2P}{S}+1}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">تنظيم الحزمة <span class=""ltr stick-together"">(batch normalization)</span></span> هي خطوه من قيم التحسين الخاصة $\gamma, \beta$  والتي تعدل الحزمة $\{x_i\}$. لنجعل $\mu_B, \sigma_B^2$ المتوسط و الانحراف للحزمة المعنية و نريد تصحيح هذه الحزمة, يتم ذلك كالتالي:    </p>
</div>
<div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
<div dir=rtl>
<p>في الغالب تتم بعد الطبقة الالتفافية أو المتصلة كليا و قبل طبقة التغيرات الغير خطية و تهدف للسماح للسرعات التعليم العالية للتقليل من الاعتمادية القوية للقيم الاولية.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#rnn id=rnn></a>الشبكات العصبونية التكرارية <span class=""ltr stick-together"">(RNN)</span></h2>
<p><span class=""new-item item-r"">انواع البوابات</span> هنا الانواع المختلفة التي ممكن مواجهتها في الشبكة العصبونية الاعتيادية:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>بوابة ادخال</b></td>
<td align=center><b>بوابة نسيان</b></td>
<td align=center><b>بوابة منفذ</b></td>
<td align=center><b>بوابة اخراج </b></td>
</tr>
<tr>
<td align=center>كتابة ام عدم كتابة الى الخلية؟</td>
<td align=center>مسح ام عدم مسح الخلية؟</td>
<td align=center>كمية الكتابة الى الخلية ؟ </td>
<td align=center>مدى الافصاح عن الخلية ؟ </td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">LSTM</span> ذاكرة طويلة قصير الامد <span class=""ltr stick-together"">(long short-term memory)</span> هي نوع من نموذج ال <span class=""ltr stick-together"">RNN</span> تستخدم لتجنب مشكلة اختفاء الانحدار عبر اضافة بوابات النسيان.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#reinforcement id=reinforcement></a>التعلم و التحكم المعزز <span class=""ltr stick-together"">(reinforcement learning)</span></h2>
<p>الهدف من التعلم المعزز للعميل الذكي هو التعلم لكيفية التأقلم في اي بيئة.</p>
<h3>تعريفات</h3>
<p><span class=""new-item item-b"">عملية ماركوف لاتخاذ القرار</span> عملية ماركوف لاتخاذ القرار هي سلسلة خماسية $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ حيث
<br>-  $\mathcal{S}$ هي مجموعة من حالات البيئة
<br>- $\mathcal{A}$ هي مجموعة من حالات الاجراءات
<br>- $\{P_{sa}\}$ هو حالة احتمال الانتقال من الحالة $s\in\mathcal{S}$ و $a\in\mathcal{A}$
<br>- $\gamma\in[0,1[$ هي عامل الخصم
<br>- $R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$  هي دالة المكافأة والتي تعمل الخوارزمية على جعلها اعلى قيمة</p>
<br>
<p><span class=""new-item item-b"">دالة القواعد</span> دالة القواعد $\pi:\mathcal{S}\longrightarrow\mathcal{A}$  هي التي تقوم بترجمة الحالات الى اجراءات.</p>
<p><span class=remark>ملاحظة: نقول ان النموذج ينفذ القاعدة المعينه $\pi$ للحالة المعطاة $s$ ان نتخذ الاجراء$a=\pi(s)$.  </span></p>
<br>
<p><span class=""new-item item-g"">دالة القاعدة</span> لاي قاعدة معطاة $\pi$ و حالة $s$, نقوم بتعريف دالة القيمة $V^{\pi}$  كما يلي:  </p>
</div>
<div class=mobile-container>
\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">معادلة بيلمان</span> معادلات بيلمان المثلى تشخص دالة القيمة دالة القيمة $V^{\pi^*}$  $\pi^*$:للقاعدة المثلى</p>
</div>
<div class=mobile-container>
\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]
</div>
<div dir=rtl>
<p><i>  $\pi^*$ للحالة المعطاه $s$ تعطى كاالتالي: ملاحظة: نلاحظ ان القاعدة المثلى</i></p>
</div>
<div class=mobile-container>
\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">خوارزمية تكرار القيمة <span class=""ltr stick-together"">(value iteration algorithm)</span></span> خوارزمية تكرار القيمة تكون في خطوتين:</p>
<p> 1) نقوم بوضع قيمة اولية:</p>
</div>
<div class=mobile-container>
\[\boxed{V_0(s)=0}\]
</div>
<div dir=rtl>
<p>2) نقوم بتكرير القيمة حسب القيم السابقة:</p>
</div>
<div class=mobile-container>
\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-g"">التعلم-$Q$ <span class=""ltr stick-together"">($Q$-learning)</span></span> هي طريقة غير منمذجة لتقدير $Q$, و تتم كالاتي:</p>
</div>
<div class=mobile-container>
\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]
</div>
<br>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
13,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Deep Learning cheatsheet Star

By Afshine Amidi and Shervine Amidi

Neural Networks

Neural networks are a class of models that are built with layers. Commonly used types of neural networks include convolutional and recurrent neural networks.

Architecture The vocabulary around neural networks architectures is described in the figure below:

By noting $i$ the $i^{th}$ layer of the network and $j$ the $j^{th}$ hidden unit of the layer, we have:

\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]

where we note $w$, $b$, $z$ the weight, bias and output respectively.

Activation function Activation functions are used at the end of a hidden unit to introduce non-linear complexities to the model. Here are the most common ones:

Sigmoid Tanh ReLU Leaky ReLU $g(z)=\displaystyle\frac{1}{1+e^{-z}}$ $g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ $g(z)=\textrm{max}(0,z)$ $g(z)=\textrm{max}(\epsilon z,z)$

with $\epsilon\ll1$

Cross-entropy loss In the context of neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:

\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]

Learning rate The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. This can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.

Backpropagation Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to weight $w$ is computed using chain rule and is of the following form:

\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]

As a result, the weight is updated as follows:

\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]

Updating weights In a neural network, weights are updated as follows:

Step 1 : Take a batch of training data.

: Take a batch of training data. Step 2 : Perform forward propagation to obtain the corresponding loss.

: Perform forward propagation to obtain the corresponding loss. Step 3 : Backpropagate the loss to get the gradients.

: Backpropagate the loss to get the gradients. Step 4 : Use the gradients to update the weights of the network.

Dropout Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network. In practice, neurons are either dropped with probability $p$ or kept with probability $1-p.$

Convolutional Neural Networks

Convolutional layer requirement By noting $W$ the input volume size, $F$ the size of the convolutional layer neurons, $P$ the amount of zero padding, then the number of neurons $N$ that fit in a given volume is such that:

\[\boxed{N=\frac{W-F+2P}{S}+1}\]

Batch normalization It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:

\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]

Recurrent Neural Networks

Types of gates Here are the different types of gates that we encounter in a typical recurrent neural network:

Input gate Forget gate Gate Output gate Write to cell or not? Erase a cell or not? How much to write to cell? How much to reveal cell?

LSTM A long short-term memory (LSTM) network is a type of RNN model that avoids the vanishing gradient problem by adding 'forget' gates.

For a more detailed overview of the concepts above, check out the Deep Learning cheatsheets

Reinforcement Learning and Control

The goal of reinforcement learning is for an agent to learn how to evolve in an environment.

Definitions

Markov decision processes A Markov decision process (MDP) is a 5-tuple $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ where:

$\mathcal{S}$ is the set of states

$\mathcal{A}$ is the set of actions

$\{P_{sa}\}$ are the state transition probabilities for $s\in\mathcal{S}$ and $a\in\mathcal{A}$

$\gamma\in[0,1[$ is the discount factor

$R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ is the reward function that the algorithm wants to maximize

Policy A policy $\pi$ is a function $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ that maps states to actions.

Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.

Value function For a given policy $\pi$ and a given state $s$, we define the value function $V^{\pi}$ as follows:

\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]

Bellman equation The optimal Bellman equations characterizes the value function $V^{\pi^*}$ of the optimal policy $\pi^*$:

\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]

Remark: we note that the optimal policy $\pi^*$ for a given state $s$ is such that:

\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]

Value iteration algorithm The value iteration algorithm is in two steps:

1) We initialize the value:

\[\boxed{V_0(s)=0}\]

2) We iterate the value based on the values before:

\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]

Maximum likelihood estimate The maximum likelihood estimates for the state transition probabilities are as follows:

\[\boxed{P_{sa}(s')=\frac{\#\textrm{times took action }a\textrm{ in state }s\textrm{ and got to }s'}{\#\textrm{times took action }a\textrm{ in state }s}}\]

Q-learning $Q$-learning is a model-free estimation of $Q$, which is done as follows:

\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksDeep Learning cheatsheet StarBy Afshine Amidi and Shervine AmidiNeural NetworksNeural networks are a class of models that are built with layers.
Backpropagation Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output.
Dropout Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network.
For a more detailed overview of the concepts above, check out the Deep Learning cheatsheetsReinforcement Learning and ControlThe goal of reinforcement learning is for an agent to learn how to evolve in an environment.
Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.","['deep', 'value', 'function', 'loss', 'state', 'policy', 'given', 'learning', 'network', 'cheatsheet', 'neural', 'weights']",en,Deep Learning Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Deep Learning Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Deep Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#nn>Neural Networks</a></div> <div class=dropdown-container> <a href=#nn><span>Architecture</span></a> <a href=#nn><span>Activation function</span></a> <a href=#nn><span>Backpropagation</span></a> <a href=#nn><span>Dropout</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#cnn>Convolutional Neural Networks</a></div> <div class=dropdown-container> <a href=#cnn><span>Convolutional layer</span></a> <a href=#cnn><span>Batch normalization</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#rnn>Recurrent Neural Networks</a></div> <div class=dropdown-container> <a href=#rnn><span>Gates</span></a> <a href=#rnn><span>LSTM</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#reinforcement>Reinforcement learning</a></div> <div class=dropdown-container> <a href=#reinforcement><span>Markov decision processes</span></a> <a href=#reinforcement><span>Value/policy iteration</span></a> <a href=#reinforcement><span>Approximate dynamic     programming</span></a> <a href=#reinforcement><span>Policy search</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-deep-learning.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button><b>Deep Learning</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Deep Learning cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#nn id=nn></a>Neural Networks</h2>
<p>Neural networks are a class of models that are built with layers. Commonly used types of neural networks include convolutional and recurrent neural networks.</p>
<p><span class=""new-item item-g"">Architecture</span> The vocabulary around neural networks architectures is described in the figure below:</p>
<center>
  <img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/neural-network-en.png?835862d448ad85bc5a038848d7d7df0b style=width:100%;max-width:700px>
</center>
<p>By noting $i$ the $i^{th}$ layer of the network and $j$ the $j^{th}$ hidden unit of the layer, we have:</p>
<div class=mobile-container>
\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]
</div>
<p>where we note $w$, $b$, $z$ the weight, bias and output respectively.</p>
<br>
<p><span class=""new-item item-b"">Activation function</span> Activation functions are used at the end of a hidden unit to introduce non-linear complexities to the model. Here are the most common ones:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Sigmoid</b></td>
<td align=center><b>Tanh</b></td>
<td align=center><b>ReLU</b></td>
<td align=center><b>Leaky ReLU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\displaystyle\frac{1}{1+e^{-z}}$</td>
<td align=center>$g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$</td>
<td align=center>$g(z)=\textrm{max}(0,z)$</td>
<td align=center>$g(z)=\textrm{max}(\epsilon z,z)$<br> with $\epsilon\ll1$</td>
</tr>
<tr>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/sigmoid.png?c91b6e5a7d4e78e95880bcf4e39889df>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/tanh.png?22ac27f27c510c6414e8a3bb4aca2d80>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/relu.png?6c1d78551355db5c6e4f6f8b5282cfa8>
</td>
<td align=center>
<img alt=Illustration class=img-responsive src=teaching/cs-229/illustrations/leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e>
</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Cross-entropy loss</span> In the context of neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<p><span class=""new-item item-b"">Learning rate</span> The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. This can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.</p>
<br>
<p><span class=""new-item item-r"">Backpropagation</span> Backpropagation is a method to update the weights in the neural network by taking into account the actual output and the desired output. The derivative with respect to weight $w$ is computed using chain rule and is of the following form:</p>
<div class=mobile-container>
\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]
</div>
<p>As a result, the weight is updated as follows:</p>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<p><span class=""new-item item-g"">Updating weights</span> In a neural network, weights are updated as follows:
</p><ul>
<li><u>Step 1</u>: Take a batch of training data.
</li><li><u>Step 2</u>: Perform forward propagation to obtain the corresponding loss.
</li><li><u>Step 3</u>: Backpropagate the loss to get the gradients.
</li><li><u>Step 4</u>: Use the gradients to update the weights of the network.
</li></ul>
<p></p>
<br>
<p><span class=""new-item item-g"">Dropout</span> Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network. In practice, neurons are either dropped with probability $p$ or kept with probability $1-p.$</p>
<br>
<h2><a aria-hidden=true class=anchor href=#cnn id=cnn></a>Convolutional Neural Networks</h2>
<p><span class=""new-item item-r"">Convolutional layer requirement</span> By noting $W$ the input volume size, $F$ the size of the convolutional layer neurons, $P$ the amount of zero padding, then the number of neurons $N$ that fit in a given volume is such that:</p>
<div class=mobile-container>
\[\boxed{N=\frac{W-F+2P}{S}+1}\]
</div>
<br>
<p><span class=""new-item item-g"">Batch normalization</span> It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:
</p><div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
It is usually done after a fully connected/convolutional layer and before a non-linearity layer and aims at allowing higher learning rates and reducing the strong dependence on initialization.<p></p>
<br>
<h2><a aria-hidden=true class=anchor href=#rnn id=rnn></a>Recurrent Neural Networks</h2>
<p><span class=""new-item item-r"">Types of gates</span> Here are the different types of gates that we encounter in a typical recurrent neural network:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Input gate</b></td>
<td align=center><b>Forget gate</b></td>
<td align=center><b>Gate</b></td>
<td align=center><b>Output gate</b></td>
</tr>
<tr>
<td align=center>Write to cell or not?</td>
<td align=center>Erase a cell or not?</td>
<td align=center>How much to write to cell?</td>
<td align=center>How much to reveal cell?</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">LSTM</span> A long short-term memory (LSTM) network is a type of RNN model that avoids the vanishing gradient problem by adding 'forget' gates.</p>
<br>
<div class=""alert alert-warning"" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link href=teaching/cs-230 onclick=trackOutboundLink(this);>Deep Learning cheatsheets</a>!</div>
<br>
<h2><a aria-hidden=true class=anchor href=#reinforcement id=reinforcement></a>Reinforcement Learning and Control</h2>
<p>The goal of reinforcement learning is for an agent to learn how to evolve in an environment.</p>
<h3>Definitions</h3>
<p><span class=""new-item item-b"">Markov decision processes</span> A Markov decision process (MDP) is a 5-tuple $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ where:
</p><ul>
<li>$\mathcal{S}$ is the set of states
</li><li>$\mathcal{A}$ is the set of actions
</li><li>$\{P_{sa}\}$ are the state transition probabilities for $s\in\mathcal{S}$ and $a\in\mathcal{A}$
</li><li>$\gamma\in[0,1[$ is the discount factor
</li><li>$R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ is the reward function that the algorithm wants to maximize
</li></ul><p></p>
<br>
<p><span class=""new-item item-b"">Policy</span> A policy $\pi$ is a function $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ that maps states to actions.</p>
<p><span class=remark>Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.</span></p>
<br>
<p><span class=""new-item item-g"">Value function</span> For a given policy $\pi$ and a given state $s$, we define the value function $V^{\pi}$ as follows:</p>
<div class=mobile-container>
\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]
</div>
<br>
<p><span class=""new-item item-r"">Bellman equation</span> The optimal Bellman equations characterizes the value function $V^{\pi^*}$ of the optimal policy $\pi^*$:</p>
<div class=mobile-container>
\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]
</div>
<p><span class=remark>Remark: we note that the optimal policy $\pi^*$ for a given state $s$ is such that:</span></p>
<div class=mobile-container>
\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]
</div>
<br>
<p><span class=""new-item item-g"">Value iteration algorithm</span> The value iteration algorithm is in two steps:</p>
<p>1) We initialize the value:</p>
<div class=mobile-container>
\[\boxed{V_0(s)=0}\]
</div>
<p>2) We iterate the value based on the values before:</p>
<div class=mobile-container>
\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]
</div>
<br>
<p><span class=""new-item item-r"">Maximum likelihood estimate</span> The maximum likelihood estimates for the state transition probabilities are as follows:</p>
<div class=mobile-container>
\[\boxed{P_{sa}(s')=\frac{\#\textrm{times took action }a\textrm{ in state }s\textrm{ and got to }s'}{\#\textrm{times took action }a\textrm{ in state }s}}\]
</div>
<br>
<p><span class=""new-item item-g"">Q-learning</span> $Q$-learning is a model-free estimation of $Q$, which is done as follows:</p>
<div class=mobile-container>
\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]
</div>
<br>
<div class=""alert alert-warning"" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link href=teaching/cs-221/cheatsheet-states-models onclick=trackOutboundLink(this);>States-based Models cheatsheets</a>!</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
14,"مصفوفة الدقّة (confusion matrix) تستخدم مصفوفة الدقّة لأخذ تصور شامل عند تقييم أداء النموذج. وهي تعرّف كالتالي:

في سياق التصنيف الثنائي، هذه المقاييس (metrics) المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.

منحنى دقّة الأداء (ROC) منحنى دقّة الآداء، ويطلق عليه ROC، هو رسمة لمعدل التصنيفات الإيجابية الصحيحة (TPR) مقابل معدل التصنيفات الإيجابية الخاطئة (FPR) باستخدام قيم حد (threshold) متغيرة. هذه المقاييس ملخصة في الجدول التالي:

المقاييس الأساسية المقاييس التالية تستخدم في العادة لتقييم أداء نماذج التصنيف:

المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى) (AUC) المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى)، ويطلق عليها AUC أو AUROC، هي المساحة تحت ROC كما هو موضح في الرسمة التالية:

مقاييس الانحدار

المقاييس الأساسية إذا كان لدينا نموذج الانحدار $f$، فإن المقاييس التالية غالباً ما تستخدم لتقييم أداء النموذج:

المجموع الكلي للمربعات مجموع المربعات المُفسَّر مجموع المربعات المتبقي $\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$

مُعامل التحديد (coefficient of determination) مُعامل التحديد، وغالباً يرمز له بـ $R^2$ أو $r^2$، يعطي قياس لمدى مطابقة النموذج للنتائج الملحوظة، ويعرف كما يلي:

\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]

المقاييس الرئيسية المقاييس التالية تستخدم غالباً لتقييم أداء نماذج الانحدار، وذلك بأن يتم الأخذ في الحسبان عدد المتغيرات $n$ المستخدمة فيها:

معيار معامل مالوس (Mallow's) AIC BIC Adjusted $R^2$ $\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$ $\displaystyle2\Big[(n+2)-\log(L)\Big]$ $\displaystyle\log(m)(n+2)-2\log(L)$ $\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$

حيث $L$ هو الأرجحية، و $\widehat{\sigma}^2$ تقدير التباين الخاص بكل نتيجة.

اختيار النموذج

مفردات عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:

مجموعة تدريب مجموعة تحقق مجموعة اختبار • يتم تدريب النموذج

• غالباً 80% من مجموعة البيانات • يتم تقييم النموذج

• غالباً 20% من مجموعة البيانات

• يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير • النموذج يعطي التوقعات

• بيانات لم يسبق رؤيتها من قبل

بمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل. كما هو موضح في الشكل التالي:

التحقق المتقاطع (cross-validation) التحقق المتقاطع، وكذلك يختصر بـ CV، هو طريقة تستخدم لاختيار نموذج بحيث لا يعتمد بشكل كبير على مجموعة بيانات التدريب المبدأية. أنواع التحقق المتقاطع المختلفة ملخصة في الجدول التالي:

k-fold Leave-p-out • التدريب على $k-1$ جزء والتقييم باستخدام الجزء الباقي

• بشكل عام $k=5$ أو 10 • التدريب على $n-p$ عينة والتقييم باستخدام الـ $p$ عينات المتبقية

• الحالة $p=1$ يطلق عليها الإبقاء على واحد (leave-one-out)

الطريقة الأكثر استخداماً يطلق عليها التحقق المتقاطع س جزء/أجزاء ($k$-fold)، ويتم فيها تقسيم البيانات إلى $k$ جزء، بحيث يتم تدريب النموذج باستخدام $k-1$ والتحقق باستخدام الجزء المتبقي، ويتم تكرار ذلك $k$ مرة. يتم بعد ذلك حساب معدل الأخطاء في الأجزاء $k$ ويسمى خطأ التحقق المتقاطع.

ضبط (regularization) عمليه الضبط تهدف إلى تفادي فرط التخصيص (overfit) للنموذج، وهو بذلك يتعامل مع مشاكل التباين العالي. الجدول التالي يلخص أنواع وطرق الضبط الأكثر استخداماً:

LASSO Ridge Elastic Net • يقلص المُعاملات إلى 0

• جيد لاختيار المتغيرات يجعل المُعاملات أصغر المفاضلة بين اختيار المتغيرات والمُعاملات الصغيرة $...+\lambda||\theta||_1$

$\lambda\in\mathbb{R}$ $...+\lambda||\theta||_2^2$

$\lambda\in\mathbb{R}$ $...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$

$\lambda\in\mathbb{R},\alpha\in[0,1]$

التشخيصات

الانحياز (bias) الانحياز للنموذج هو الفرق بين التنبؤ المتوقع والنموذج الحقيقي الذي نحاول تنبؤه للبيانات المعطاة.

التباين (variance) تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.

موازنة الانحياز/التباين (bias/variance tradeoff) كلما زادت بساطة النموذج، زاد الانحياز، وكلما زاد تعقيد النموذج، زاد التباين.



Underfitting Just right Overfitting الأعراض • خطأ التدريب عالي

• خطأ التدريب قريب من خطأ الاختبار

• انحياز عالي • خطأ التدريب أقل بقليل من خطأ الاختبار • خطأ التدريب منخفض جداً

• خطأ التدريب أقل بكثير من خطأ الاختبار

• تباين عالي توضيح الانحدار توضيح التصنيف توضيح التعلم العميق العلاجات الممكنة • زيادة تعقيد النموذج

• إضافة المزيد من الخصائص

• تدريب لمدة أطول • إجراء الضبط (regularization)

• الحصول على المزيد من البيانات

تحليل الخطأ تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.

تحليل استئصالي (ablative analysis) التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية (baseline).","وهي تعرّف كالتالي:في سياق التصنيف الثنائي، هذه المقاييس (metrics) المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.
اختيار النموذجمفردات عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:مجموعة تدريب مجموعة تحقق مجموعة اختبار • يتم تدريب النموذج• غالباً 80% من مجموعة البيانات • يتم تقييم النموذج• غالباً 20% من مجموعة البيانات• يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير • النموذج يعطي التوقعات• بيانات لم يسبق رؤيتها من قبلبمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل.
التباين (variance) تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.
Underfitting Just right Overfitting الأعراض • خطأ التدريب عالي• خطأ التدريب قريب من خطأ الاختبار• انحياز عالي • خطأ التدريب أقل بقليل من خطأ الاختبار • خطأ التدريب منخفض جداً• خطأ التدريب أقل بكثير من خطأ الاختبار• تباين عالي توضيح الانحدار توضيح التصنيف توضيح التعلم العميق العلاجات الممكنة • زيادة تعقيد النموذج• إضافة المزيد من الخصائص• تدريب لمدة أطول • إجراء الضبط (regularization)• الحصول على المزيد من البياناتتحليل الخطأ تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.
تحليل استئصالي (ablative analysis) التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية (baseline).","['النموذج', 'تستخدم', 'تحت', 'نصائح', 'باستخدام', 'المقاييس', 'التدريب', 'يتم', 'مجموعة', 'البيانات', 'وحيل', 'خطأ']",ar,نصائح وحيل,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>نصائح وحيل - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>نصائح وحيل</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#classification-metrics>مقاييس التصنيف</a></div> <div class=dropdown-container> <a href=#classification-metrics><span>مصفوفة الدقّة</span></a> <a href=#classification-metrics><span>الضبط <span class=ltr>(accuracy)</span></span></a> <a href=#classification-metrics><span>الدقة <span class=ltr>(precision)</span> ،الاستدعاء <span class=ltr>    (recall)</span></span></a> <a href=#classification-metrics><span>درجة <span class=ltr>F1</span></span></a> <a href=#classification-metrics><span><span class=ltr>ROC</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regression-metrics>مقاييس الانحدار</a></div> <div class=dropdown-container> <a href=#regression-metrics><span>مربع <span class=ltr>R</span></span></a> <a href=#regression-metrics><span>معيار معامل مالوس <span class=ltr>(Mallow's)</span></span></a> <a href=#regression-metrics><span>معيار آكياك المعلوماتي <span class=ltr>(AIC)</span>     معيار المعلومات البايزي <span class=ltr>(BIC)</span></span></a> </div> </li> <li> <div class=dropdown-btn><a href=#model-selection>اختيار النموذج</a></div> <div class=dropdown-container> <a href=#model-selection><span>التحقق المتقاطع</span></a> <a href=#model-selection><span>الضبط</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#diagnostics>التشخيصات</a></div> <div class=dropdown-container> <a href=#diagnostics><span>موازنة الانحياز/التباين</span></a> <a href=#diagnostics><span>تحليل الخطأ/التحليل الاستئصالي</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/cheatsheet-machine-learning-tips-and-tricks.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-supervised-learning'"" type=button>تعلّم موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>تعلم غير موجَّه</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-deep-learning'"" type=button>تعلم متعمق</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button><b>نصائح وحيل</b></button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مرجع سريع لنصائح وحيل تعلّم الآلة</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة فارس القنيعير. تمت المراجعة بواسطة زيد اليافعي.</font></p>
</div>
<h2><a aria-hidden=true class=anchor href=#classification-metrics id=classification-metrics></a><div dir=rtl>مقاييس التصنيف</div></h2>
<div dir=rtl>
<p>في سياق التصنيف الثنائي، هذه المقاييس <span class=""ltr stick-together"">(metrics)</span> المهمة التي يجدر مراقبتها من أجل تقييم آداء النموذج.</p>
<p><span class=""new-item item-b"">مصفوفة الدقّة <span class=""ltr stick-together"">(confusion matrix)</span></span> تستخدم مصفوفة الدقّة لأخذ تصور شامل عند تقييم أداء النموذج. وهي تعرّف كالتالي:</p>
</div>
<div class=mobile-container>
<span class=""ltr stick-together"">
</span><span class=""ltr stick-together"">
</span><table style=""margin-left: 10%"">
<colgroup><col width=120px>
<col width=50px>
<col width=200px>
<col width=200px>
</colgroup><tbody>
<tr style=""border-top: 0px"">
<td align=center colspan=2 rowspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""></td>
<td align=center colspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""><b>التصنيف المتوقع</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>+</b></td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>-</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center rowspan=2 style=""border: 0px""><b>التصنيف الفعلي</b></td><td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>+</b></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b><span class=""ltr stick-together"">TP</span></b><br><span class=""ltr stick-together"">True Positives</span></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b><span class=""ltr stick-together"">FN</span></b><br><span class=""ltr stick-together"">False Negatives</span><br><span class=""ltr stick-together"">Type II error</span></td>
</tr>
<tr style=""border-top: 0px""><td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>-</b></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b><span class=""ltr stick-together"">FP</span></b><br><span class=""ltr stick-together"">False Positives</span><br><span class=""ltr stick-together"">Type I error</span></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b><span class=""ltr stick-together"">TN</span></b><br><span class=""ltr stick-together"">True Negatives</span></td>
</tr>
</tbody>
</table>
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">المقاييس الأساسية</span> المقاييس التالية تستخدم في العادة لتقييم أداء نماذج التصنيف:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>المقياس</b></td>
<td align=center><b>المعادلة</b></td>
<td align=center><b>التفسير</b></td>
</tr>
<tr>
<td align=center>الضبط <span class=""ltr stick-together"">(accuracy)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$</td>
<td align=right>الأداء العام للنموذج</td>
</tr>
<tr>
<td align=center>الدقة <span class=""ltr stick-together"">(precision)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$</td>
<td align=right>دقّة التوقعات الإيجابية <span class=""ltr stick-together"">(positive)</span></td>
</tr>
<tr>
<td align=center>الاستدعاء <span class=""ltr stick-together"">(recall, sensitivity)</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=right>تغطية عينات التوقعات الإيجابية الفعلية</td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">Specificity</span></td>
<td align=center>$\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=right>تغطية عينات التوقعات السلبية الفعلية</td>
</tr>
<tr>
<td align=center>درجة <span class=""ltr stick-together"">F1</span></td>
<td align=center>$\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$</td>
<td align=right>مقياس هجين مفيد للأصناف غير المتوازنة <span class=""ltr stick-together"">(unbalanced)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">منحنى دقّة الأداء <span class=""ltr stick-together"">(ROC)</span></span> منحنى دقّة الآداء، ويطلق عليه <span class=""ltr stick-together"">ROC</span>، هو رسمة لمعدل التصنيفات الإيجابية الصحيحة <span class=""ltr stick-together"">(TPR)</span> مقابل معدل التصنيفات الإيجابية الخاطئة <span class=""ltr stick-together"">(FPR)</span> باستخدام قيم حد <span class=""ltr stick-together"">(threshold)</span> متغيرة. هذه المقاييس ملخصة في الجدول التالي:</p>
</div>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>المقياس</b></td>
<td align=center><b>المعادلة</b></td>
<td align=center><b>مرادف</b></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">True Positive Rate</span><br><span class=""ltr stick-together"">TPR</span></td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left><span class=""ltr stick-together"">Recall, sensitivity</span></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">False Positive Rate</span><br><span class=""ltr stick-together"">FPR</span></td>
<td align=center>$\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left><span class=""ltr stick-together"">1-specificity</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<div dir=rtl>
<p><span class=""new-item item-r"">المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى) <span class=""ltr stick-together"">(AUC)</span></span> المساحة تحت منحنى دقة الأداء (المساحة تحت المنحنى)، ويطلق عليها  <span class=""ltr stick-together"">AUC</span> أو <span class=""ltr stick-together"">AUROC</span>، هي المساحة تحت <span class=""ltr stick-together"">ROC</span> كما هو موضح في الرسمة التالية:</p>
</div>
<br>
<div class=mobile-container>
<center>
<img alt=""ROC AUC"" class=img-responsive src=teaching/cs-229/illustrations/roc-auc-ar.png?d9ee2f725f841dd8d59e7cad68529e5a style=width:100%;max-width:700px>
</center>
</div>
<br>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#regression-metrics id=regression-metrics></a>مقاييس الانحدار</h2>
<p><span class=""new-item item-b"">المقاييس الأساسية</span> إذا كان لدينا نموذج الانحدار $f$، فإن المقاييس التالية غالباً ما تستخدم لتقييم أداء النموذج:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>المجموع الكلي للمربعات</b></td>
<td align=center><b>مجموع المربعات المُفسَّر</b></td>
<td align=center><b>مجموع المربعات المتبقي</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">مُعامل التحديد <span class=""ltr stick-together"">(coefficient of determination)</span></span> مُعامل التحديد، وغالباً يرمز له بـ $R^2$ أو $r^2$، يعطي قياس لمدى مطابقة النموذج للنتائج الملحوظة، ويعرف كما يلي:</p>
<div class=mobile-container>
\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]
</div>
<br>
<p><span class=""new-item item-r"">المقاييس الرئيسية</span> المقاييس التالية تستخدم غالباً لتقييم أداء نماذج الانحدار، وذلك بأن يتم الأخذ في الحسبان عدد المتغيرات $n$ المستخدمة فيها:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>معيار معامل مالوس <span class=""ltr stick-together"">(Mallow's)</span></b></td>
<td align=center><b><span class=""ltr stick-together"">AIC</span></b></td>
<td align=center><b><span class=""ltr stick-together"">BIC</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Adjusted</span> $R^2$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$</td>
<td align=center>$\displaystyle2\Big[(n+2)-\log(L)\Big]$</td>
<td align=center>$\displaystyle\log(m)(n+2)-2\log(L)$</td>
<td align=center>$\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>حيث $L$ هو الأرجحية، و $\widehat{\sigma}^2$ تقدير التباين الخاص بكل نتيجة.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#model-selection id=model-selection></a>اختيار النموذج</h2>
<p><span class=""new-item item-b"">مفردات</span> عند اختيار النموذج، نفرق بين 3 أجزاء من البيانات التي لدينا كالتالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>مجموعة تدريب</b></td>
<td align=center><b>مجموعة تحقق</b></td>
<td align=center><b>مجموعة اختبار</b></td>
</tr>
<tr>
<td align=right>• يتم تدريب النموذج<br>
                 • غالباً 80% من مجموعة البيانات</td>
<td align=right>• يتم تقييم النموذج<br>
                 • غالباً 20% من مجموعة البيانات<br>
                 • يطلق عليها كذلك المجموعة المُجنّبة أو مجموعة التطوير</td>
<td align=right>• النموذج يعطي التوقعات<br>
                 • بيانات لم يسبق رؤيتها من قبل</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>بمجرد اختيار النموذج، يتم تدريبه على مجموعة البيانات بالكامل ثم يتم اختباره على مجموعة اختبار لم يسبق رؤيتها من قبل. كما هو موضح في الشكل التالي:</p>
<div class=mobile-container>
<center>
<img alt=""Partition of the dataset"" class=img-responsive src=teaching/cs-229/illustrations/train-val-test-ar.png?f2b9792f76bcec48b27fab6f3030cba0 style=width:100%;max-width:550px>
</center>
</div>
<br>
<p><span class=""new-item item-g"">التحقق المتقاطع <span class=""ltr stick-together"">(cross-validation)</span></span> التحقق المتقاطع، وكذلك يختصر بـ <span class=""ltr stick-together"">CV</span>، هو طريقة تستخدم لاختيار نموذج بحيث لا يعتمد بشكل كبير على مجموعة بيانات التدريب المبدأية. أنواع التحقق المتقاطع المختلفة ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=50%>
<col width=50%>
</colgroup><tbody>
<tr>
<td align=center><b><span class=""ltr stick-together"">k-fold</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Leave-p-out</span></b></td>
</tr>
<tr>
<td align=right>• التدريب على $k-1$ جزء والتقييم باستخدام الجزء الباقي<br>
                 • بشكل عام $k=5$ أو 10</td>
<td align=right>• التدريب على $n-p$ عينة والتقييم باستخدام الـ $p$ عينات المتبقية<br>
                 • الحالة $p=1$ يطلق عليها الإبقاء على واحد <span class=""ltr stick-together"">(leave-one-out)</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<p>الطريقة الأكثر استخداماً يطلق عليها التحقق المتقاطع س جزء/أجزاء <span class=""ltr stick-together"">($k$-fold)</span>، ويتم فيها تقسيم البيانات إلى $k$ جزء، بحيث يتم تدريب النموذج باستخدام $k-1$ والتحقق باستخدام الجزء المتبقي، ويتم تكرار ذلك $k$ مرة. يتم بعد ذلك حساب معدل الأخطاء في الأجزاء $k$ ويسمى خطأ التحقق المتقاطع.</p>
<div class=mobile-container>
<center>
<img alt=Cross-validation class=img-responsive src=teaching/cs-229/illustrations/cross-validation-ar.png?65754a34e4e452acfc7c1f35b31acbb4 style=width:100%;max-width:770px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">ضبط <span class=""ltr stick-together"">(regularization)</span></span> عمليه الضبط تهدف إلى تفادي فرط التخصيص <span class=""ltr stick-together"">(overfit)</span> للنموذج، وهو بذلك يتعامل مع مشاكل التباين العالي. الجدول التالي يلخص أنواع وطرق الضبط الأكثر استخداماً:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b><span class=""ltr stick-together"">LASSO</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Ridge</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Elastic Net</span></b></td>
</tr>
<tr>
<td align=right>• يقلص المُعاملات إلى 0<br>• جيد لاختيار المتغيرات</td>
<td align=right>يجعل المُعاملات أصغر</td>
<td align=right>المفاضلة بين اختيار المتغيرات والمُعاملات الصغيرة</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive src=teaching/cs-229/illustrations/lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive src=teaching/cs-229/illustrations/ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt=""Elastic Net"" class=img-responsive src=teaching/cs-229/illustrations/elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#diagnostics id=diagnostics></a>التشخيصات</h2>
<p><span class=""new-item item-b"">الانحياز <span class=""ltr stick-together"">(bias)</span></span> الانحياز للنموذج هو الفرق بين التنبؤ المتوقع والنموذج الحقيقي الذي نحاول تنبؤه للبيانات المعطاة.</p>
<br>
<p><span class=""new-item item-b"">التباين <span class=""ltr stick-together"">(variance)</span></span> تباين النموذج هو مقدار التغير في تنبؤ النموذج لنقاط البيانات المعطاة.</p>
<br>
<p><span class=""new-item item-r"">موازنة الانحياز/التباين <span class=""ltr stick-together"">(bias/variance tradeoff)</span></span> كلما زادت بساطة النموذج، زاد الانحياز، وكلما زاد تعقيد النموذج، زاد التباين.</p>
<div class=mobile-container>
<center>
<br>
<table style=""table-layout:fixed; width:100%; min-width:735px;"">
<colgroup>
<col style=width:19%>
<col style=width:27%>
<col style=width:27%>
<col style=width:27%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b><span class=""ltr stick-together"">Underfitting</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Just right</span></b></td>
<td align=center><b><span class=""ltr stick-together"">Overfitting</span></b></td>
</tr>
<tr>
<td align=center><b>الأعراض</b></td>
<td align=right>• خطأ التدريب عالي <br>• خطأ التدريب قريب من خطأ الاختبار <br>• انحياز عالي</td>
<td align=right style=vertical-align:top>• خطأ التدريب أقل بقليل من خطأ الاختبار</td>
<td align=right>• خطأ التدريب منخفض جداً <br>• خطأ التدريب أقل بكثير من خطأ الاختبار <br>• تباين عالي</td>
</tr>
<tr>
<td align=center><b>توضيح الانحدار</b></td>
<td align=center><img alt=""Underfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-underfit.png?cd7fd5e4d334aa31d323b7d3f994a9df></td>
<td align=center><img alt=""Right fit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-just-right.png?4018112cca66bdc10de14e7e59702a32></td>
<td align=center><img alt=""Overfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-overfit.png?4133157c77ba0baff93110d1d0e73382></td>
</tr>
<tr>
<td align=center><b>توضيح التصنيف</b></td>
<td align=center><img alt=""Underfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-underfit.png?1f014836b68bfc74da1d767ca32783a3></td>
<td align=center><img alt=""Right fit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-just-right.png?67a70eb8c5fb11dd75d8e5035714a435></td>
<td align=center><img alt=""Overfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-overfit.png?64516ea4ed89dad5b422380ea1f8f350></td>
</tr>
<tr>
<td align=center><b>توضيح التعلم العميق</b></td>
<td align=center><img alt=""Underfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-underfit-ar.png?80c4ecf7dd48df97b9b9ef106890df3f></td>
<td align=center><img alt=""Right fit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-just-right-ar.png?e8e82e3385a23a414a3b41c87506db0c></td>
<td align=center><img alt=""Overfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-overfit-ar.png?5410d108c608de79536791696e5659bc></td>
</tr>
<tr>
<td align=center><b>العلاجات الممكنة</b></td>
<td align=right>• زيادة تعقيد النموذج<br>• إضافة المزيد من الخصائص<br>• تدريب لمدة أطول</td>
<td align=center style=""background: rgba(234, 234, 234, 1);""></td>
<td align=right>• إجراء الضبط <span class=""ltr stick-together"">(regularization)</span><br>• الحصول على المزيد من البيانات</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">تحليل الخطأ</span> تحليل الخطأ هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المثالية.</p>
<br>
<p><span class=""new-item item-b"">تحليل استئصالي <span class=""ltr stick-together"">(ablative analysis)</span></span> التحليل الاستئصالي هو تحليل السبب الرئيسي للفرق في الأداء بين النماذج الحالية والنماذج المبدئية <span class=""ltr stick-together"">(baseline)</span>.</p>
<br>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
15,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Supervised Learning Unsupervised Learning Deep Learning Tips and tricks

Machine Learning tips and tricks cheatsheet Star

By Afshine Amidi and Shervine Amidi

Classification metrics

In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.

Confusion matrix The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:

Predicted class + - Actual class + TP

True Positives FN

False Negatives

Type II error - FP

False Positives

Type I error TN

True Negatives

Main metrics The following metrics are commonly used to assess the performance of classification models:

Metric Formula Interpretation Accuracy $\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$ Overall performance of model Precision $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$ How accurate the positive predictions are Recall

Sensitivity $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$ Coverage of actual positive sample Specificity $\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$ Coverage of actual negative sample F1 score $\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$ Hybrid metric useful for unbalanced classes

ROC The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:

Metric Formula Equivalent True Positive Rate

TPR $\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$ Recall, sensitivity False Positive Rate

FPR $\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$ 1-specificity

AUC The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure:

Regression metrics

Basic metrics Given a regression model $f$, the following metrics are commonly used to assess the performance of the model:

Total sum of squares Explained sum of squares Residual sum of squares $\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$ $\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$

Coefficient of determination The coefficient of determination, often noted $R^2$ or $r^2$, provides a measure of how well the observed outcomes are replicated by the model and is defined as follows:

Main metrics The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables $n$ that they take into consideration:

Mallow's Cp AIC BIC Adjusted $R^2$ $\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$ $\displaystyle2\Big[(n+2)-\log(L)\Big]$ $\displaystyle\log(m)(n+2)-2\log(L)$ $\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$

where $L$ is the likelihood and $\widehat{\sigma}^2$ is an estimate of the variance associated with each response.

Model selection

Vocabulary When selecting a model, we distinguish 3 different parts of the data that we have as follows:

Training set Validation set Testing set • Model is trained

• Usually 80% of the dataset • Model is assessed

• Usually 20% of the dataset

• Also called hold-out or development set • Model gives predictions

• Unseen data

Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:

Cross-validation Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below:

k-fold Leave-p-out • Training on $k-1$ folds and assessment on the remaining one

• Generally $k=5$ or $10$ • Training on $n-p$ observations and assessment on the $p$ remaining ones

• Case $p=1$ is called leave-one-out

The most commonly used method is called $k$-fold cross-validation and splits the training data into $k$ folds to validate the model on one fold while training the model on the $k-1$ other folds, all of this $k$ times. The error is then averaged over the $k$ folds and is named cross-validation error.

Regularization The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques:

LASSO Ridge Elastic Net • Shrinks coefficients to 0

• Good for variable selection Makes coefficients smaller Tradeoff between variable selection and small coefficients $...+\lambda||\theta||_1$

$\lambda\in\mathbb{R}$ $...+\lambda||\theta||_2^2$

$\lambda\in\mathbb{R}$ $...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$

$\lambda\in\mathbb{R},\alpha\in[0,1]$

Diagnostics

Bias The bias of a model is the difference between the expected prediction and the correct model that we try to predict for given data points.

Variance The variance of a model is the variability of the model prediction for given data points.

Bias/variance tradeoff The simpler the model, the higher the bias, and the more complex the model, the higher the variance.



Underfitting Just right Overfitting Symptoms • High training error

• Training error close to test error

• High bias • Training error slightly lower than test error • Very low training error

• Training error much lower than test error

• High variance Regression illustration Classification illustration Deep learning illustration Possible remedies • Complexify model

• Add more features

• Train longer • Perform regularization

• Get more data

Error analysis Error analysis is analyzing the root cause of the difference in performance between the current and the perfect models.

Ablative analysis Ablative analysis is analyzing the root cause of the difference in performance between the current and the baseline models.","CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 Supervised Learning Unsupervised Learning Deep Learning Tips and tricksMachine Learning tips and tricks cheatsheet StarBy Afshine Amidi and Shervine AmidiClassification metricsIn a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.
Confusion matrix The confusion matrix is used to have a more complete picture when assessing the performance of a model.
Regularization The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues.
Variance The variance of a model is the variability of the model prediction for given data points.
Bias/variance tradeoff The simpler the model, the higher the bias, and the more complex the model, the higher the variance.","['metrics', 'set', 'tips', 'performance', 'tricks', 'error', 'training', 'following', 'learning', 'cheatsheet', 'used', 'machine', 'data', 'model']",en,Machine Learning Tips and Tricks Cheatsheet,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Machine Learning Tips and Tricks Cheatsheet</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Tips and tricks</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#classification-metrics>Classification metrics</a></div> <div class=dropdown-container> <a href=#classification-metrics><span>Confusion matrix</span></a> <a href=#classification-metrics><span>Accuracy</span></a> <a href=#classification-metrics><span>Precision, recall</span></a> <a href=#classification-metrics><span>F1 score</span></a> <a href=#classification-metrics><span>ROC</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regression-metrics>Regression metrics</a></div> <div class=dropdown-container> <a href=#regression-metrics><span>R squared</span></a> <a href=#regression-metrics><span>Mallow's CP</span></a> <a href=#regression-metrics><span>AIC, BIC</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#model-selection>Model selection</a></div> <div class=dropdown-container> <a href=#model-selection><span>Cross-validation</span></a> <a href=#model-selection><span>Regularization</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#diagnostics>Diagnostics</a></div> <div class=dropdown-container> <a href=#diagnostics><span>Bias/variance tradeoff</span></a> <a href=#diagnostics><span>Error/ablative analysis</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-supervised-learning'"" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-unsupervised-learning'"" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/cheatsheet-deep-learning'"" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'"" type=button><b>Tips and tricks</b></button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Machine Learning tips and tricks cheatsheet
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#classification-metrics id=classification-metrics></a>Classification metrics</h2>
<p>In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model.</p>
<p><span class=""new-item item-b"">Confusion matrix</span> The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:</p>
<div class=mobile-container>
<table style=""margin-left: 10%"">
<colgroup><col width=120px>
<col width=50px>
<col width=200px>
<col width=200px>
</colgroup><tbody>
<tr style=""border-top: 0px"">
<td align=center colspan=2 rowspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""></td>
<td align=center colspan=2 style=""background: rgba(255, 255, 255, 1);border: 0px""><b>Predicted</b> class</td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>+</b></td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px""><b>-</b></td>
</tr>
<tr style=""border-top: 0px"">
<td align=center rowspan=2 style=""border: 0px""><b>Actual</b> class</td>
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>+</b></td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b>TP</b><br>True Positives</td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b>FN</b><br>False Negatives<br>Type II error</td>
</tr>
<tr style=""border-top: 0px"">
<td align=center style=""background: rgba(255, 255, 255, 1);border: 0px;""><b>-</b></td>
<td align=center style=""background: rgba(255, 0, 0, 0.25);border: 0px;""><b>FP</b><br>False Positives<br>Type I error</td>
<td align=center style=""background: rgba(0, 255, 0, 0.15);border: 0px;""><b>TN</b><br>True Negatives</td>
</tr>
</tbody>
</table>
</div>
<br>
<p><span class=""new-item item-r"">Main metrics</span> The following metrics are commonly used to assess the performance of classification models:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Metric</b></td>
<td align=center><b>Formula</b></td>
<td align=center><b>Interpretation</b></td>
</tr>
<tr>
<td align=center>Accuracy</td>
<td align=center>$\displaystyle\frac{\textrm{TP}+\textrm{TN}}{\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN}}$</td>
<td align=left>Overall performance of model</td>
</tr>
<tr>
<td align=center>Precision</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FP}}$</td>
<td align=left>How accurate the positive predictions are</td>
</tr>
<tr>
<td align=center>Recall<br>Sensitivity</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left>Coverage of actual positive sample</td>
</tr>
<tr>
<td align=center>Specificity</td>
<td align=center>$\displaystyle\frac{\textrm{TN}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left>Coverage of actual negative sample</td>
</tr>
<tr>
<td align=center>F1 score</td>
<td align=center>$\displaystyle\frac{2\textrm{TP}}{2\textrm{TP}+\textrm{FP}+\textrm{FN}}$</td>
<td align=left>Hybrid metric useful for unbalanced classes</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">ROC</span> The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Metric</b></td>
<td align=center><b>Formula</b></td>
<td align=center><b>Equivalent</b></td>
</tr>
<tr>
<td align=center>True Positive Rate<br>TPR</td>
<td align=center>$\displaystyle\frac{\textrm{TP}}{\textrm{TP}+\textrm{FN}}$</td>
<td align=left>Recall, sensitivity</td>
</tr>
<tr>
<td align=center>False Positive Rate<br>FPR</td>
<td align=center>$\displaystyle\frac{\textrm{FP}}{\textrm{TN}+\textrm{FP}}$</td>
<td align=left>1-specificity</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">AUC</span> The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure:</p>
<br>
<div class=mobile-container>
<center>
<img alt=""ROC AUC"" class=img-responsive src=teaching/cs-229/illustrations/roc-auc-en.png?d2dda6ec6e15f3e05597c058de976702 style=width:100%;max-width:700px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#regression-metrics id=regression-metrics></a>Regression metrics</h2>
<p><span class=""new-item item-b"">Basic metrics</span> Given a regression model $f$, the following metrics are commonly used to assess the performance of the model:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Total sum of squares</b></td>
<td align=center><b>Explained sum of squares</b></td>
<td align=center><b>Residual sum of squares</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{tot}}=\sum_{i=1}^m(y_i-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{reg}}=\sum_{i=1}^m(f(x_i)-\overline{y})^2$</td>
<td align=center>$\displaystyle\textrm{SS}_{\textrm{res}}=\sum_{i=1}^m(y_i-f(x_i))^2$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Coefficient of determination</span> The coefficient of determination, often noted $R^2$ or $r^2$, provides a measure of how well the observed outcomes are replicated by the model and is defined as follows:</p>
\[\boxed{R^2=1-\frac{\textrm{SS}_\textrm{res}}{\textrm{SS}_\textrm{tot}}}\]
<br>
<p><span class=""new-item item-r"">Main metrics</span> The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables $n$ that they take into consideration:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Mallow's Cp</b></td>
<td align=center><b>AIC</b></td>
<td align=center><b>BIC</b></td>
<td align=center><b>Adjusted $R^2$</b></td>
</tr>
<tr>
<td align=center>$\displaystyle\frac{\textrm{SS}_{\textrm{res}}+2(n+1)\widehat{\sigma}^2}{m}$</td>
<td align=center>$\displaystyle2\Big[(n+2)-\log(L)\Big]$</td>
<td align=center>$\displaystyle\log(m)(n+2)-2\log(L)$</td>
<td align=center>$\displaystyle1-\frac{(1-R^2)(m-1)}{m-n-1}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>where $L$ is the likelihood and $\widehat{\sigma}^2$ is an estimate of the variance associated with each response.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#model-selection id=model-selection></a>Model selection</h2>
<p><span class=""new-item item-b"">Vocabulary</span> When selecting a model, we distinguish 3 different parts of the data that we have as follows:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=33%>
<col width=33%>
<col width=33%>
</colgroup><tbody>
<tr>
<td align=center><b>Training set</b></td>
<td align=center><b>Validation set</b></td>
<td align=center><b>Testing set</b></td>
</tr>
<tr>
<td align=left>• Model is trained<br>
                 • Usually 80% of the dataset</td>
<td align=left>• Model is assessed<br>
                 • Usually 20% of the dataset<br>
                 • Also called hold-out or development set</td>
<td align=left>• Model gives predictions<br>
                 • Unseen data</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:</p>
<div class=mobile-container>
<center>
<img alt=""Partition of the dataset"" class=img-responsive src=teaching/cs-229/illustrations/train-val-test-en.png?0949795ac868562e193efdc249ae1066 style=width:100%;max-width:550px>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Cross-validation</span> Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=50%>
<col width=50%>
</colgroup><tbody>
<tr>
<td align=center><b>k-fold</b></td>
<td align=center><b>Leave-p-out</b></td>
</tr>
<tr>
<td align=left>• Training on $k-1$ folds and assessment on the remaining one<br>
                 • Generally $k=5$ or $10$</td>
<td align=left>• Training on $n-p$ observations and assessment on the $p$ remaining ones<br>
                 • Case $p=1$ is called leave-one-out</td>
</tr>
</tbody>
</table>
</center>
</div>
<p>The most commonly used method is called $k$-fold cross-validation and splits the training data into $k$ folds to validate the model on one fold while training the model on the $k-1$ other folds, all of this $k$ times. The error is then averaged over the $k$ folds and is named cross-validation error.</p>
<div class=mobile-container>
<center>
<img alt=Cross-validation class=img-responsive src=teaching/cs-229/illustrations/cross-validation-en.png?0f7ada4dc141d0af6b12bb21cc431471 style=width:100%;max-width:770px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Regularization</span> The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%; min-width:760px;"">
  <colgroup>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>LASSO</b></td>
<td align=center><b>Ridge</b></td>
<td align=center><b>Elastic Net</b></td>
</tr>
<tr>
<td align=left>• Shrinks coefficients to 0<br>• Good for variable selection</td>
<td align=left>Makes coefficients smaller</td>
<td align=left>Tradeoff between variable selection and small coefficients</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive src=teaching/cs-229/illustrations/lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive src=teaching/cs-229/illustrations/ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt=""Elastic Net"" class=img-responsive src=teaching/cs-229/illustrations/elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#diagnostics id=diagnostics></a>Diagnostics</h2>
<p><span class=""new-item item-b"">Bias</span> The bias of a model is the difference between the expected prediction and the correct model that we try to predict for given data points.</p>
<br>
<p><span class=""new-item item-b"">Variance</span> The variance of a model is the variability of the model prediction for given data points.</p>
<br>
<p><span class=""new-item item-r"">Bias/variance tradeoff</span> The simpler the model, the higher the bias, and the more complex the model, the higher the variance.</p>
<div class=mobile-container>
<center>
<br>
<table style=""table-layout:fixed; width:100%; min-width:735px;"">
  <colgroup>
    <col style=width:19%>
    <col style=width:27%>
    <col style=width:27%>
    <col style=width:27%>
  </colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>Underfitting</b></td>
<td align=center><b>Just right</b></td>
<td align=center><b>Overfitting</b></td>
</tr>
<tr>
<td align=center><b>Symptoms</b></td>
<td align=left>• High training error <br>• Training error close to test error <br>• High bias</td>
<td align=left style=vertical-align:top>• Training error slightly lower than test error</td>
<td align=left>• Very low training error <br>• Training error much lower than test error <br>• High variance</td>
</tr>
<tr>
<td align=center><b>Regression illustration</b></td>
<td align=center><img alt=""Underfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-underfit.png?cd7fd5e4d334aa31d323b7d3f994a9df></td>
<td align=center><img alt=""Right fit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-just-right.png?4018112cca66bdc10de14e7e59702a32></td>
<td align=center><img alt=""Overfit in regression"" class=img-responsive src=teaching/cs-229/illustrations/regression-overfit.png?4133157c77ba0baff93110d1d0e73382></td>
</tr>
<tr>
<td align=center><b>Classification illustration</b></td>
<td align=center><img alt=""Underfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-underfit.png?1f014836b68bfc74da1d767ca32783a3></td>
<td align=center><img alt=""Right fit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-just-right.png?67a70eb8c5fb11dd75d8e5035714a435></td>
<td align=center><img alt=""Overfit in classification"" class=img-responsive src=teaching/cs-229/illustrations/classification-overfit.png?64516ea4ed89dad5b422380ea1f8f350></td>
</tr>
<tr>
<td align=center><b>Deep learning illustration</b></td>
<td align=center><img alt=""Underfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-underfit-en.png?028697ac0c3ffff2a7a64edbab4dd61a></td>
<td align=center><img alt=""Right fit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-just-right-en.png?5accb2fc5bfed4b0e328fa798b1dd47c></td>
<td align=center><img alt=""Overfit in deep learning"" class=img-responsive src=teaching/cs-229/illustrations/deep-learning-overfit-en.png?026ff9256072273492de106ed7a9857f></td>
</tr>
<tr>
<td align=center><b>Possible remedies</b></td>
<td align=left>• Complexify model<br>• Add more features<br>• Train longer</td>
<td align=center style=""background: rgba(234, 234, 234, 1);""></td>
<td align=left>• Perform regularization<br>• Get more data</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Error analysis</span> Error analysis is analyzing the root cause of the difference in performance between the current and the perfect models.</p>
<br>
<p><span class=""new-item item-b"">Ablative analysis</span> Ablative analysis is analyzing the root cause of the difference in performance between the current and the baseline models.</p>
<br>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
16,"مقدمة في الاحتمالات والتوافيق

فضاء العينة يعرَّف فضاء العينة لتجربة ما بمجموعة كل النتائج الممكنة لهذه التجربة ويرمز لها بـ $S$.

الحدث أي مجموعة جزئية $E$ من فضاء العينة تعتبر حدثاً. أي، الحدث هو مجموعة من النتائج الممكنة للتجربة. إذا كانت نتيجة التجربة محتواة في $E$، عندها نقول أن الحدث $E$ وقع.

مسلَّمات الاحتمالات لكل حدث $E$، نرمز لإحتمال وقوعه بـ $P(E)$.

المسلَّمة 1 ― كل احتمال يأخد قيماً بين الـ 0 والـ 1 مضمَّنة:

\[\boxed{0\leqslant P(E)\leqslant 1}\]

المسلَّمة 2 ― احتمال وقوع حدث ابتدائي واحد على الأقل من الأحداث الابتدائية في فضاء العينة يساوي الـ 1:

\[\boxed{P(S)=1}\]

المسلَّمة 3 ― لأي سلسلة من الأحداث الغير متداخلة $E_1, ..., E_n$، لدينا:

\[\boxed{P\left(\bigcup_{i=1}^nE_i\right)=\sum_{i=1}^nP(E_i)}\]

التباديل التبديل هو عبارة عن عدد الاختيارات لـ $r$ غرض من مجموعة مكونة من $n$ غرض بترتيب محدد. عدد هكذا تراتيب يرمز له بـ $P(n, r)$، المعرف كالتالي:

\[\boxed{P(n, r)=\frac{n!}{(n-r)!}}\]

التوافيق التوفيق هو عدد الاختيارات لـ $r$ غرض من مجموعة مكونة من $n$ غرض بدون إعطاء الترتيب أية أهمية. عدد هكذا توافيق يرمز له بـ $C(n, r)$، المعرف كالتالي:

\[\boxed{C(n, r)=\frac{P(n, r)}{r!}=\frac{n!}{r!(n-r)!}}\]

ملاحظة: لكل $0\leqslant r\leqslant n$، يكون لدينا $P(n,r)\geqslant C(n,r)$

الاحتمال الشرطي

قاعدة بايز إذا كانت لدينا الأحداث $A$ و $B$ بحيث $P(B)>0$، يكون لدينا:

\[\boxed{P(A|B)=\frac{P(B|A)P(A)}{P(B)}}\]

ملاحظة: لدينا $P(A\cap B)=P(A)P(B|A)=P(A|B)P(B)$

القسم ليكن $\{A_i, i\in[\![1,n]\!]\}$ بحيث لكل $i$ لدينا $A_i

eq\varnothing$. نقول أن $\{A_i\}$ قسم إذا كان لدينا:

\[\boxed{\forall i

eq j, A_i\cap A_j=\emptyset\quad\textrm{ and }\quad\bigcup_{i=1}^nA_i=S}\]

ملاحظة: لأي حدث $B$ في فضاء العينة، لدينا $\displaystyle P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)$.

النسخة الموسعة من قاعدة بايز ليكن $\{A_i, i\in[\![1,n]\!]\}$ قسم من فضاء العينة. لدينا:

\[\boxed{P(A_k|B)=\frac{P(B|A_k)P(A_k)}{\displaystyle\sum_{i=1}^nP(B|A_i)P(A_i)}}\]

الاستقلال يكون حدثين $A$ و $B$ مستقلين إذا وفقط إذا كان لدينا:

\[\boxed{P(A\cap B)=P(A)P(B)}\]

المتحولات العشوائية

تعاريف

المتحول العشوائي المتحول العشوائي، ويرمز له عادة بـ $X$، هو دالة تربط كل عنصر في فضاء العينة إلى خط الأعداد الحقيقية.

دالة التوزيع التراكمي (CDF) تعرف دالة التوزيع التراكمي $F$، والتي تكون غير متناقصة بشكل رتيب وتحقق $\underset{x\rightarrow-\infty}{\textrm{lim}}F(x)=0$ و $\underset{x\rightarrow+\infty}{\textrm{lim}}F(x)=1$، كالتالي:

\[\boxed{F(x)=P(X\leqslant x)}\]

ملاحظة: لدينا $P(a < X\leqslant B)=F(b)-F(a)$.

دالة الكثافة الإحتمالية (PDF) دالة الكثافة الاحتمالية $f$ هي احتمال أن يأخذ $X$ قيماً بين قيمتين متجاورتين من قيم المتحول العشوائي.

علاقات تتضمن دالة الكثافة الاحتمالية ودالة التوزع التراكمي هذه بعض الخصائص التي من المهم معرفتها في الحالتين المتقطعة (D) والمستمرة (C).

الحالة دالة التوزع التراكمي $F$ دالة الكثافة الاحتمالية $f$ خصائص دالة الكثافة الاحتمالية (D) $\displaystyle F(x)=\sum_{x_i\leqslant x}P(X=x_i)$ $f(x_j)=P(X=x_j)$ $\displaystyle0\leqslant f(x_j)\leqslant1\textrm{ and }\sum_{j}f(x_j)=1$ (C) $\displaystyle F(x)=\int_{-\infty}^xf(y)dy$ $f(x)=\displaystyle \frac{dF}{dx}$ $\displaystyle f(x)\geqslant0\textrm{ and }\int_{-\infty}^{+\infty}f(x)dx=1$

التوقع وعزوم التوزيع فيما يلي المصطلحات المستخدمة للتعبير عن القيمة المتوقعة $E[X]$، الصيغة العامة للقيمة المتوقعة $E[g(X)]$، العزم رقم $k$ $E[X^k]$ ودالة السمة $\psi(\omega)$ للحالات المتقطعة والمستمرة:

حالة $E[X]$ $E[g(X)]$ $E[X^k]$ $\psi(\omega)$ (D) $\displaystyle \sum_{i=1}^nx_if(x_i)$ $\displaystyle \sum_{i=1}^ng(x_i)f(x_i)$ $\displaystyle \sum_{i=1}^nx_i^kf(x_i)$ $\displaystyle\sum_{i=1}^nf(x_i)e^{i\omega x_i}$ (C) $\displaystyle \int_{-\infty}^{+\infty}xf(x)dx$ $\displaystyle \int_{-\infty}^{+\infty}g(x)f(x)dx$ $\displaystyle \int_{-\infty}^{+\infty}x^kf(x)dx$ $\displaystyle\int_{-\infty}^{+\infty}f(x)e^{i\omega x}dx$

التباين تباين متحول عشوائي، والذي يرمز له عادةً ب $\textrm{Var}(X)$ أو $\sigma^2$، هو مقياس لانتشار دالة توزيع هذا المتحول. يحسب بالشكل التالي:

\[\boxed{\textrm{Var}(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2}\]

الانحراف المعياري الانحراف المعياري لمتحول عشوائي، والذي يرمز له عادةً ب $\sigma$، هو مقياس لانتشار دالة توزيع هذا المتحول بما يتوافق مع وحدات قياس المتحول العشوائي. يحسب بالشكل التالي:

\[\boxed{\sigma=\sqrt{\textrm{Var}(X)}}\]

تحويل المتحولات العشوائية لتكن المتحولات العشوائية $X$ و$Y$ مرتبطة من خلال دالة ما. باعتبار $f_X$ و$f_Y$ دالتا التوزيع ل$X$ و$Y$ على التوالي، يكون لدينا:

\[\boxed{f_Y(y)=f_X(x)\left|\frac{dx}{dy}\right|}\]

قاعدة لايبنتز (Leibniz) للتكامل لتكن $g$ دالة لـ $x$ وربما لـ $c$، ولتكن $a$ و$b$ حدود قد تعتمد على $c$. يكون لدينا:

\[\boxed{\frac{\partial}{\partial c}\left(\int_a^bg(x)dx\right)=\frac{\partial b}{\partial c}\cdot g(b)-\frac{\partial a}{\partial c}\cdot g(a)+\int_a^b\frac{\partial g}{\partial c}(x)dx}\]

التوزيعات الاحتمالية

متراجحة تشيبشيف (Chebyshev) ليكن $X$ متحولاً عشوائياً قيمته المتوقعة تساوي $\mu$. إذا كان لدينا $k, \sigma>0$، سنحصل على المتراجحة التالية:

\[\boxed{P(|X-\mu|\geqslant k\sigma)\leqslant\frac{1}{k^2}}\]

التوزيعات الأساسية فيما يلي التوزيعات الأساسية لأخذها بالاعتبار:

النوع التوزيع PDF $\psi(\omega)$ $E[X]$ $\textrm{Var}(X)$ رسم توضيحي (D) $X\sim\mathcal{B}(n, p)$ $\displaystyle \displaystyle\binom{n}{x} p^xq^{n-x}$ $(pe^{i\omega}+q)^n$ $np$ $npq$ (D) $X\sim\textrm{Po}(\mu)$ $\displaystyle \frac{\mu^x}{x!}e^{-\mu}$ $e^{\mu(e^{i\omega}-1)}$ $\mu$ $\mu$ (C) $X\sim\mathcal{U}(a, b)$ $\displaystyle \frac{1}{b-a}$ $\displaystyle\frac{e^{i\omega b}-e^{i\omega a}}{(b-a)i\omega}$ $\displaystyle\frac{a+b}{2}$ $\displaystyle\frac{(b-a)^2}{12}$ (C) $X\sim\mathcal{N}(\mu, \sigma)$ $\displaystyle \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$ $e^{i\omega\mu-\frac{1}{2}\omega^2\sigma^2}$ $\mu$ $\sigma^2$ (C) $X\sim\textrm{Exp}(\lambda)$ $\displaystyle \lambda e^{-\lambda x}$ $\displaystyle\frac{1}{1-\frac{i\omega}{\lambda}}$ $\displaystyle\frac{1}{\lambda}$ $\displaystyle\frac{1}{\lambda^2}$

المتغيرات العشوائية الموزعة اشتراكياً

الكثافة الهامشية والتوزيع التراكمي من دالة الكثافة الاحتمالية المشتركة $f_{XY}$، لدينا:

الحالة الكثافة الهامشية الدالة التراكمية (D) $\displaystyle f_X(x_i)=\sum_{j}f_{XY}(x_i,y_j)$ $\displaystyle F_{XY}(x,y)=\sum_{x_i\leqslant x}\sum_{y_j\leqslant y}f_{XY}(x_i,y_j)$ (C) $\displaystyle f_X(x)=\int_{-\infty}^{+\infty}f_{XY}(x,y)dy$ $\displaystyle F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^yf_{XY}(x',y')dx'dy'$

الكثافة الشرطية الكثافة الشرطية لـ $X$ بالنسبة لـ $Y$، والتي يرمز لها عادةً بـ $f_{X|Y}$، تعرف بالشكل التالي:

\[\boxed{f_{X|Y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)}}\]

الاستقلال يقال عن متحولين عشوائيين $X$ و $Y$ أنهما مستقلين إذا كان لدينا:

\[\boxed{f_{XY}(x,y)=f_X(x)f_Y(y)}\]

التغاير نعرف تغاير متحولين عشوائيين $X$ و $Y$، والذي نرمز له بـ $\sigma_{XY}^2$ أو بالرمز الأكثر شيوعاً $\textrm{Cov}(X,Y)$، كالتالي:

\[\boxed{\textrm{Cov}(X,Y)\triangleq\sigma_{XY}^2=E[(X-\mu_X)(Y-\mu_Y)]=E[XY]-\mu_X\mu_Y}\]

الارتباط بأخذ $\sigma_X$، $\sigma_Y$ كانحراف معياري لـ $X$ و $Y$، نعرف الارتباط بين المتحولات العشوائية $X$ و $Y$، والمرمز بـ $\rho_{XY}$، كالتالي:

\[\boxed{\rho_{XY}=\frac{\sigma_{XY}^2}{\sigma_X\sigma_Y}}\]

ملاحظة 1: لأي متحولات عشوائية $X, Y$، لدينا $\rho_{XY}\in[-1,1]$.

ملاحظة 2: إذا كان $X$ و $Y$ مستقلين، فإن $\rho_{XY} = 0$.

تقدير المُدخَل (parameter)

تعاريف

العينة العشوائية العينة العشوائية هي مجموعة من $n$ متحول عشوائي $X_1, ..., X_n$ والتي تكون مستقلة وموزعة تطابقياً مع $X$.

المُقَدِّر المُقَدِّر هو دالة للبيانات المستخدمة ويستخدم لاستنباط قيمة مُدخل غير معلوم ضمن نموذج إحصائي.

الانحياز انحياز مُقَدِّر $\hat{\theta}$ هو الفرق بين القيمة المتوقعة لتوزيع $\hat{\theta}$ والقيمة الحقيقية، كالتالي:

\[\boxed{\textrm{Bias}(\hat{\theta})=E[\hat{\theta}]-\theta}\]

ملاحظة: يقال عن مُقَدِّر أنه غير منحاز عندما يكون لدينا $E[\hat{\theta}]=\theta$.

تقدير المتوسط

متوسط العينة يستخدم متوسط عينة عشوائية لتقدير المتوسط الحقيقي $\mu$ لتوزيع ما، عادةً ما يرمز له بـ $\overline{X}$ ويعرف كالتالي:

\[\boxed{\overline{X}=\frac{1}{n}\sum_{i=1}^nX_i}\]

ملاحظة: متوسط العينة غير منحاز، أي $E[\overline{X}]=\mu$.

مبرهنة النهاية المركزية ليكن لدينا عينة عشوائية $X_1, ..., X_n$ والتي تتبع لتوزيع معطى له متوسط $\mu$ وتباين $\sigma^2$، فيكون:

\[\boxed{\overline{X}\underset{n\rightarrow+\infty}{\sim}\mathcal{N}\left(\mu, \frac{\sigma}{\sqrt{n}}\right)}\]

تقدير التباين

تباين العينة يستخدم تباين عينة عشوائية لتقدير التباين الحقيقي $\sigma^2$ لتوزيع ما، والذي يرمز له عادةً بـ $s^2$ أو $\hat{\sigma}^2$ ويعرّف بالشكل التالي:

\[\boxed{s^2=\hat{\sigma}^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2}\]

ملاحظة: تباين العينة غير منحاز، أي $E[s^2]=\sigma^2$.

علاقة مربع كاي (chi-squared) مع تباين العينة ليكن $s^2$ تباين العينة لعينة عشوائية. لدينا:

\[\boxed{\frac{s^2(n-1)}{\sigma^2}\sim\chi_{n-1}^2}\]","مقدمة في الاحتمالات والتوافيقفضاء العينة يعرَّف فضاء العينة لتجربة ما بمجموعة كل النتائج الممكنة لهذه التجربة ويرمز لها بـ $S$.
مسلَّمات الاحتمالات لكل حدث $E$، نرمز لإحتمال وقوعه بـ $P(E)$.
نقول أن $\{A_i\}$ قسم إذا كان لدينا:\[\boxed{\forall ieq j, A_i\cap A_j=\emptyset\quad\textrm{ and }\quad\bigcup_{i=1}^nA_i=S}\]ملاحظة: لأي حدث $B$ في فضاء العينة، لدينا $\displaystyle P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)$.
دالة الكثافة الإحتمالية (PDF) دالة الكثافة الاحتمالية $f$ هي احتمال أن يأخذ $X$ قيماً بين قيمتين متجاورتين من قيم المتحول العشوائي.
علاقات تتضمن دالة الكثافة الاحتمالية ودالة التوزع التراكمي هذه بعض الخصائص التي من المهم معرفتها في الحالتين المتقطعة (D) والمستمرة (C).","['يرمز', 'لدينا', 'x', 'العينة', 'الاحتمالات', 'إذا', 'بـ', 'c', 'دالة', 'displaystyle', 'الكثافة', 'والإحصائيات']",ar,الاحتمالات والإحصائيات,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>الاحتمالات والإحصائيات - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/refresher-probabilities-statistics rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>الاحتمالات والإحصائيات</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>مقدمة</a></div> <div class=dropdown-container> <a href=#introduction><span>فضاء العينة</span></a> <a href=#introduction><span>الحدث</span></a> <a href=#introduction><span>التبديل</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#conditional-probability>الاحتمال الشرطي</a></div> <div class=dropdown-container> <a href=#conditional-probability><span>قاعدة بايز</span></a> <a href=#conditional-probability><span>الاستقلال</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#random-variables>المتحولات العشوائية</a></div> <div class=dropdown-container> <a href=#random-variables><span>تعاريف</span></a> <a href=#random-variables><span>القيمة المتوقعة</span></a> <a href=#random-variables><span>التباين</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#probability-distributions>التوزيعات الاحتمالية</a></div> <div class=dropdown-container> <a href=#probability-distributions><span>متراجحة تشيبشيف</span></a> <a href=#probability-distributions><span>توزيعات رئيسية</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#joint-random-variables>المتحولات العشوائية الموزعة اشتراكياً</a></div> <div class=dropdown-container> <a href=#joint-random-variables><span>الكثافة</span></a> <a href=#joint-random-variables><span>التغاير</span></a> <a href=#joint-random-variables><span>الارتباط</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#parameter-estimation>تقدير المُدخَل</a></div> <div class=dropdown-container> <a href=#parameter-estimation><span>المتوسط</span></a> <a href=#parameter-estimation><span>التباين</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/refresher-probabilities-statistics.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/refresher-probabilities-statistics'"" type=button><b>الاحتمالات والإحصائيات</b></button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/refresher-algebra-calculus'"" type=button>الجبر الخطي والتفاضل</button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>مراجعة الاحتمالات والإحصاء</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة محمود أصلان. تمت المراجعة بواسطة فارس القنيعير.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>مقدمة في الاحتمالات والتوافيق</h2>
<p><span class=""new-item item-g"">فضاء العينة</span> يعرَّف فضاء العينة لتجربة ما بمجموعة كل النتائج الممكنة لهذه التجربة ويرمز لها بـ $S$.</p>
<br>
<p><span class=""new-item item-g"">الحدث</span> أي مجموعة جزئية $E$ من فضاء العينة تعتبر حدثاً. أي، الحدث هو مجموعة من النتائج الممكنة للتجربة. إذا كانت نتيجة التجربة محتواة في $E$، عندها نقول أن الحدث $E$ وقع.</p>
<br>
<p><span class=""new-item item-g"">مسلَّمات الاحتمالات</span> لكل حدث $E$، نرمز لإحتمال وقوعه بـ $P(E)$.</p>
<p><i>المسلَّمة 1</i> ― كل احتمال يأخد قيماً بين الـ 0 والـ 1 مضمَّنة:</p>
<div class=mobile-container>
\[\boxed{0\leqslant P(E)\leqslant 1}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 1"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-1.png?20e52e95618c88a4c10a5232c2c60ed0 style=width:100%;max-width:600px>
</center>
</div>
<p><i>المسلَّمة 2</i> ― احتمال وقوع حدث ابتدائي واحد على الأقل من الأحداث الابتدائية في فضاء العينة يساوي الـ 1:</p>
<div class=mobile-container>
\[\boxed{P(S)=1}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 2"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-2.png?b1295ceda8ee7aa3202488a1ecb6133d style=width:100%;max-width:600px>
</center>
</div>
<p><i>المسلَّمة 3</i> ― لأي سلسلة من الأحداث الغير متداخلة $E_1, ..., E_n$، لدينا:</p>
<div class=mobile-container>
\[\boxed{P\left(\bigcup_{i=1}^nE_i\right)=\sum_{i=1}^nP(E_i)}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 3"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-3.png?3c16a178334bb1d048d6d19c49c9a78d style=width:100%;max-width:600px>
</center>
</div>
<br>
<p><span class=""new-item item-b"">التباديل</span> التبديل هو عبارة عن عدد الاختيارات لـ $r$ غرض من مجموعة مكونة من $n$ غرض بترتيب محدد. عدد هكذا تراتيب يرمز له بـ $P(n, r)$، المعرف كالتالي:</p>
<div class=mobile-container>
\[\boxed{P(n, r)=\frac{n!}{(n-r)!}}\]
</div>
<br>
<p><span class=""new-item item-b"">التوافيق</span> التوفيق هو عدد الاختيارات لـ $r$ غرض من مجموعة مكونة من $n$ غرض بدون إعطاء الترتيب أية أهمية. عدد هكذا توافيق يرمز له بـ $C(n, r)$، المعرف كالتالي:</p>
<div class=mobile-container>
\[\boxed{C(n, r)=\frac{P(n, r)}{r!}=\frac{n!}{r!(n-r)!}}\]
</div>
<p><span class=remark>ملاحظة: لكل $0\leqslant r\leqslant n$، يكون لدينا $P(n,r)\geqslant C(n,r)$</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#conditional-probability id=conditional-probability></a>الاحتمال الشرطي</h2>
<p><span class=""new-item item-r"">قاعدة بايز</span> إذا كانت لدينا الأحداث $A$ و $B$ بحيث $P(B)&gt;0$، يكون لدينا:</p>
<div class=mobile-container>
\[\boxed{P(A|B)=\frac{P(B|A)P(A)}{P(B)}}\]
</div>
<div class=mobile-container>
<p><span class=remark>ملاحظة: لدينا $P(A\cap B)=P(A)P(B|A)=P(A|B)P(B)$</span></p>
</div>
<br>
<p><span class=""new-item item-g"">القسم</span> ليكن $\{A_i, i\in[\![1,n]\!]\}$ بحيث لكل $i$ لدينا $A_i\neq\varnothing$. نقول أن $\{A_i\}$ قسم إذا كان لدينا:</p>
<div class=mobile-container>
\[\boxed{\forall i\neq j, A_i\cap A_j=\emptyset\quad\textrm{ and }\quad\bigcup_{i=1}^nA_i=S}\]
</div>
<div class=mobile-container>
<center>
<img alt=Partition class=img-responsive src=teaching/cme-106/illustrations/partition.png?1e98f377294dced2c2ebbb59ce1f6188 style=width:100%;max-width:600px>
</center>
</div>
<p><span class=remark>ملاحظة: لأي حدث $B$ في فضاء العينة، لدينا $\displaystyle P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)$.</span></p>
<br>
<p><span class=""new-item item-r"">النسخة الموسعة من قاعدة بايز</span> ليكن $\{A_i, i\in[\![1,n]\!]\}$ قسم من فضاء العينة. لدينا:</p>
<div class=mobile-container>
\[\boxed{P(A_k|B)=\frac{P(B|A_k)P(A_k)}{\displaystyle\sum_{i=1}^nP(B|A_i)P(A_i)}}\]
</div>
<br>
<p><span class=""new-item item-g"">الاستقلال</span> يكون حدثين $A$ و $B$ مستقلين إذا وفقط إذا كان لدينا:</p>
<div class=mobile-container>
\[\boxed{P(A\cap B)=P(A)P(B)}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#random-variables id=random-variables></a>المتحولات العشوائية</h2>
<h3>تعاريف</h3>
<p><span class=""new-item item-g"">المتحول العشوائي</span> المتحول العشوائي، ويرمز له عادة بـ $X$، هو دالة تربط كل عنصر في فضاء العينة إلى خط الأعداد الحقيقية.</p>
<br>
<p><span class=""new-item item-g"">دالة التوزيع التراكمي <span class=""ltr stick-together"">(CDF)</span></span> تعرف دالة التوزيع التراكمي $F$، والتي تكون غير متناقصة بشكل رتيب وتحقق $\underset{x\rightarrow-\infty}{\textrm{lim}}F(x)=0$ و $\underset{x\rightarrow+\infty}{\textrm{lim}}F(x)=1$، كالتالي:</p>
<div class=mobile-container>
\[\boxed{F(x)=P(X\leqslant x)}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Cumulative distribution function"" class=img-responsive src=teaching/cme-106/illustrations/cdf.png?f60eb6371235b9fe2d823aff3670ce20 style=width:100%;max-width:600px>
</center>
</div>
<p><span class=remark>ملاحظة: لدينا $P(a &lt; X\leqslant B)=F(b)-F(a)$.</span></p>
<br>
<p><span class=""new-item item-g"">دالة الكثافة الإحتمالية <span class=""ltr stick-together"">(PDF)</span></span> دالة الكثافة الاحتمالية $f$ هي احتمال أن يأخذ $X$ قيماً بين قيمتين متجاورتين من قيم المتحول العشوائي.</p>
<br>
<p><span class=""new-item item-b"">علاقات تتضمن دالة الكثافة الاحتمالية ودالة التوزع التراكمي</span> هذه بعض الخصائص التي من المهم معرفتها في الحالتين المتقطعة <span class=""ltr stick-together"">(D)</span> والمستمرة <span class=""ltr stick-together"">(C)</span>.</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>الحالة</b></td>
<td align=center><b>دالة التوزع التراكمي $F$</b></td>
<td align=center><b>دالة الكثافة الاحتمالية $f$</b></td>
<td align=center><b>خصائص دالة الكثافة الاحتمالية</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$\displaystyle F(x)=\sum_{x_i\leqslant x}P(X=x_i)$</td>
<td align=center>$f(x_j)=P(X=x_j)$</td>
<td align=center>$\displaystyle0\leqslant f(x_j)\leqslant1\textrm{ and }\sum_{j}f(x_j)=1$</td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$\displaystyle F(x)=\int_{-\infty}^xf(y)dy$</td>
<td align=center>$f(x)=\displaystyle \frac{dF}{dx}$</td>
<td align=center>$\displaystyle f(x)\geqslant0\textrm{ and }\int_{-\infty}^{+\infty}f(x)dx=1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">التوقع وعزوم التوزيع</span> فيما يلي المصطلحات المستخدمة للتعبير عن القيمة المتوقعة $E[X]$، الصيغة العامة للقيمة المتوقعة $E[g(X)]$، العزم رقم $k$  $E[X^k]$  ودالة السمة $\psi(\omega)$ للحالات المتقطعة والمستمرة:
</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>حالة</b></td>
<td align=center><b>$E[X]$</b></td>
<td align=center><b>$E[g(X)]$</b></td>
<td align=center><b>$E[X^k]$</b></td>
<td align=center><b>$\psi(\omega)$</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$\displaystyle \sum_{i=1}^nx_if(x_i)$</td>
<td align=center>$\displaystyle \sum_{i=1}^ng(x_i)f(x_i)$</td>
<td align=center>$\displaystyle \sum_{i=1}^nx_i^kf(x_i)$</td>
<td align=center>$\displaystyle\sum_{i=1}^nf(x_i)e^{i\omega x_i}$</td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}xf(x)dx$</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}g(x)f(x)dx$</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}x^kf(x)dx$</td>
<td align=center>$\displaystyle\int_{-\infty}^{+\infty}f(x)e^{i\omega x}dx$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">التباين</span> تباين متحول عشوائي، والذي يرمز له عادةً ب <span class=""ltr stick-together"">$\textrm{Var}(X)$</span> أو $\sigma^2$، هو مقياس لانتشار دالة توزيع هذا المتحول. يحسب بالشكل التالي:</p>
<div class=mobile-container>
\[\boxed{\textrm{Var}(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2}\]
</div>
<br>
<p><span class=""new-item item-g"">الانحراف المعياري</span> الانحراف المعياري لمتحول عشوائي، والذي يرمز له عادةً ب $\sigma$، هو مقياس لانتشار دالة توزيع هذا المتحول بما يتوافق مع وحدات قياس المتحول العشوائي. يحسب بالشكل التالي:</p>
<div class=mobile-container>
\[\boxed{\sigma=\sqrt{\textrm{Var}(X)}}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Standard deviation"" class=img-responsive src=teaching/cme-106/illustrations/std.png?782af23c9eeaaefc688417f82dabfba0 style=width:100%;max-width:600px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">تحويل المتحولات العشوائية</span> لتكن المتحولات العشوائية $X$ و$Y$ مرتبطة من خلال دالة ما. باعتبار $f_X$ و$f_Y$ دالتا التوزيع ل$X$ و$Y$ على التوالي، يكون لدينا:</p>
<div class=mobile-container>
\[\boxed{f_Y(y)=f_X(x)\left|\frac{dx}{dy}\right|}\]
</div>
<br>
<p><span class=""new-item item-b""> قاعدة لايبنتز <span class=""ltr stick-together"">(Leibniz)</span> للتكامل</span> لتكن $g$ دالة لـ $x$ وربما لـ $c$، ولتكن $a$ و$b$ حدود قد تعتمد على $c$. يكون لدينا:</p>
<div class=mobile-container>
\[\boxed{\frac{\partial}{\partial c}\left(\int_a^bg(x)dx\right)=\frac{\partial b}{\partial c}\cdot g(b)-\frac{\partial a}{\partial c}\cdot g(a)+\int_a^b\frac{\partial g}{\partial c}(x)dx}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#probability-distributions id=probability-distributions></a>التوزيعات الاحتمالية</h2>
<p><span class=""new-item item-r"">متراجحة تشيبشيف <span class=""ltr stick-together"">(Chebyshev)</span></span> ليكن $X$ متحولاً عشوائياً قيمته المتوقعة تساوي $\mu$. إذا كان لدينا $k, \sigma&gt;0$، سنحصل على المتراجحة التالية:</p>
<div class=mobile-container>
\[\boxed{P(|X-\mu|\geqslant k\sigma)\leqslant\frac{1}{k^2}}\]
</div>
<br>
<p><span class=""new-item item-g"">التوزيعات الأساسية</span> فيما يلي التوزيعات الأساسية لأخذها بالاعتبار:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%;min-width:950px;"">
<colgroup>
<col style=width:60px>
<col style=width:105px>
<col style=width:125px>
<col style=width:90px>
<col style=width:65px>
<col style=width:75px>
<col style=width:250px>
</colgroup>
<tbody>
<tr>
<td align=center><b>النوع</b></td>
<td align=center><b>التوزيع</b></td>
<td align=center><b><span class=""ltr stick-together"">PDF</span></b></td>
<td align=center><b>$\psi(\omega)$</b></td>
<td align=center><b>$E[X]$</b></td>
<td align=center><b>$\textrm{Var}(X)$</b></td>
<td align=center><b>رسم توضيحي</b></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(D)</span></td>
<td align=center>$X\sim\mathcal{B}(n, p)$</td>
<td align=center>$\displaystyle \displaystyle\binom{n}{x} p^xq^{n-x}$</td>
<td align=center>$(pe^{i\omega}+q)^n$</td>
<td align=center>$np$</td>
<td align=center>$npq$</td>
<td align=center><img alt=""Binomial distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-binomial.png?f417e75085cbe5ab9970ee9cbd2d8a81></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(D)</span></td>
<td align=center>$X\sim\textrm{Po}(\mu)$</td>
<td align=center>$\displaystyle \frac{\mu^x}{x!}e^{-\mu}$</td>
<td align=center>$e^{\mu(e^{i\omega}-1)}$</td>
<td align=center>$\mu$</td>
<td align=center>$\mu$</td>
<td align=center><img alt=""Poisson distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-poisson.png?d1fc605f455fe8ebb320ccdbacd2e1bd></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(C)</span></td>
<td align=center>$X\sim\mathcal{U}(a, b)$</td>
<td align=center>$\displaystyle \frac{1}{b-a}$</td>
<td align=center>$\displaystyle\frac{e^{i\omega b}-e^{i\omega a}}{(b-a)i\omega}$</td>
<td align=center>$\displaystyle\frac{a+b}{2}$</td>
<td align=center>$\displaystyle\frac{(b-a)^2}{12}$</td>
<td align=center><img alt=""Uniform distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-uniform.png?cd537566da8203b80a0f0ed5ca6a9701></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(C)</span></td>
<td align=center>$X\sim\mathcal{N}(\mu, \sigma)$</td>
<td align=center>$\displaystyle \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$</td>
<td align=center>$e^{i\omega\mu-\frac{1}{2}\omega^2\sigma^2}$</td>
<td align=center>$\mu$</td>
<td align=center>$\sigma^2$</td>
<td align=center><img alt=""Normal distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-normal.png?0e0141a251cd9774758b029cc353b78a></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(C)</span></td>
<td align=center>$X\sim\textrm{Exp}(\lambda)$</td>
<td align=center>$\displaystyle \lambda e^{-\lambda x}$</td>
<td align=center>$\displaystyle\frac{1}{1-\frac{i\omega}{\lambda}}$</td>
<td align=center>$\displaystyle\frac{1}{\lambda}$</td>
<td align=center>$\displaystyle\frac{1}{\lambda^2}$</td>
<td align=center><img alt=""Exponential distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-exponential.png?9b6795473f6b7d74f90276ef62897770></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#joint-random-variables id=joint-random-variables></a>المتغيرات العشوائية الموزعة اشتراكياً</h2>
<p><span class=""new-item item-g"">الكثافة الهامشية والتوزيع التراكمي</span> من دالة الكثافة الاحتمالية المشتركة $f_{XY}$، لدينا:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>الحالة</b></td>
<td align=center><b>الكثافة الهامشية</b></td>
<td align=center><b>الدالة التراكمية</b></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(D)</span></td>
<td align=center>$\displaystyle f_X(x_i)=\sum_{j}f_{XY}(x_i,y_j)$</td>
<td align=center>$\displaystyle F_{XY}(x,y)=\sum_{x_i\leqslant x}\sum_{y_j\leqslant y}f_{XY}(x_i,y_j)$</td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">(C)</span></td>
<td align=center>$\displaystyle f_X(x)=\int_{-\infty}^{+\infty}f_{XY}(x,y)dy$</td>
<td align=center>$\displaystyle F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^yf_{XY}(x',y')dx'dy'$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">الكثافة الشرطية</span> الكثافة الشرطية لـ $X$ بالنسبة لـ $Y$، والتي يرمز لها عادةً بـ $f_{X|Y}$، تعرف بالشكل التالي:</p>
<div class=mobile-container>
\[\boxed{f_{X|Y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)}}\]
</div>
<br>
<p><span class=""new-item item-g"">الاستقلال</span> يقال عن متحولين عشوائيين $X$ و $Y$ أنهما مستقلين إذا كان لدينا:</p>
<div class=mobile-container>
\[\boxed{f_{XY}(x,y)=f_X(x)f_Y(y)}\]
</div>
<br>
<p><span class=""new-item item-g"">التغاير</span> نعرف تغاير متحولين عشوائيين $X$ و $Y$، والذي نرمز له بـ $\sigma_{XY}^2$ أو بالرمز الأكثر شيوعاً $\textrm{Cov}(X,Y)$، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\textrm{Cov}(X,Y)\triangleq\sigma_{XY}^2=E[(X-\mu_X)(Y-\mu_Y)]=E[XY]-\mu_X\mu_Y}\]
</div>
<br>
<p><span class=""new-item item-g"">الارتباط</span> بأخذ $\sigma_X$، $\sigma_Y$ كانحراف معياري لـ $X$ و $Y$، نعرف الارتباط بين المتحولات العشوائية $X$ و $Y$، والمرمز بـ $\rho_{XY}$، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\rho_{XY}=\frac{\sigma_{XY}^2}{\sigma_X\sigma_Y}}\]
</div>
<p><span class=remark>ملاحظة 1: لأي متحولات عشوائية $X, Y$، لدينا $\rho_{XY}\in[-1,1]$.</span></p>
<p><span class=remark>ملاحظة 2: إذا كان $X$ و $Y$ مستقلين، فإن $\rho_{XY} = 0$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#parameter-estimation id=parameter-estimation></a>تقدير المُدخَل <span class=""ltr stick-together"">(parameter)</span></h2>
<h3>تعاريف</h3>
<p><span class=""new-item item-r"">العينة العشوائية</span> العينة العشوائية هي مجموعة من $n$ متحول عشوائي $X_1, ..., X_n$ والتي تكون مستقلة وموزعة تطابقياً مع $X$.</p>
<br>
<p><span class=""new-item item-g"">المُقَدِّر</span> المُقَدِّر هو دالة للبيانات المستخدمة ويستخدم لاستنباط قيمة مُدخل غير معلوم ضمن نموذج إحصائي.</p>
<br>
<p><span class=""new-item item-g"">الانحياز</span> انحياز مُقَدِّر $\hat{\theta}$ هو الفرق بين القيمة المتوقعة لتوزيع $\hat{\theta}$ والقيمة الحقيقية، كالتالي:</p>
<div class=mobile-container>
\[\boxed{\textrm{Bias}(\hat{\theta})=E[\hat{\theta}]-\theta}\]
</div>
<p><span class=remark>ملاحظة: يقال عن مُقَدِّر أنه غير منحاز عندما يكون لدينا $E[\hat{\theta}]=\theta$.</span></p>
<br>
<h3>تقدير المتوسط</h3>
<p><span class=""new-item item-b"">متوسط العينة</span> يستخدم متوسط عينة عشوائية لتقدير المتوسط الحقيقي $\mu$ لتوزيع ما، عادةً ما يرمز له بـ $\overline{X}$ ويعرف كالتالي:</p>
<div class=mobile-container>
\[\boxed{\overline{X}=\frac{1}{n}\sum_{i=1}^nX_i}\]
</div>
<p><span class=remark>ملاحظة: متوسط العينة غير منحاز، أي $E[\overline{X}]=\mu$.</span></p>
<br>
<p><span class=""new-item item-r"">مبرهنة النهاية المركزية</span> ليكن لدينا عينة عشوائية $X_1, ..., X_n$ والتي تتبع لتوزيع معطى له متوسط $\mu$ وتباين $\sigma^2$، فيكون:</p>
<div class=mobile-container>
\[\boxed{\overline{X}\underset{n\rightarrow+\infty}{\sim}\mathcal{N}\left(\mu, \frac{\sigma}{\sqrt{n}}\right)}\]
</div>
<br>
<h3>تقدير التباين</h3>
<p><span class=""new-item item-b"">تباين العينة</span> يستخدم تباين عينة عشوائية لتقدير التباين الحقيقي $\sigma^2$ لتوزيع ما، والذي يرمز له عادةً بـ $s^2$ أو $\hat{\sigma}^2$ ويعرّف بالشكل التالي:</p>
<div class=mobile-container>
\[\boxed{s^2=\hat{\sigma}^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2}\]
</div>
<p><span class=remark>ملاحظة: تباين العينة غير منحاز، أي $E[s^2]=\sigma^2$.</span></p>
<br>
<p><span class=""new-item item-r"">علاقة مربع كاي <span class=""ltr stick-together"">(chi-squared)</span> مع تباين العينة</span> ليكن $s^2$ تباين العينة لعينة عشوائية. لدينا:</p>
<div class=mobile-container>
\[\boxed{\frac{s^2(n-1)}{\sigma^2}\sim\chi_{n-1}^2}\]
</div>
<br>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
17,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Probabilities Algebra

Probabilities and Statistics refresher Star

Introduction to Probability and Combinatorics

Sample space The set of all possible outcomes of an experiment is known as the sample space of the experiment and is denoted by $S$.

Event Any subset $E$ of the sample space is known as an event. That is, an event is a set consisting of possible outcomes of the experiment. If the outcome of the experiment is contained in $E$, then we say that $E$ has occurred.

Axioms of probability For each event $E$, we denote $P(E)$ as the probability of event $E$ occurring.

Axiom 1 ― Every probability is between 0 and 1 included, i.e:

\[\boxed{0\leqslant P(E)\leqslant 1}\]

Axiom 2 ― The probability that at least one of the elementary events in the entire sample space will occur is 1, i.e:

\[\boxed{P(S)=1}\]

Axiom 3 ― For any sequence of mutually exclusive events $E_1, ..., E_n$, we have:

\[\boxed{P\left(\bigcup_{i=1}^nE_i\right)=\sum_{i=1}^nP(E_i)}\]

Permutation A permutation is an arrangement of $r$ objects from a pool of $n$ objects, in a given order. The number of such arrangements is given by $P(n, r)$, defined as:

\[\boxed{P(n, r)=\frac{n!}{(n-r)!}}\]

Combination A combination is an arrangement of $r$ objects from a pool of $n$ objects, where the order does not matter. The number of such arrangements is given by $C(n, r)$, defined as:

\[\boxed{C(n, r)=\frac{P(n, r)}{r!}=\frac{n!}{r!(n-r)!}}\]

Remark: we note that for $0\leqslant r\leqslant n$, we have $P(n,r)\geqslant C(n,r)$.

Conditional Probability

Bayes' rule For events $A$ and $B$ such that $P(B)>0$, we have:

\[\boxed{P(A|B)=\frac{P(B|A)P(A)}{P(B)}}\]

Remark: we have $P(A\cap B)=P(A)P(B|A)=P(A|B)P(B)$.

Partition Let $\{A_i, i\in[\![1,n]\!]\}$ be such that for all $i$, $A_i

eq\varnothing$. We say that $\{A_i\}$ is a partition if we have:

\[\boxed{\forall i

eq j, A_i\cap A_j=\emptyset\quad\textrm{ and }\quad\bigcup_{i=1}^nA_i=S}\]

Remark: for any event $B$ in the sample space, we have $\displaystyle P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)$.

Extended form of Bayes' rule Let $\{A_i, i\in[\![1,n]\!]\}$ be a partition of the sample space. We have:

\[\boxed{P(A_k|B)=\frac{P(B|A_k)P(A_k)}{\displaystyle\sum_{i=1}^nP(B|A_i)P(A_i)}}\]

Independence Two events $A$ and $B$ are independent if and only if we have:

\[\boxed{P(A\cap B)=P(A)P(B)}\]

Random Variables

Definitions

Random variable A random variable, often noted $X$, is a function that maps every element in a sample space to a real line.

Cumulative distribution function (CDF) The cumulative distribution function $F$, which is monotonically non-decreasing and is such that $\underset{x\rightarrow-\infty}{\textrm{lim}}F(x)=0$ and $\underset{x\rightarrow+\infty}{\textrm{lim}}F(x)=1$, is defined as:

\[\boxed{F(x)=P(X\leqslant x)}\]

Remark: we have $P(a < X\leqslant B)=F(b)-F(a)$.

Probability density function (PDF) The probability density function $f$ is the probability that $X$ takes on values between two adjacent realizations of the random variable.

Relationships involving the PDF and CDF Here are the important properties to know in the discrete (D) and the continuous (C) cases.

Case CDF $F$ PDF $f$ Properties of PDF (D) $\displaystyle F(x)=\sum_{x_i\leqslant x}P(X=x_i)$ $f(x_j)=P(X=x_j)$ $\displaystyle0\leqslant f(x_j)\leqslant1\textrm{ and }\sum_{j}f(x_j)=1$ (C) $\displaystyle F(x)=\int_{-\infty}^xf(y)dy$ $f(x)=\displaystyle \frac{dF}{dx}$ $\displaystyle f(x)\geqslant0\textrm{ and }\int_{-\infty}^{+\infty}f(x)dx=1$

Expectation and Moments of the Distribution Here are the expressions of the expected value $E[X]$, generalized expected value $E[g(X)]$, $k^{th}$ moment $E[X^k]$ and characteristic function $\psi(\omega)$ for the discrete and continuous cases:

Case $E[X]$ $E[g(X)]$ $E[X^k]$ $\psi(\omega)$ (D) $\displaystyle \sum_{i=1}^nx_if(x_i)$ $\displaystyle \sum_{i=1}^ng(x_i)f(x_i)$ $\displaystyle \sum_{i=1}^nx_i^kf(x_i)$ $\displaystyle\sum_{i=1}^nf(x_i)e^{i\omega x_i}$ (C) $\displaystyle \int_{-\infty}^{+\infty}xf(x)dx$ $\displaystyle \int_{-\infty}^{+\infty}g(x)f(x)dx$ $\displaystyle \int_{-\infty}^{+\infty}x^kf(x)dx$ $\displaystyle\int_{-\infty}^{+\infty}f(x)e^{i\omega x}dx$

Variance The variance of a random variable, often noted Var$(X)$ or $\sigma^2$, is a measure of the spread of its distribution function. It is determined as follows:

\[\boxed{\textrm{Var}(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2}\]

Standard deviation The standard deviation of a random variable, often noted $\sigma$, is a measure of the spread of its distribution function which is compatible with the units of the actual random variable. It is determined as follows:

\[\boxed{\sigma=\sqrt{\textrm{Var}(X)}}\]

Transformation of random variables Let the variables $X$ and $Y$ be linked by some function. By noting $f_X$ and $f_Y$ the distribution function of $X$ and $Y$ respectively, we have:

\[\boxed{f_Y(y)=f_X(x)\left|\frac{dx}{dy}\right|}\]

Leibniz integral rule Let $g$ be a function of $x$ and potentially $c$, and $a, b$ boundaries that may depend on $c$. We have:

\[\boxed{\frac{\partial}{\partial c}\left(\int_a^bg(x)dx\right)=\frac{\partial b}{\partial c}\cdot g(b)-\frac{\partial a}{\partial c}\cdot g(a)+\int_a^b\frac{\partial g}{\partial c}(x)dx}\]

Probability Distributions

Chebyshev's inequality Let $X$ be a random variable with expected value $\mu$. For $k, \sigma>0$, we have the following inequality:

\[\boxed{P(|X-\mu|\geqslant k\sigma)\leqslant\frac{1}{k^2}}\]

Main distributions Here are the main distributions to have in mind:

Type Distribution PDF $\psi(\omega)$ $E[X]$ $\textrm{Var}(X)$ Illustration (D) $X\sim\mathcal{B}(n, p)$ $\displaystyle \displaystyle\binom{n}{x} p^xq^{n-x}$ $(pe^{i\omega}+q)^n$ $np$ $npq$ (D) $X\sim\textrm{Po}(\mu)$ $\displaystyle \frac{\mu^x}{x!}e^{-\mu}$ $e^{\mu(e^{i\omega}-1)}$ $\mu$ $\mu$ (C) $X\sim\mathcal{U}(a, b)$ $\displaystyle \frac{1}{b-a}$ $\displaystyle\frac{e^{i\omega b}-e^{i\omega a}}{(b-a)i\omega}$ $\displaystyle\frac{a+b}{2}$ $\displaystyle\frac{(b-a)^2}{12}$ (C) $X\sim\mathcal{N}(\mu, \sigma)$ $\displaystyle \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$ $e^{i\omega\mu-\frac{1}{2}\omega^2\sigma^2}$ $\mu$ $\sigma^2$ (C) $X\sim\textrm{Exp}(\lambda)$ $\displaystyle \lambda e^{-\lambda x}$ $\displaystyle\frac{1}{1-\frac{i\omega}{\lambda}}$ $\displaystyle\frac{1}{\lambda}$ $\displaystyle\frac{1}{\lambda^2}$

Jointly Distributed Random Variables

Marginal density and cumulative distribution From the joint density probability function $f_{XY}$ , we have

Case Marginal density Cumulative function (D) $\displaystyle f_X(x_i)=\sum_{j}f_{XY}(x_i,y_j)$ $\displaystyle F_{XY}(x,y)=\sum_{x_i\leqslant x}\sum_{y_j\leqslant y}f_{XY}(x_i,y_j)$ (C) $\displaystyle f_X(x)=\int_{-\infty}^{+\infty}f_{XY}(x,y)dy$ $\displaystyle F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^yf_{XY}(x',y')dx'dy'$

Conditional density The conditional density of $X$ with respect to $Y$, often noted $f_{X|Y}$, is defined as follows:

\[\boxed{f_{X|Y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)}}\]

Independence Two random variables $X$ and $Y$ are said to be independent if we have:

\[\boxed{f_{XY}(x,y)=f_X(x)f_Y(y)}\]

Covariance We define the covariance of two random variables $X$ and $Y$, that we note $\sigma_{XY}^2$ or more commonly $\textrm{Cov}(X,Y)$, as follows:

\[\boxed{\textrm{Cov}(X,Y)\triangleq\sigma_{XY}^2=E[(X-\mu_X)(Y-\mu_Y)]=E[XY]-\mu_X\mu_Y}\]

Correlation By noting $\sigma_X, \sigma_Y$ the standard deviations of $X$ and $Y$, we define the correlation between the random variables $X$ and $Y$, noted $\rho_{XY}$, as follows:

\[\boxed{\rho_{XY}=\frac{\sigma_{XY}^2}{\sigma_X\sigma_Y}}\]

Remark 1: we note that for any random variables $X, Y$, we have $\rho_{XY}\in[-1,1]$.

Remark 2: If X and Y are independent, then $\rho_{XY} = 0$.

Parameter estimation

Definitions

Random sample A random sample is a collection of $n$ random variables $X_1, ..., X_n$ that are independent and identically distributed with $X$.

Estimator An estimator is a function of the data that is used to infer the value of an unknown parameter in a statistical model.

Bias The bias of an estimator $\hat{\theta}$ is defined as being the difference between the expected value of the distribution of $\hat{\theta}$ and the true value, i.e.:

\[\boxed{\textrm{Bias}(\hat{\theta})=E[\hat{\theta}]-\theta}\]

Remark: an estimator is said to be unbiased when we have $E[\hat{\theta}]=\theta$.

Estimating the mean

Sample mean The sample mean of a random sample is used to estimate the true mean $\mu$ of a distribution, is often noted $\overline{X}$ and is defined as follows:

\[\boxed{\overline{X}=\frac{1}{n}\sum_{i=1}^nX_i}\]

Remark: the sample mean is unbiased, i.e $E[\overline{X}]=\mu$.

Central Limit Theorem Let us have a random sample $X_1, ..., X_n$ following a given distribution with mean $\mu$ and variance $\sigma^2$, then we have:

\[\boxed{\overline{X}\underset{n\rightarrow+\infty}{\sim}\mathcal{N}\left(\mu, \frac{\sigma}{\sqrt{n}}\right)}\]

Estimating the variance

Sample variance The sample variance of a random sample is used to estimate the true variance $\sigma^2$ of a distribution, is often noted $s^2$ or $\hat{\sigma}^2$ and is defined as follows:

\[\boxed{s^2=\hat{\sigma}^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2}\]

Remark: the sample variance is unbiased, i.e $E[s^2]=\sigma^2$.

Chi-Squared relation with sample variance Let $s^2$ be the sample variance of a random sample. We have:

\[\boxed{\frac{s^2(n-1)}{\sigma^2}\sim\chi_{n-1}^2}\]","Cumulative distribution function (CDF) The cumulative distribution function $F$, which is monotonically non-decreasing and is such that $\underset{x\rightarrow-\infty}{\textrm{lim}}F(x)=0$ and $\underset{x\rightarrow+\infty}{\textrm{lim}}F(x)=1$, is defined as:\[\boxed{F(x)=P(X\leqslant x)}\]Remark: we have $P(a < X\leqslant B)=F(b)-F(a)$.
Probability density function (PDF) The probability density function $f$ is the probability that $X$ takes on values between two adjacent realizations of the random variable.
It is determined as follows:\[\boxed{\sigma=\sqrt{\textrm{Var}(X)}}\]Transformation of random variables Let the variables $X$ and $Y$ be linked by some function.
Parameter estimationDefinitionsRandom sample A random sample is a collection of $n$ random variables $X_1, ..., X_n$ that are independent and identically distributed with $X$.
Chi-Squared relation with sample variance Let $s^2$ be the sample variance of a random sample.","['probability', 'x', 'variance', 'refresher', 'function', 'probabilities', 'c', 'statistics', 'y', 'distribution', 'displaystyle', 'random', 'sample']",en,Probabilities and Statistics refresher,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Probabilities and Statistics refresher</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/refresher-probabilities-statistics rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?b9ca12c0c1a8c9ab26cdba43eda7389e rel=stylesheet type=text/css><link href=css/article.min.css?7ecf0d5a8e06567a9e963d255c1e32e1 rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Probabilities and Statistics</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#introduction>Introduction</a></div> <div class=dropdown-container> <a href=#introduction><span>Sample space</span></a> <a href=#introduction><span>Event</span></a> <a href=#introduction><span>Permutation</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#conditional-probability>Conditional probability</a></div> <div class=dropdown-container> <a href=#conditional-probability><span>Bayes' rule</span></a> <a href=#conditional-probability><span>Independence</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#random-variables>Random Variables</a></div> <div class=dropdown-container> <a href=#random-variables><span>Definitions</span></a> <a href=#random-variables><span>Expectation</span></a> <a href=#random-variables><span>Variance</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#probability-distributions>Probability distributions</a></div> <div class=dropdown-container> <a href=#probability-distributions><span>Chebyshev's inequality</span></a> <a href=#probability-distributions><span>Main distributions</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#joint-rv>Jointly distributed random variables</a></div> <div class=dropdown-container> <a href=#joint-rv><span>Density</span></a> <a href=#joint-rv><span>Covariance</span></a> <a href=#joint-rv><span>Correlation</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#parameter-estimation>Parameter estimation</a></div> <div class=dropdown-container> <a href=#parameter-estimation><span>Mean</span></a> <a href=#parameter-estimation><span>Variance</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/refresher-probabilities-statistics'"" type=button><b>Probabilities</b></button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/refresher-algebra-calculus'"" type=button>Algebra</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Probabilities and Statistics refresher
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></i>
<h2><a aria-hidden=true class=anchor href=#introduction id=introduction></a>Introduction to Probability and Combinatorics</h2>
<p><span class=""new-item item-g"">Sample space</span> The set of all possible outcomes of an experiment is known as the sample space of the experiment and is denoted by $S$.</p>
<br>
<p><span class=""new-item item-g"">Event</span> Any subset $E$ of the sample space is known as an event. That is, an event is a set consisting of possible outcomes of the experiment. If the outcome of the experiment is contained in $E$, then we say that $E$ has occurred.</p>
<br>
<p><span class=""new-item item-g"">Axioms of probability</span> For each event $E$, we denote $P(E)$ as the probability of event $E$ occurring.</p>
<p><i>Axiom 1</i> ― Every probability is between 0 and 1 included, i.e:</p>
<div class=mobile-container>
\[\boxed{0\leqslant P(E)\leqslant 1}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 1"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-1.png?20e52e95618c88a4c10a5232c2c60ed0 style=width:100%;max-width:600px>
</center>
</div>
<p><i>Axiom 2</i> ― The probability that at least one of the elementary events in the entire sample space will occur is 1, i.e:</p>
<div class=mobile-container>
\[\boxed{P(S)=1}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 2"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-2.png?b1295ceda8ee7aa3202488a1ecb6133d style=width:100%;max-width:600px>
</center>
</div>
<p><i>Axiom 3</i> ― For any sequence of mutually exclusive events $E_1, ..., E_n$, we have:</p>
<div class=mobile-container>
\[\boxed{P\left(\bigcup_{i=1}^nE_i\right)=\sum_{i=1}^nP(E_i)}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Axiom 3"" class=img-responsive src=teaching/cme-106/illustrations/probability-axiom-3.png?3c16a178334bb1d048d6d19c49c9a78d style=width:100%;max-width:600px>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Permutation</span> A permutation is an arrangement of $r$ objects from a pool of $n$ objects, in a given order. The number of such arrangements is given by $P(n, r)$, defined as:</p>
<div class=mobile-container>
\[\boxed{P(n, r)=\frac{n!}{(n-r)!}}\]
</div>
<br>
<p><span class=""new-item item-b"">Combination</span> A combination is an arrangement of $r$ objects from a pool of $n$ objects, where the order does not matter. The number of such arrangements is given by $C(n, r)$, defined as:</p>
<div class=mobile-container>
\[\boxed{C(n, r)=\frac{P(n, r)}{r!}=\frac{n!}{r!(n-r)!}}\]
</div>
<p><span class=remark>Remark: we note that for $0\leqslant r\leqslant n$, we have $P(n,r)\geqslant C(n,r)$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#conditional-probability id=conditional-probability></a>Conditional Probability</h2>
<p><span class=""new-item item-r"">Bayes' rule</span> For events $A$ and $B$ such that $P(B)&gt;0$, we have:</p>
<div class=mobile-container>
\[\boxed{P(A|B)=\frac{P(B|A)P(A)}{P(B)}}\]
</div>
<div class=mobile-container>
<p><span class=remark>Remark: we have $P(A\cap B)=P(A)P(B|A)=P(A|B)P(B)$.</span></p>
</div>
<br>
<p><span class=""new-item item-g"">Partition</span> Let $\{A_i, i\in[\![1,n]\!]\}$ be such that for all $i$, $A_i\neq\varnothing$. We say that $\{A_i\}$ is a partition if we have:</p>
<div class=mobile-container>
\[\boxed{\forall i\neq j, A_i\cap A_j=\emptyset\quad\textrm{ and }\quad\bigcup_{i=1}^nA_i=S}\]
</div>
<div class=mobile-container>
<center>
<img alt=Partition class=img-responsive src=teaching/cme-106/illustrations/partition.png?1e98f377294dced2c2ebbb59ce1f6188 style=width:100%;max-width:600px>
</center>
</div>
<p><span class=remark>Remark: for any event $B$ in the sample space, we have $\displaystyle P(B)=\sum_{i=1}^nP(B|A_i)P(A_i)$.</span></p>
<br>
<p><span class=""new-item item-r"">Extended form of Bayes' rule</span> Let $\{A_i, i\in[\![1,n]\!]\}$ be a partition of the sample space. We have:</p>
<div class=mobile-container>
\[\boxed{P(A_k|B)=\frac{P(B|A_k)P(A_k)}{\displaystyle\sum_{i=1}^nP(B|A_i)P(A_i)}}\]
</div>
<br>
<p><span class=""new-item item-g"">Independence</span> Two events $A$ and $B$ are independent if and only if we have:</p>
<div class=mobile-container>
\[\boxed{P(A\cap B)=P(A)P(B)}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#random-variables id=random-variables></a>Random Variables</h2>
<h3>Definitions</h3>
<p><span class=""new-item item-g"">Random variable</span> A random variable, often noted $X$, is a function that maps every element in a sample space to a real line.</p>
<br>
<p><span class=""new-item item-g"">Cumulative distribution function (CDF)</span> The cumulative distribution function $F$, which is monotonically non-decreasing and is such that $\underset{x\rightarrow-\infty}{\textrm{lim}}F(x)=0$ and $\underset{x\rightarrow+\infty}{\textrm{lim}}F(x)=1$, is defined as:</p>
<div class=mobile-container>
\[\boxed{F(x)=P(X\leqslant x)}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Cumulative distribution function"" class=img-responsive src=teaching/cme-106/illustrations/cdf.png?f60eb6371235b9fe2d823aff3670ce20 style=width:100%;max-width:600px>
</center>
</div>
<p><span class=remark>Remark: we have $P(a &lt; X\leqslant B)=F(b)-F(a)$.</span></p>
<br>
<p><span class=""new-item item-g"">Probability density function (PDF)</span> The probability density function $f$ is the probability that $X$ takes on values between two adjacent realizations of the random variable.</p>
<br>
<p><span class=""new-item item-b"">Relationships involving the PDF and CDF</span> Here are the important properties to know
in the discrete (D) and the continuous (C) cases.</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Case</b></td>
<td align=center><b>CDF $F$</b></td>
<td align=center><b>PDF $f$</b></td>
<td align=center><b>Properties of PDF</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$\displaystyle F(x)=\sum_{x_i\leqslant x}P(X=x_i)$</td>
<td align=center>$f(x_j)=P(X=x_j)$</td>
<td align=center>$\displaystyle0\leqslant f(x_j)\leqslant1\textrm{ and }\sum_{j}f(x_j)=1$</td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$\displaystyle F(x)=\int_{-\infty}^xf(y)dy$</td>
<td align=center>$f(x)=\displaystyle \frac{dF}{dx}$</td>
<td align=center>$\displaystyle f(x)\geqslant0\textrm{ and }\int_{-\infty}^{+\infty}f(x)dx=1$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-b"">Expectation and Moments of the Distribution</span> Here are the expressions of the expected value $E[X]$, generalized expected value $E[g(X)]$, $k^{th}$ moment $E[X^k]$ and characteristic function $\psi(\omega)$ for the discrete and continuous cases:
</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Case</b></td>
<td align=center><b>$E[X]$</b></td>
<td align=center><b>$E[g(X)]$</b></td>
<td align=center><b>$E[X^k]$</b></td>
<td align=center><b>$\psi(\omega)$</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$\displaystyle \sum_{i=1}^nx_if(x_i)$</td>
<td align=center>$\displaystyle \sum_{i=1}^ng(x_i)f(x_i)$</td>
<td align=center>$\displaystyle \sum_{i=1}^nx_i^kf(x_i)$</td>
<td align=center>$\displaystyle\sum_{i=1}^nf(x_i)e^{i\omega x_i}$</td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}xf(x)dx$</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}g(x)f(x)dx$</td>
<td align=center>$\displaystyle \int_{-\infty}^{+\infty}x^kf(x)dx$</td>
<td align=center>$\displaystyle\int_{-\infty}^{+\infty}f(x)e^{i\omega x}dx$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Variance</span> The variance of a random variable, often noted Var$(X)$ or $\sigma^2$, is a measure of the spread of its distribution function. It is determined as follows:</p>
<div class=mobile-container>
\[\boxed{\textrm{Var}(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2}\]
</div>
<br>
<p><span class=""new-item item-g"">Standard deviation</span> The standard deviation of a random variable, often noted $\sigma$, is a measure of the spread of its distribution function which is compatible with the units of the actual random variable. It is determined as follows:</p>
<div class=mobile-container>
\[\boxed{\sigma=\sqrt{\textrm{Var}(X)}}\]
</div>
<div class=mobile-container>
<center>
<img alt=""Standard deviation"" class=img-responsive src=teaching/cme-106/illustrations/std.png?782af23c9eeaaefc688417f82dabfba0 style=width:100%;max-width:600px>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Transformation of random variables</span> Let the variables $X$ and $Y$ be linked by some function. By noting $f_X$ and $f_Y$ the distribution function of $X$ and $Y$ respectively, we have:</p>
<div class=mobile-container>
\[\boxed{f_Y(y)=f_X(x)\left|\frac{dx}{dy}\right|}\]
</div>
<br>
<p><span class=""new-item item-b"">Leibniz integral rule</span> Let $g$ be a function of $x$ and potentially $c$, and $a, b$ boundaries that may depend on $c$. We have:</p>
<div class=mobile-container>
\[\boxed{\frac{\partial}{\partial c}\left(\int_a^bg(x)dx\right)=\frac{\partial b}{\partial c}\cdot g(b)-\frac{\partial a}{\partial c}\cdot g(a)+\int_a^b\frac{\partial g}{\partial c}(x)dx}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#probability-distributions id=probability-distributions></a>Probability Distributions</h2>
<p><span class=""new-item item-r"">Chebyshev's inequality</span> Let $X$ be a random variable with expected value $\mu$. For $k, \sigma&gt;0$, we have the following inequality:</p>
<div class=mobile-container>
\[\boxed{P(|X-\mu|\geqslant k\sigma)\leqslant\frac{1}{k^2}}\]
</div>
<br>
<p><span class=""new-item item-r"">Main distributions</span> Here are the main distributions to have in mind:</p>
<div class=mobile-container>
<center>
<table style=""table-layout:fixed; width:100%;min-width:950px;"">
  <colgroup>
    <col style=width:60px>
    <col style=width:105px>
    <col style=width:125px>
    <col style=width:90px>
    <col style=width:65px>
    <col style=width:75px>
    <col style=width:250px>
  </colgroup>
<tbody>
<tr>
<td align=center><b>Type</b></td>
<td align=center><b>Distribution</b></td>
<td align=center><b>PDF</b></td>
<td align=center><b>$\psi(\omega)$</b></td>
<td align=center><b>$E[X]$</b></td>
<td align=center><b>$\textrm{Var}(X)$</b></td>
<td align=center><b>Illustration</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$X\sim\mathcal{B}(n, p)$</td>
<td align=center>$\displaystyle \displaystyle\binom{n}{x} p^xq^{n-x}$</td>
<td align=center>$(pe^{i\omega}+q)^n$</td>
<td align=center>$np$</td>
<td align=center>$npq$</td>
<td align=center><img alt=""Binomial distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-binomial.png?dc87a0e54e2ef1f46391b55ca40dc09e></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$X\sim\textrm{Po}(\mu)$</td>
<td align=center>$\displaystyle \frac{\mu^x}{x!}e^{-\mu}$</td>
<td align=center>$e^{\mu(e^{i\omega}-1)}$</td>
<td align=center>$\mu$</td>
<td align=center>$\mu$</td>
<td align=center><img alt=""Poisson distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-poisson.png?b2c5cd622b917c691814b475f5b6a2fa></td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$X\sim\mathcal{U}(a, b)$</td>
<td align=center>$\displaystyle \frac{1}{b-a}$</td>
<td align=center>$\displaystyle\frac{e^{i\omega b}-e^{i\omega a}}{(b-a)i\omega}$</td>
<td align=center>$\displaystyle\frac{a+b}{2}$</td>
<td align=center>$\displaystyle\frac{(b-a)^2}{12}$</td>
<td align=center><img alt=""Uniform distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-uniform.png?8e8595803628c45d3d4e678a29593788></td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$X\sim\mathcal{N}(\mu, \sigma)$</td>
<td align=center>$\displaystyle \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$</td>
<td align=center>$e^{i\omega\mu-\frac{1}{2}\omega^2\sigma^2}$</td>
<td align=center>$\mu$</td>
<td align=center>$\sigma^2$</td>
<td align=center><img alt=""Normal distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-normal.png?c8d3d312a2a493540e439cb156e1710a></td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$X\sim\textrm{Exp}(\lambda)$</td>
<td align=center>$\displaystyle \lambda e^{-\lambda x}$</td>
<td align=center>$\displaystyle\frac{1}{1-\frac{i\omega}{\lambda}}$</td>
<td align=center>$\displaystyle\frac{1}{\lambda}$</td>
<td align=center>$\displaystyle\frac{1}{\lambda^2}$</td>
<td align=center><img alt=""Exponential distribution"" class=img-responsive src=teaching/cme-106/illustrations/dist-exponential.png?09116ce799454b285ac487fb39f097c3></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#joint-rv id=joint-rv></a>Jointly Distributed Random Variables</h2>
<p><span class=""new-item item-g"">Marginal density and cumulative distribution</span> From the joint density probability function $f_{XY}$ , we have</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Case</b></td>
<td align=center><b>Marginal density</b></td>
<td align=center><b>Cumulative function</b></td>
</tr>
<tr>
<td align=center>(D)</td>
<td align=center>$\displaystyle f_X(x_i)=\sum_{j}f_{XY}(x_i,y_j)$</td>
<td align=center>$\displaystyle F_{XY}(x,y)=\sum_{x_i\leqslant x}\sum_{y_j\leqslant y}f_{XY}(x_i,y_j)$</td>
</tr>
<tr>
<td align=center>(C)</td>
<td align=center>$\displaystyle f_X(x)=\int_{-\infty}^{+\infty}f_{XY}(x,y)dy$</td>
<td align=center>$\displaystyle F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^yf_{XY}(x',y')dx'dy'$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-g"">Conditional density</span> The conditional density of $X$ with respect to $Y$, often noted $f_{X|Y}$, is defined as follows:</p>
<div class=mobile-container>
\[\boxed{f_{X|Y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)}}\]
</div>
<br>
<p><span class=""new-item item-g"">Independence</span> Two random variables $X$ and $Y$ are said to be independent if we have:</p>
<div class=mobile-container>
\[\boxed{f_{XY}(x,y)=f_X(x)f_Y(y)}\]
</div>
<br>
<p><span class=""new-item item-g"">Covariance</span> We define the covariance of two random variables $X$ and $Y$, that we note $\sigma_{XY}^2$ or more commonly $\textrm{Cov}(X,Y)$, as follows:</p>
<div class=mobile-container>
\[\boxed{\textrm{Cov}(X,Y)\triangleq\sigma_{XY}^2=E[(X-\mu_X)(Y-\mu_Y)]=E[XY]-\mu_X\mu_Y}\]
</div>
<br>
<p><span class=""new-item item-g"">Correlation</span> By noting $\sigma_X, \sigma_Y$ the standard deviations of $X$ and $Y$, we define the correlation between the random variables $X$ and $Y$, noted $\rho_{XY}$, as follows:</p>
<div class=mobile-container>
\[\boxed{\rho_{XY}=\frac{\sigma_{XY}^2}{\sigma_X\sigma_Y}}\]
</div>
<p><span class=remark>Remark 1: we note that for any random variables $X, Y$, we have $\rho_{XY}\in[-1,1]$.</span></p>
<p><span class=remark>Remark 2: If X and Y are independent, then $\rho_{XY} = 0$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#parameter-estimation id=parameter-estimation></a>Parameter estimation</h2>
<h3>Definitions</h3>
<p><span class=""new-item item-g"">Random sample</span> A random sample is a collection of $n$ random variables $X_1, ..., X_n$ that are independent and identically distributed with $X$.</p>
<br>
<p><span class=""new-item item-g"">Estimator</span> An estimator is a function of the data that is used to infer the value of an unknown parameter in a statistical model.</p>
<br>
<p><span class=""new-item item-g"">Bias</span> The bias of an estimator $\hat{\theta}$ is defined as being the difference between the expected value of the distribution of $\hat{\theta}$ and the true value, i.e.:</p>
<div class=mobile-container>
\[\boxed{\textrm{Bias}(\hat{\theta})=E[\hat{\theta}]-\theta}\]
</div>
<p><span class=remark>Remark: an estimator is said to be unbiased when we have $E[\hat{\theta}]=\theta$.</span></p>
<br>
<h3>Estimating the mean</h3>
<p><span class=""new-item item-b"">Sample mean</span> The sample mean of a random sample is used to estimate the true mean $\mu$ of a distribution, is often noted $\overline{X}$ and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{\overline{X}=\frac{1}{n}\sum_{i=1}^nX_i}\]
</div>
<p><span class=remark>Remark: the sample mean is unbiased, i.e $E[\overline{X}]=\mu$.</span></p>
<br>
<p><span class=""new-item item-r"">Central Limit Theorem</span> Let us have a random sample $X_1, ..., X_n$ following a given distribution with mean $\mu$ and variance $\sigma^2$, then we have:</p>
<div class=mobile-container>
\[\boxed{\overline{X}\underset{n\rightarrow+\infty}{\sim}\mathcal{N}\left(\mu, \frac{\sigma}{\sqrt{n}}\right)}\]
</div>
<br>
<h3>Estimating the variance</h3>
<p><span class=""new-item item-b"">Sample variance</span> The sample variance of a random sample is used to estimate the true variance $\sigma^2$ of a distribution, is often noted $s^2$ or $\hat{\sigma}^2$ and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{s^2=\hat{\sigma}^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2}\]
</div>
<p><span class=remark>Remark: the sample variance is unbiased, i.e $E[s^2]=\sigma^2$.</span></p>
<br>
<p><span class=""new-item item-r"">Chi-Squared relation with sample variance</span> Let $s^2$ be the sample variance of a random sample. We have:</p>
<div class=mobile-container>
\[\boxed{\frac{s^2(n-1)}{\sigma^2}\sim\chi_{n-1}^2}\]
</div>
<br>
<div class=""alert alert-warning"" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link href=teaching/cme-106 onclick=trackOutboundLink(this);>Probabilities and Statistics cheatsheets</a>!</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
18,"ملخص الجبر الخطي و التفاضل و التكامل

النص الأصلي بواسطة افشین عمیدی و شروین عمیدی تمت الترجمة بواسطة زيد اليافعي. تمت المراجعة بواسطة أمجد الخطابي و مازن مليباري.

الرموز العامة

التعريفات

متجه (vector) نرمز ل $x\in\mathbb{R}^n$ متجه يحتوي على $n$ مدخلات، حيث $x_i\in\mathbb{R}$ يعتبر المدخل رقم $i$ .

\[x=\left(\begin{array}{c}x_1\\x_2\\\vdots\\x_n\end{array}\right)\in\mathbb{R}^n\]

مصفوفة (matrix) نرمز ل $A\in\mathbb{R}^{m\times n}$ مصفوفة تحتوي على $m$ صفوف و $n$ أعمدة، حيث $A_{i,j}\in\mathbb{R}$ يرمز للمدخل في الصف$ i$ و العمود $j$

\[A=\left(\begin{array}{ccc}A_{1,1}& \cdots&A_{1,n}\\\vdots&& \vdots\\A_{m,1}& \cdots&A_{m,n}\end{array}\right)\in\mathbb{R}^{m\times n}\]

ملاحظة : المتجه $x$ المعرف مسبقا يمكن اعتباره مصفوفة من الشكل $n \times 1$ والذي يسمى ب مصفوفة من عمود واحد.

المصفوفات الأساسية

مصفوفة الوحدة (identity) مصفوفة الوحدة $I\in\mathbb{R}^{n\times n}$ تعتبر مصفوفة مربعة تحتوي على المدخل 1 في قطر المصفوفة و 0 في بقية المدخلات:

\[I=\left(\begin{array}{cccc}1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&1\end{array}\right)\]

ملاحظة : جميع المصفوفات من الشكل $A\in\mathbb{R}^{n\times n}$ فإن $A\times I=I\times A=A$.

مصفوفة قطرية (diagonal) المصفوفة القطرية هي مصفوفة من الشكل

\[D=\left(\begin{array}{cccc}d_1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&d_n\end{array}\right)\]

ملاحظة: نرمز كذلك ل $D$ ب $\textrm{diag}(d_1,...,d_n)$.

عمليات المصفوفات

الضرب

ضرب المتجهات توجد طريقتين لضرب متجه بمتجه :

- ضرب داخلي (inner product): ل $x,y\in\mathbb{R}^n$ نستنتج :

\[\boxed{x^Ty=\sum_{i=1}^nx_iy_i\in\mathbb{R}}\]

- ضرب خارجي (outer product): ل $x\in\mathbb{R}^m, y\in\mathbb{R}^n$ نستنتج :

\[\boxed{xy^T=\left(\begin{array}{ccc}x_1y_1& \cdots&x_1y_n\\\vdots&& \vdots\\x_my_1& \cdots&x_my_n\end{array}\right)\in\mathbb{R}^{m\times n}}\]

مصفوفة متجه : ضرب المصفوفة $A\in\mathbb{R}^{m\times n}$ والمتجه $x \in \mathbb{R}^n$ ينتجه متجه من الشكل $\mathbb{R}^{m}$ حيث :

\[\boxed{Ax=\left(\begin{array}{c}a_{r,1}^Tx\\\vdots\\a_{r,m}^Tx\end{array}\right)=\sum_{i=1}^na_{c,i}x_{i}\in\mathbb{R}^{m}}\]

حيث $a^{T}_{r,i}$ يعتبر متجه الصفوف و $a_{c,j}$ يعتبر متجه الأعمدة ل $A$ كذلك $x_i$ يرمز لعناصر $x$.

ضرب مصفوفة ومصفوفة ضرب المصفوفة $A\in\mathbb{R}^{m\times n}$ و $A \in \mathbb{R}^{n \times p}$ ينتجه عنه المصفوفة $\mathbb{R}^{m\times p}$ حيث أن :

\[\boxed{AB=\left(\begin{array}{ccc}a_{r,1}^Tb_{c,1}& \cdots&a_{r,1}^Tb_{c,p}\\\vdots&& \vdots\\a_{r,m}^Tb_{c,1}& \cdots&a_{r,m}^Tb_{c,p}\end{array}\right)=\sum_{i=1}^na_{c,i}b_{r,i}^T\in\mathbb{R}^{n\times p}}\]

حيث $a^T_{r, i}$ و $b^T_{r, i}$ يعتبر متجه الصفوف $a_{c, j}$ و $b_{c, j}$ متجه الأعمدة ل $A$ و $B$ على التوالي.

عمليات أخرى

المنقول (transpose) منقول المصفوفة$A\in\mathbb{R}^{m\times n}$ يرمز له ب $A^T$ حيث الصفوف يتم تبديلها مع الأعمدة :

\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]

ملاحظة: لأي مصفوفتين $A$ و $B$، نستنتج $(AB)^T = B^T A^T$.

المعكوس (inverse) معكوس أي مصفوفة $A$ قابلة للعكس (invertible) يرمز له ب $A^{-1}$ ويعتبر المعكوس المصفوفة الوحيدة التي لديها الخاصية التالية :

\[\boxed{AA^{-1}=A^{-1}A=I}\]

ملاحظة: ليس جميع المصفوفات يمكن إيجاد معكوس لها. كذلك لأي مصفوفتين $A$ و $B$ نستنتج $(AB)^{-1}=B^{-1}A^{-1}$.

أثر المصفوفة (trace) أثر أي مصفوفة مربعة $A$ يرمز له ب $\textrm{tr}(A)$ يعتبر مجموع العناصر التي في القطر:

\[\boxed{\textrm{tr}(A)=\sum_{i=1}^nA_{i,i}}\]

ملاحظة : لأي مصفوفتين $A$ و $B$ لدينا $\textrm{tr}(A^T)=\textrm{tr}(A)$ و $\textrm{tr}(AB)=\textrm{tr}(BA)$.

المحدد (determinant) المحدد لأي مصفوفة مربعة من الشكل $A\in\mathbb{R}^{n\times n}$ يرمز له ب $|A|$ او $\textrm{det}(A)$يتم تعريفه بإستخدام $A_{\backslash i, \backslash j}$ والذي يعتبر المصفوفة $A$ مع حذف الصف $i$ والعمود $j$ كالتالي :

\[\boxed{\textrm{det}(A)=|A|=\sum_{j=1}^n(-1)^{i+j}A_{i,j}|A_{\backslash i,\backslash j}|}\]

ملاحظة: $A$ يكون لديه معكوذ إذا وفقط إذا $|A|

eq0$. كذلك $|A B| = |A| |B|$ و $|A^T| = |A|$.

خواص المصفوفات

التعريفات

التفكيك المتماثل (symmetric decomposition) المصفوفة $A$ يمكن التعبير عنها بإستخدام جزئين مثماثل (symmetric) وغير متماثل(antisymmetric) كالتالي :

\[\boxed{A=\underbrace{\frac{A+A^T}{2}}_{\textrm{Symmetric}}+\underbrace{\frac{A-A^T}{2}}_{\textrm{Antisymmetric}}}\]

المعيار (norm) المعيار يعتبر دالة $N:V\longrightarrow[0,+\infty[$ حيث $V$ يعتبر فضاء متجه (vector space)، حيث أن لكل $x,y \in V$ لدينا :

- $N(x+y)\leqslant N(x)+N(y)$

- لأي عدد $a$ فإن $N(ax) = |a| N(x)$

- $N(x) =0 \implies x = 0$

لأي $x \in V$ المعايير الأكثر إستخداماً ملخصة في الجدول التالي:

المعيار الرمز التعريف مثال للإستخدام Manhattan ,$L^1$ $||x||_1$ $\displaystyle\sum_{i=1}^n|x_i|$ LASSO regularization Euclidean ,$L^2$ $||x||_2$ $\displaystyle\sqrt{\sum_{i=1}^nx_i^2}$ Ridge regularization norm-$p$ ,$L^p$ $||x||_p$ $\displaystyle\left(\sum_{i=1}^nx_i^p\right)^{\frac{1}{p}}$ Hölder inequality Infinity ,$L^{\infty}$ $||x||_{\infty}$ $\underset{i}{\textrm{max }}|x_i|$ Uniform convergence

الارتباط الخطي (linear dependence) مجموعة المتجهات تعتبر تابعة خطياً إذا وفقط إذا كل متجه يمكن كتابته بشكل خطي بإسخدام مجموعة من المتجهات الأخرى.

ملاحظة: إذا لم يتحقق هذا الشرط فإنها تسمى مستقلة خطياً .

رتبة المصفوفة (rank) رتبة المصفوفة $A$ يرمز له ب $\textrm{rank}(A)$ وهو يصف حجم الفضاء المتجهي الذي نتج من أعمدة المصفوفة. يمكن وصفه كذلك بأقصى عدد من أعمدة المصفوفة $A$ التي تمتلك خاصية أنها مستقلة خطياً.

مصفوفة شبه معرفة موجبة (positive semi-definite) المصفوفة $A \in \mathbb{R}^{n \times n}$ تعتبر مصفوفة شبه معرفة موجبة (PSD) ويرمز لها بالرمز $A\succeq 0$ إذا :

\[\boxed{A=A^T}\quad\textrm{ and }\quad\boxed{\forall x\in\mathbb{R}^n,\quad x^TAx\geqslant0}\]

ملاحظة: المصفوفة $A$ تعتبر مصفوفة معرفة موجبة إذا $A \succ 0 $ وهي تعتبر مصفوفة (PSD) والتي تستوفي الشرط : لكل متجه غير الصفر $x$ حيث $x^TAx>0 $.

القيم الذايتة (eigenvalue), المتجه الذاتي (eigenvector) إذا كان لدينا مصفوفة $A \in \mathbb{R}^{n \times n}$، القيمة $\lambda$ تعتبر قيمة ذاتية للمصفوفة $A$ إذا وجد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجه ذاتي حيث أن :

\[\boxed{Az=\lambda z}\]

النظرية الطيفية (spectral theorem) نفرض $A \in \mathbb{R}^{n \times n}$ إذا كانت المصفوفة $A$ متماثلة فإن $A$ تعتبر مصفوفة قطرية بإستخدام مصفوفة متعامدة (orthogonal) $U \in \mathbb{R} ^{n \times n}$ ويرمز لها بالرمز $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ حيث أن:

\[\boxed{\exists\Lambda\textrm{ قطرية},\quad A=U\Lambda U^T}\]

مجزئ القيمة المفرده (singular value decomposition) لأي مصفوفة $A$ من الشكل $n\times m$ ، تفكيك القيمة المنفردة (SVD) يعتبر طريقة تحليل تضمن وجود $U \in \mathbb{R}^{m \times m}$ ،مصفوفة قطرية $\Sigma \in \mathbb{R}^{m \times n}$ و $V \in \mathbb{R}^{n \times n}$ حيث أن :

\[\boxed{A=U\Sigma V^T}\]

حساب المصفوفات

المشتقة في فضاءات عالية (gradient) افترض $f:\mathbb{R}^{m\times n}\rightarrow\mathbb{R}$ تعتبر دالة و $f: \mathbb{R}^{m \times n} \rightarrow \mathbb{R}$ تعتبر مصفوفة. المشتقة العليا ل $f$ بالنسبة ل $A$ يعتبر مصفوفة $n\times m$ يرمز له $

abla_A f(A)$ حيث أن:

\[\boxed{\Big(

abla_A f(A)\Big)_{i,j}=\frac{\partial f(A)}{\partial A_{i,j}}}\]

ملاحظة : المشتقة العليا معرفة فقط إذا كانت الدالة $f$ لديها مدى ضمن الأعداد الحقيقية.

هيشيان (Hessian) افترض $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ تعتبر دالة و $x \in \mathbb{R}^n$ يعتبر متجه. الهيشيان ل $f$ بالنسبة ل $x$ تعتبر مصفوفة متماثلة من الشكل $n \times n$ يرمز لها بالرمز $

abla_x^2 f(x)$ حيثب أن :

\[\boxed{\Big(

abla_x^2 f(x)\Big)_{i,j}=\frac{\partial^2 f(x)}{\partial x_i\partial x_j}}\]

ملاحظة : الهيشيان معرفة فقط إذا كانت الدالة $f$ لديها مدى ضمن الأعداد الحقيقية.

الحساب في مشتقة الفضاءات العالية لأي مصفوفات $A,B,C$ فإن الخواص التالية مهمة :

\[\boxed{

abla_A\textrm{tr}(AB)=B^T}\quad\quad\boxed{

abla_{A^T}f(A)=\left(

abla_Af(A)\right)^T}\] \[\boxed{

abla_A\textrm{tr}(ABA^TC)=CAB+C^TAB^T}\quad\quad\boxed{

abla_A|A|=|A|(A^{-1})^T}\]","ملخص الجبر الخطي و التفاضل و التكاملالنص الأصلي بواسطة افشین عمیدی و شروین عمیدی تمت الترجمة بواسطة زيد اليافعي.
الرموز العامةالتعريفاتمتجه (vector) نرمز ل $x\in\mathbb{R}^n$ متجه يحتوي على $n$ مدخلات، حيث $x_i\in\mathbb{R}$ يعتبر المدخل رقم $i$ .
عمليات أخرىالمنقول (transpose) منقول المصفوفة$A\in\mathbb{R}^{m\times n}$ يرمز له ب $A^T$ حيث الصفوف يتم تبديلها مع الأعمدة :\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]ملاحظة: لأي مصفوفتين $A$ و $B$، نستنتج $(AB)^T = B^T A^T$.
رتبة المصفوفة (rank) رتبة المصفوفة $A$ يرمز له ب $\textrm{rank}(A)$ وهو يصف حجم الفضاء المتجهي الذي نتج من أعمدة المصفوفة.
هيشيان (Hessian) افترض $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ تعتبر دالة و $x \in \mathbb{R}^n$ يعتبر متجه.","['ل', 'يرمز', 'متجه', 'الخطي', 'إذا', 'مصفوفة', 'الجبر', 'المصفوفة', 'n', 'والتفاضل', 'تعتبر', 'يعتبر', 'times']",ar,الجبر الخطي والتفاضل,"<!DOCTYPE html><html lang=ar><head><base href=../../../../ ><title>الجبر الخطي والتفاضل - CS ۲۲۹</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science, deep learning"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/l/ar/teaching/cs-229/refresher-algebra-calculus rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link href=css/style.min.css?3587b1299365680430aa5634d6b49ffb rel=stylesheet type=text/css><link href=css/article.min.css?6b276411853b0aa728d3d16d218cc10d rel=stylesheet><link href=css/font-ar.min.css?611012c494fe37b0d02229cd2a7a963c media=screen rel=stylesheet type=text/css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script type=text/x-mathjax-config>MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async src=""https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"" type=text/javascript></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href=l/ar onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>شروین عمیدی</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href=l/ar onclick=trackOutboundLink(this);>معلومات</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>مشاريع</a></li> <li class=active><a href=l/ar/teaching onclick=trackOutboundLink(this);>تدريس</a></li> <li><a href=blog onclick=trackOutboundLink(this);>مدونة</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>معلومات</a></li> <p class=navbar-text><font color=#dddddd>افشین عمیدی</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>الجبر الخطي والتفاضل</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#notations>الرموز العامة</a></div> <div class=dropdown-container> <a href=#notations><span>التعريفات </span></a> <a href=#notations><span>المصفوفات الأساسية</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#operations>عمليات المصفوفات</a></div> <div class=dropdown-container> <a href=#operations><span>الضرب</span></a> <a href=#operations><span>عمليات أخرى</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#properties>خواص المصفوفات</a></div> <div class=dropdown-container> <a href=#properties><span>المعيار</span></a> <a href=#properties><span>قيمة ذاتية/متجه ذاتي</span></a> <a href=#properties><span>تفكيك القيمة المنفردة</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#calculus>حساب المصفوفات</a></div> <div class=dropdown-container> <a href=#calculus><span>مشتقة الفضاءات العالية</span></a> <a href=#calculus><span>الهيشيان</span></a> <a href=#calculus><span>العمليات</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/ar/refresher-algebra-calculus.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <span class=ltr>GitHub</span> بي دي إف على <i aria-hidden=false class=""fa fa-github fa-fw""></i> </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=title-lang>
<a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=l/ar/teaching/cs-229 onclick=trackOutboundLink(this);>تعلم آلي - <span class=ltr>CS</span> ۲۲۹</a>

<div style=float:right;>
  <div class=input-group>
    <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
      <option selected value=ar>العربية</option>
      <option value=en>English</option>
      <option value=es>Español</option>
      <option value=fa>فارسی</option>
      <option value=fr>Français</option>
      <option value=ko>한국어</option>
      <option value=pt>Português</option>
      <option value=tr>Türkçe</option>
      <option value=vi>Tiếng Việt</option>
      <option value=zh>简中</option>
      <option value=zh-tw>繁中</option>
    </select>
    <div class=input-group-addon><i class=fa></i></div>
  </div>
</div>
</div>
<br>
<div dir=rtl>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
<div class=btn-group role=group>
<button class=""btn btn-default"" onclick=""location.href='l/ar/teaching/cs-229/refresher-probabilities-statistics'"" type=button>الاحتمالات والإحصائيات</button>
</div>
<div class=btn-group role=group>
<button class=""btn btn-default active"" onclick=""location.href='l/ar/teaching/cs-229/refresher-algebra-calculus'"" type=button><b>الجبر الخطي والتفاضل</b></button>
</div>
</div>
</div>
<h1>
<a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a><div dir=rtl>ملخص الجبر الخطي و التفاضل و التكامل</div>
</h1>
<div dir=ltr style=float:left><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
<div dir=rtl>
<p>النص الأصلي بواسطة <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>افشین عمیدی</a> و <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);> شروین عمیدی </a>
<br>
<font size=2>تمت الترجمة بواسطة زيد اليافعي. تمت المراجعة بواسطة أمجد الخطابي و مازن مليباري.</font></p>
</div>
<div dir=rtl>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>الرموز العامة</h2>
<h3>التعريفات  </h3>
<p><span class=""new-item item-b"">متجه <span class=""ltr stick-together"">(vector)</span></span> نرمز ل $x\in\mathbb{R}^n$ متجه يحتوي على $n$ مدخلات، حيث $x_i\in\mathbb{R}$  يعتبر المدخل رقم $i$ .</p>
<div class=mobile-container>
\[x=\left(\begin{array}{c}x_1\\x_2\\\vdots\\x_n\end{array}\right)\in\mathbb{R}^n\]
</div>
<br>
<p><span class=""new-item item-b"">مصفوفة <span class=""ltr stick-together"">(matrix)</span></span> نرمز ل $A\in\mathbb{R}^{m\times n}$ مصفوفة تحتوي على $m$ صفوف و $n$ أعمدة، حيث $A_{i,j}\in\mathbb{R}$  يرمز للمدخل في الصف$ i$ و العمود $j$  </p>
<div class=mobile-container>
\[A=\left(\begin{array}{ccc}A_{1,1}&amp; \cdots&amp;A_{1,n}\\\vdots&amp;&amp; \vdots\\A_{m,1}&amp; \cdots&amp;A_{m,n}\end{array}\right)\in\mathbb{R}^{m\times n}\]
</div>
<p><span class=remark>ملاحظة : المتجه $x$ المعرف مسبقا يمكن اعتباره مصفوفة من الشكل $n \times 1$ والذي يسمى ب مصفوفة من عمود واحد.</span></p>
<br>
<h3>المصفوفات الأساسية</h3>
<p><span class=""new-item item-b"">مصفوفة الوحدة <span class=""ltr stick-together"">(identity)</span></span> مصفوفة الوحدة $I\in\mathbb{R}^{n\times n}$ تعتبر مصفوفة مربعة تحتوي على المدخل 1 في قطر المصفوفة و 0 في بقية المدخلات:</p>
<div class=mobile-container>
\[I=\left(\begin{array}{cccc}1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;1\end{array}\right)\]
</div>
<p><span class=remark>ملاحظة : جميع المصفوفات من الشكل $A\in\mathbb{R}^{n\times n}$  فإن $A\times I=I\times A=A$.</span></p>
<br>
<p><span class=""new-item item-b"">مصفوفة قطرية <span class=""ltr stick-together"">(diagonal)</span></span> المصفوفة القطرية هي مصفوفة من الشكل</p>
<div class=mobile-container>
\[D=\left(\begin{array}{cccc}d_1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;d_n\end{array}\right)\]
</div>
<p><span class=remark>ملاحظة: نرمز كذلك ل $D$ ب $\textrm{diag}(d_1,...,d_n)$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#operations id=operations></a>عمليات المصفوفات</h2>
<h3>الضرب</h3>
<p><span class=""new-item item-r"">ضرب المتجهات</span> توجد طريقتين لضرب متجه بمتجه :</p>
<p>- ضرب داخلي <span class=""ltr stick-together"">(inner product)</span>: ل $x,y\in\mathbb{R}^n$ نستنتج :</p>
<div class=mobile-container>
\[\boxed{x^Ty=\sum_{i=1}^nx_iy_i\in\mathbb{R}}\]
</div>
<br><p>- ضرب خارجي <span class=""ltr stick-together"">(outer product)</span>:  ل $x\in\mathbb{R}^m, y\in\mathbb{R}^n$ نستنتج :</p>
<div class=mobile-container>
\[\boxed{xy^T=\left(\begin{array}{ccc}x_1y_1&amp; \cdots&amp;x_1y_n\\\vdots&amp;&amp; \vdots\\x_my_1&amp; \cdots&amp;x_my_n\end{array}\right)\in\mathbb{R}^{m\times n}}\]
</div>
<br>
<p><span class=""new-item item-r"">مصفوفة</span> متجه : ضرب المصفوفة $A\in\mathbb{R}^{m\times n}$ والمتجه $x \in \mathbb{R}^n$ ينتجه متجه من الشكل $\mathbb{R}^{m}$ حيث :</p>
<div class=mobile-container>
\[\boxed{Ax=\left(\begin{array}{c}a_{r,1}^Tx\\\vdots\\a_{r,m}^Tx\end{array}\right)=\sum_{i=1}^na_{c,i}x_{i}\in\mathbb{R}^{m}}\]
</div>
<p>حيث $a^{T}_{r,i}$ يعتبر متجه الصفوف و $a_{c,j}$ يعتبر متجه الأعمدة ل $A$ كذلك $x_i$ يرمز لعناصر $x$.</p>
<br>
<p><span class=""new-item item-r"">ضرب مصفوفة ومصفوفة</span> ضرب المصفوفة $A\in\mathbb{R}^{m\times n}$ و $A \in \mathbb{R}^{n \times p}$ ينتجه عنه المصفوفة $\mathbb{R}^{m\times p}$ حيث أن :</p>
<div class=mobile-container>
\[\boxed{AB=\left(\begin{array}{ccc}a_{r,1}^Tb_{c,1}&amp; \cdots&amp;a_{r,1}^Tb_{c,p}\\\vdots&amp;&amp; \vdots\\a_{r,m}^Tb_{c,1}&amp; \cdots&amp;a_{r,m}^Tb_{c,p}\end{array}\right)=\sum_{i=1}^na_{c,i}b_{r,i}^T\in\mathbb{R}^{n\times p}}\]
</div>
<p>حيث $a^T_{r, i}$ و $b^T_{r, i}$ يعتبر متجه الصفوف $a_{c, j}$ و $b_{c, j}$ متجه الأعمدة ل $A$ و $B$ على التوالي.</p>
<br>
<h3>عمليات أخرى</h3>
<p><span class=""new-item item-g"">المنقول <span class=""ltr stick-together"">(transpose)</span></span> منقول المصفوفة$A\in\mathbb{R}^{m\times n}$ يرمز له ب $A^T$ حيث الصفوف يتم تبديلها مع الأعمدة :</p>
<div class=mobile-container>
\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]
</div><br>
<p><span class=remark>ملاحظة: لأي مصفوفتين $A$ و $B$، نستنتج $(AB)^T = B^T A^T$.</span></p>
<br>
<p><span class=""new-item item-g"">المعكوس <span class=""ltr stick-together"">(inverse)</span></span> معكوس أي مصفوفة $A$ قابلة للعكس <span class=""ltr stick-together"">(invertible)</span> يرمز له ب $A^{-1}$ ويعتبر المعكوس المصفوفة الوحيدة التي لديها الخاصية التالية :</p>
<div class=mobile-container>
\[\boxed{AA^{-1}=A^{-1}A=I}\]
</div>
<p><span class=remark>ملاحظة: ليس جميع المصفوفات يمكن إيجاد معكوس لها. كذلك لأي مصفوفتين $A$ و $B$ نستنتج $(AB)^{-1}=B^{-1}A^{-1}$.</span></p>
<br>
<p><span class=""new-item item-g"">أثر المصفوفة <span class=""ltr stick-together"">(trace)</span></span> أثر أي مصفوفة مربعة $A$ يرمز له ب $\textrm{tr}(A)$ يعتبر مجموع العناصر التي في القطر:</p>
<div class=mobile-container>
\[\boxed{\textrm{tr}(A)=\sum_{i=1}^nA_{i,i}}\]
</div>
<p><span class=remark>ملاحظة : لأي مصفوفتين $A$ و $B$ لدينا $\textrm{tr}(A^T)=\textrm{tr}(A)$ و $\textrm{tr}(AB)=\textrm{tr}(BA)$.</span></p>
<br>
<p><span class=""new-item item-g"">المحدد <span class=""ltr stick-together"">(determinant)</span></span> المحدد لأي مصفوفة مربعة من الشكل $A\in\mathbb{R}^{n\times n}$ يرمز له ب $|A|$ او $\textrm{det}(A)$يتم تعريفه بإستخدام $A_{\backslash i, \backslash j}$ والذي يعتبر المصفوفة $A$ مع حذف الصف $i$ والعمود $j$ كالتالي :</p>
<div class=mobile-container>
\[\boxed{\textrm{det}(A)=|A|=\sum_{j=1}^n(-1)^{i+j}A_{i,j}|A_{\backslash i,\backslash j}|}\]
</div>
<p><span class=remark>ملاحظة: $A$ يكون لديه معكوذ إذا وفقط إذا $|A|\neq0$. كذلك $|A B| = |A| |B|$ و $|A^T| = |A|$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#properties id=properties></a>خواص المصفوفات</h2>
<h3>التعريفات</h3>
<p><span class=""new-item item-r"">التفكيك المتماثل <span class=""ltr stick-together"">(symmetric decomposition)</span></span> المصفوفة $A$ يمكن التعبير عنها بإستخدام جزئين مثماثل <span class=""ltr stick-together"">(symmetric)</span> وغير متماثل<span class=""ltr stick-together"">(antisymmetric)</span> كالتالي :</p>
<div class=mobile-container>
\[\boxed{A=\underbrace{\frac{A+A^T}{2}}_{\textrm{Symmetric}}+\underbrace{\frac{A-A^T}{2}}_{\textrm{Antisymmetric}}}\]
</div>
<br>
<p><span class=""new-item item-b"">المعيار <span class=""ltr stick-together"">(norm)</span></span> المعيار يعتبر دالة $N:V\longrightarrow[0,+\infty[$ حيث $V$ يعتبر فضاء متجه <span class=""ltr stick-together"">(vector space)</span>، حيث أن لكل $x,y \in V$ لدينا :</p>
<p>- $N(x+y)\leqslant N(x)+N(y)$
<br>- لأي عدد $a$ فإن $N(ax) = |a| N(x)$
<br>- $N(x) =0 \implies x = 0$</p>
<p>لأي $x \in V$ المعايير الأكثر إستخداماً ملخصة في الجدول التالي:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>المعيار</b></td>
<td align=center><b>الرمز</b></td>
<td align=center><b>التعريف</b></td>
<td align=center><b>مثال للإستخدام</b></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">Manhattan ,$L^1$</span></td>
<td align=center>$||x||_1$</td>
<td align=center>$\displaystyle\sum_{i=1}^n|x_i|$</td>
<td align=center><span class=""ltr stick-together"">LASSO regularization</span></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">Euclidean ,$L^2$</span></td>
<td align=center>$||x||_2$</td>
<td align=center>$\displaystyle\sqrt{\sum_{i=1}^nx_i^2}$</td>
<td align=center><span class=""ltr stick-together"">Ridge regularization</span></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">norm-$p$ ,$L^p$</span></td>
<td align=center>$||x||_p$</td>
<td align=center>$\displaystyle\left(\sum_{i=1}^nx_i^p\right)^{\frac{1}{p}}$</td>
<td align=center><span class=""ltr stick-together"">Hölder inequality</span></td>
</tr>
<tr>
<td align=center><span class=""ltr stick-together"">Infinity ,$L^{\infty}$</span></td>
<td align=center>$||x||_{\infty}$</td>
<td align=center>$\underset{i}{\textrm{max }}|x_i|$</td>
<td align=center><span class=""ltr stick-together"">Uniform convergence</span></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r""> الارتباط الخطي <span class=""ltr stick-together"">(linear dependence)</span></span> مجموعة المتجهات تعتبر تابعة خطياً إذا وفقط إذا كل متجه يمكن كتابته بشكل خطي بإسخدام مجموعة من المتجهات الأخرى.</p>
<p><span class=remark>ملاحظة: إذا لم يتحقق هذا الشرط فإنها تسمى مستقلة خطياً .</span></p>
<br>
<p><span class=""new-item item-b"">رتبة المصفوفة <span class=""ltr stick-together"">(rank)</span></span> رتبة المصفوفة $A$ يرمز له ب $\textrm{rank}(A)$ وهو يصف حجم الفضاء المتجهي الذي نتج من أعمدة المصفوفة. يمكن وصفه كذلك بأقصى عدد من أعمدة المصفوفة $A$ التي تمتلك خاصية أنها مستقلة خطياً.</p>
<br>
<p><span class=""new-item item-r"">مصفوفة شبه معرفة موجبة <span class=""ltr stick-together"">(positive semi-definite)</span></span> المصفوفة  $A \in \mathbb{R}^{n \times n}$ تعتبر مصفوفة شبه معرفة موجبة <span class=""ltr stick-together"">(PSD)</span> ويرمز لها بالرمز  $A\succeq 0$ إذا :</p>
<div class=mobile-container>
\[\boxed{A=A^T}\quad\textrm{ and }\quad\boxed{\forall x\in\mathbb{R}^n,\quad x^TAx\geqslant0}\]
</div>
<p><span class=remark>ملاحظة: المصفوفة $A$ تعتبر مصفوفة معرفة موجبة إذا $A \succ 0  $  وهي تعتبر مصفوفة (PSD) والتي تستوفي الشرط : لكل متجه غير الصفر $x$ حيث $x^TAx&gt;0 $.</span></p>
<br>
<p><span class=""new-item item-b"">القيم الذايتة <span class=""ltr stick-together"">(eigenvalue)</span>, المتجه الذاتي <span class=""ltr stick-together"">(eigenvector)</span></span> إذا كان لدينا مصفوفة $A \in \mathbb{R}^{n \times n}$، القيمة $\lambda$  تعتبر قيمة ذاتية للمصفوفة $A$ إذا وجد متجه $z\in\mathbb{R}^n\backslash\{0\}$ يسمى متجه ذاتي حيث أن :</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">النظرية الطيفية <span class=""ltr stick-together"">(spectral theorem)</span></span> نفرض $A \in \mathbb{R}^{n \times n}$ إذا كانت المصفوفة $A$ متماثلة فإن $A$ تعتبر مصفوفة قطرية بإستخدام مصفوفة  متعامدة <span class=""ltr stick-together"">(orthogonal)</span> $U \in \mathbb{R} ^{n \times n}$ ويرمز لها بالرمز  $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$ حيث أن:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda\textrm{ قطرية},\quad A=U\Lambda U^T}\]
</div>
<br>
<p><span class=""new-item item-g"">مجزئ القيمة المفرده <span class=""ltr stick-together"">(singular value decomposition)</span></span> لأي مصفوفة $A$ من الشكل $n\times m$ ، تفكيك القيمة المنفردة <span class=""ltr stick-together"">(SVD)</span> يعتبر طريقة تحليل تضمن وجود $U \in \mathbb{R}^{m \times m}$ ،مصفوفة قطرية  $\Sigma \in \mathbb{R}^{m \times n}$ و $V \in \mathbb{R}^{n \times n}$ حيث أن :</p>
<div class=mobile-container>
\[\boxed{A=U\Sigma V^T}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#calculus id=calculus></a>حساب المصفوفات</h2>
<p><span class=""new-item item-b"">المشتقة في فضاءات عالية <span class=""ltr stick-together"">(gradient)</span></span> افترض $f:\mathbb{R}^{m\times n}\rightarrow\mathbb{R}$ تعتبر دالة و $f: \mathbb{R}^{m \times n} \rightarrow \mathbb{R}$ تعتبر مصفوفة. المشتقة العليا ل $f$ بالنسبة ل $A$  يعتبر مصفوفة $n\times m$ يرمز له $\nabla_A f(A)$ حيث أن:</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_A f(A)\Big)_{i,j}=\frac{\partial f(A)}{\partial A_{i,j}}}\]
</div>
<p><span class=remark>ملاحظة : المشتقة العليا معرفة فقط إذا كانت الدالة $f$ لديها مدى ضمن الأعداد الحقيقية.</span></p>
<br>
<p><span class=""new-item item-b"">هيشيان <span class=""ltr stick-together"">(Hessian)</span></span> افترض $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ تعتبر دالة و $x \in \mathbb{R}^n$ يعتبر متجه. الهيشيان ل $f$ بالنسبة ل $x$ تعتبر مصفوفة متماثلة من الشكل $n \times n$ يرمز لها بالرمز $\nabla_x^2 f(x)$ حيثب أن :</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_x^2 f(x)\Big)_{i,j}=\frac{\partial^2 f(x)}{\partial x_i\partial x_j}}\]
</div>
<p><span class=remark>ملاحظة : الهيشيان معرفة فقط إذا كانت الدالة $f$ لديها مدى ضمن الأعداد الحقيقية.</span></p>
<br>
<p><span class=""new-item item-r"">الحساب في مشتقة الفضاءات العالية</span> لأي مصفوفات $A,B,C$ فإن الخواص التالية مهمة :</p>
<div class=mobile-container>
\[\boxed{\nabla_A\textrm{tr}(AB)=B^T}\quad\quad\boxed{\nabla_{A^T}f(A)=\left(\nabla_Af(A)\right)^T}\]
\[\boxed{\nabla_A\textrm{tr}(ABA^TC)=CAB+C^TAB^T}\quad\quad\boxed{\nabla_A|A|=|A|(A^{-1})^T}\]
</div>
<br>
</div>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
19,"Would you like to see this cheatsheet in your native language? You can help us translating it on GitHub!

CS 229 - Machine Learning العربية English Español فارسی Français 한국어 Português Türkçe Tiếng Việt 简中 繁中 

Probabilities Algebra

Linear Algebra and Calculus refresher Star

General notations

Definitions

Vector We note $x\in\mathbb{R}^n$ a vector with $n$ entries, where $x_i\in\mathbb{R}$ is the $i^{th}$ entry:

\[x=\left(\begin{array}{c}x_1\\x_2\\\vdots\\x_n\end{array}\right)\in\mathbb{R}^n\]

Matrix We note $A\in\mathbb{R}^{m\times n}$ a matrix with $m$ rows and $n$ columns, where $A_{i,j}\in\mathbb{R}$ is the entry located in the $i^{th}$ row and $j^{th}$ column:

\[A=\left(\begin{array}{ccc}A_{1,1}& \cdots&A_{1,n}\\\vdots&& \vdots\\A_{m,1}& \cdots&A_{m,n}\end{array}\right)\in\mathbb{R}^{m\times n}\]

Remark: the vector $x$ defined above can be viewed as a $n\times1$ matrix and is more particularly called a column-vector.

Main matrices

Identity matrix The identity matrix $I\in\mathbb{R}^{n\times n}$ is a square matrix with ones in its diagonal and zero everywhere else:

\[I=\left(\begin{array}{cccc}1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&1\end{array}\right)\]

Remark: for all matrices $A\in\mathbb{R}^{n\times n}$, we have $A\times I=I\times A=A$.

Diagonal matrix A diagonal matrix $D\in\mathbb{R}^{n\times n}$ is a square matrix with nonzero values in its diagonal and zero everywhere else:

\[D=\left(\begin{array}{cccc}d_1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&d_n\end{array}\right)\]

Remark: we also note $D$ as $\textrm{diag}(d_1,...,d_n)$.

Matrix operations

Multiplication

Vector-vector There are two types of vector-vector products:

inner product: for $x,y\in\mathbb{R}^n$, we have: \[\boxed{x^Ty=\sum_{i=1}^nx_iy_i\in\mathbb{R}}\]

outer product: for $x\in\mathbb{R}^m, y\in\mathbb{R}^n$, we have: \[\boxed{xy^T=\left(\begin{array}{ccc}x_1y_1& \cdots&x_1y_n\\\vdots&& \vdots\\x_my_1& \cdots&x_my_n\end{array}\right)\in\mathbb{R}^{m\times n}}\]

Matrix-vector The product of matrix $A\in\mathbb{R}^{m\times n}$ and vector $x\in\mathbb{R}^{n}$ is a vector of size $\mathbb{R}^{m}$, such that:

\[\boxed{Ax=\left(\begin{array}{c}a_{r,1}^Tx\\\vdots\\a_{r,m}^Tx\end{array}\right)=\sum_{i=1}^na_{c,i}x_{i}\in\mathbb{R}^{m}}\]

Matrix-matrix The product of matrices $A\in\mathbb{R}^{m\times n}$ and $B\in\mathbb{R}^{n\times p}$ is a matrix of size $\mathbb{R}^{n\times p}$, such that:

\[\boxed{AB=\left(\begin{array}{ccc}a_{r,1}^Tb_{c,1}& \cdots&a_{r,1}^Tb_{c,p}\\\vdots&& \vdots\\a_{r,m}^Tb_{c,1}& \cdots&a_{r,m}^Tb_{c,p}\end{array}\right)=\sum_{i=1}^na_{c,i}b_{r,i}^T\in\mathbb{R}^{n\times p}}\]

Other operations

Transpose The transpose of a matrix $A\in\mathbb{R}^{m\times n}$, noted $A^T$, is such that its entries are flipped:

\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]

Remark: for matrices $A,B$, we have $(AB)^T=B^TA^T$.

Inverse The inverse of an invertible square matrix $A$ is noted $A^{-1}$ and is the only matrix such that:

\[\boxed{AA^{-1}=A^{-1}A=I}\]

Remark: not all square matrices are invertible. Also, for matrices $A,B$, we have $(AB)^{-1}=B^{-1}A^{-1}$

Trace The trace of a square matrix $A$, noted $\textrm{tr}(A)$, is the sum of its diagonal entries:

\[\boxed{\textrm{tr}(A)=\sum_{i=1}^nA_{i,i}}\]

Remark: for matrices $A,B$, we have $\textrm{tr}(A^T)=\textrm{tr}(A)$ and $\textrm{tr}(AB)=\textrm{tr}(BA)$

Determinant The determinant of a square matrix $A\in\mathbb{R}^{n\times n}$, noted $|A|$ or $\textrm{det}(A)$ is expressed recursively in terms of $A_{\backslash i, \backslash j}$, which is the matrix A without its $i^{th}$ row and $j^{th}$ column, as follows:

\[\boxed{\textrm{det}(A)=|A|=\sum_{j=1}^n(-1)^{i+j}A_{i,j}|A_{\backslash i,\backslash j}|}\]

Remark: $A$ is invertible if and only if $|A|

eq0$. Also, $|AB|=|A||B|$ and $|A^T|=|A|$.

Matrix properties

Definitions

Symmetric decomposition A given matrix $A$ can be expressed in terms of its symmetric and antisymmetric parts as follows:

\[\boxed{A=\underbrace{\frac{A+A^T}{2}}_{\textrm{Symmetric}}+\underbrace{\frac{A-A^T}{2}}_{\textrm{Antisymmetric}}}\]

Norm A norm is a function $N:V\longrightarrow[0,+\infty[$ where $V$ is a vector space, and such that for all $x,y\in V$, we have:

$N(x+y)\leqslant N(x)+N(y)$

$N(ax)=|a|N(x)$ for $a$ scalar

if $N(x)=0$, then $x=0$

For $x\in V$, the most commonly used norms are summed up in the table below:

Norm Notation Definition Use case Manhattan, $L^1$ $||x||_1$ $\displaystyle\sum_{i=1}^n|x_i|$ LASSO regularization Euclidean, $L^2$ $||x||_2$ $\displaystyle\sqrt{\sum_{i=1}^nx_i^2}$ Ridge regularization $p$-norm, $L^p$ $||x||_p$ $\displaystyle\left(\sum_{i=1}^nx_i^p\right)^{\frac{1}{p}}$ Hölder inequality Infinity, $L^{\infty}$ $||x||_{\infty}$ $\underset{i}{\textrm{max }}|x_i|$ Uniform convergence

Linearly dependence A set of vectors is said to be linearly dependent if one of the vectors in the set can be defined as a linear combination of the others.

Remark: if no vector can be written this way, then the vectors are said to be linearly independent.

Matrix rank The rank of a given matrix $A$ is noted $\textrm{rank}(A)$ and is the dimension of the vector space generated by its columns. This is equivalent to the maximum number of linearly independent columns of $A$.

Positive semi-definite matrix A matrix $A\in\mathbb{R}^{n\times n}$ is positive semi-definite (PSD) and is noted $A\succeq 0$ if we have:

\[\boxed{A=A^T}\quad\textrm{ and }\quad\boxed{\forall x\in\mathbb{R}^n,\quad x^TAx\geqslant0}\]

Remark: similarly, a matrix $A$ is said to be positive definite, and is noted $A\succ0$, if it is a PSD matrix which satisfies for all non-zero vector $x$, $x^TAx>0$.

Eigenvalue, eigenvector Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:

\[\boxed{Az=\lambda z}\]

Spectral theorem Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:

\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]

Singular-value decomposition For a given matrix $A$ of dimensions $m\times n$, the singular-value decomposition (SVD) is a factorization technique that guarantees the existence of $U$ $m\times m$ unitary, $\Sigma$ $m\times n$ diagonal and $V$ $n\times n$ unitary matrices, such that:

\[\boxed{A=U\Sigma V^T}\]

Matrix calculus

Gradient Let $f:\mathbb{R}^{m\times n}\rightarrow\mathbb{R}$ be a function and $A\in\mathbb{R}^{m\times n}$ be a matrix. The gradient of $f$ with respect to $A$ is a $m\times n$ matrix, noted $

abla_A f(A)$, such that:

\[\boxed{\Big(

abla_A f(A)\Big)_{i,j}=\frac{\partial f(A)}{\partial A_{i,j}}}\]

Remark: the gradient of $f$ is only defined when $f$ is a function that returns a scalar.

Hessian Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a function and $x\in\mathbb{R}^{n}$ be a vector. The hessian of $f$ with respect to $x$ is a $n\times n$ symmetric matrix, noted $

abla_x^2 f(x)$, such that:

\[\boxed{\Big(

abla_x^2 f(x)\Big)_{i,j}=\frac{\partial^2 f(x)}{\partial x_i\partial x_j}}\]

Remark: the hessian of $f$ is only defined when $f$ is a function that returns a scalar.

Gradient operations For matrices $A,B,C$, the following gradient properties are worth having in mind:

\[\boxed{

abla_A\textrm{tr}(AB)=B^T}\quad\quad\boxed{

abla_{A^T}f(A)=\left(

abla_Af(A)\right)^T}\] \[\boxed{

abla_A\textrm{tr}(ABA^TC)=CAB+C^TAB^T}\quad\quad\boxed{

abla_A|A|=|A|(A^{-1})^T}\]","Main matricesIdentity matrix The identity matrix $I\in\mathbb{R}^{n\times n}$ is a square matrix with ones in its diagonal and zero everywhere else:\[I=\left(\begin{array}{cccc}1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&1\end{array}\right)\]Remark: for all matrices $A\in\mathbb{R}^{n\times n}$, we have $A\times I=I\times A=A$.
Diagonal matrix A diagonal matrix $D\in\mathbb{R}^{n\times n}$ is a square matrix with nonzero values in its diagonal and zero everywhere else:\[D=\left(\begin{array}{cccc}d_1&0& \cdots&0\\0& \ddots& \ddots& \vdots\\\vdots& \ddots& \ddots&0\\0& \cdots&0&d_n\end{array}\right)\]Remark: we also note $D$ as $\textrm{diag}(d_1,...,d_n)$.
Inverse The inverse of an invertible square matrix $A$ is noted $A^{-1}$ and is the only matrix such that:\[\boxed{AA^{-1}=A^{-1}A=I}\]Remark: not all square matrices are invertible.
Matrix rank The rank of a given matrix $A$ is noted $\textrm{rank}(A)$ and is the dimension of the vector space generated by its columns.
If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$.","['ddots', 'linear', 'matrix', 'refresher', 'algebra', 'function', 'square', 'f', 'noted', 'diagonal', 'calculus', 'n', 'vector', 'matrices']",en,Linear Algebra and Calculus refresher,"<!DOCTYPE html><html lang=en><head><base href=../../ ><title>CS 229 - Linear Algebra and Calculus refresher</title><meta charset=utf-8><meta content=""Teaching page of Shervine Amidi, Graduate Student at Stanford University."" name=description><meta content=""teaching, shervine, shervine amidi, data science"" name=keywords><meta content=""width=device-width, initial-scale=1"" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-229/refresher-algebra-calculus rel=canonical><link href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css rel=stylesheet><link href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css rel=stylesheet><link crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq rel=stylesheet><link href=css/style.min.css?b9ca12c0c1a8c9ab26cdba43eda7389e rel=stylesheet type=text/css><link href=css/article.min.css?7ecf0d5a8e06567a9e963d255c1e32e1 rel=stylesheet><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js type=text/javascript></script><script crossorigin=anonymous defer integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script crossorigin=anonymous defer integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script src=js/ga.min.js?973cf97267541a888198336699a55cfd></script><script defer src=js/article.min.js?d4501a257815c34bb5963984260f6b39></script><script defer src=js/lang.min.js?49b78d872651f24046a7aff7b8536db5></script><script async defer src=https://buttons.github.io/buttons.js></script></head> <body data-offset=50 data-spy=scroll data-target=.navbar> <nav class=""navbar navbar-inverse navbar-static-top""> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class=""collapse navbar-collapse"" id=myNavbar> <ul class=""nav navbar-nav""> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class=""nav navbar-nav navbar-center""> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class=""collapse navbar-collapse"" data-target=None id=HiddenNavbar> <ul class=""nav navbar-nav navbar-right""> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style=""padding: 0px;""> <img alt=MIT src=images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style=""padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;""> </a> </ul> </div> </div> </div> </nav> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford src=images/stanford-logo.png?f7176222abba492681ca93190e078e48 style=""width: 15px;"">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Algebra and Calculus</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#notations>General notations</a></div> <div class=dropdown-container> <a href=#notations><span>Definitions</span></a> <a href=#notations><span>Main matrices</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#operations>Matrix operations</a></div> <div class=dropdown-container> <a href=#operations><span>Multiplication</span></a> <a href=#operations><span>Other operations</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#properties>Matrix properties</a></div> <div class=dropdown-container> <a href=#properties><span>Norm</span></a> <a href=#properties><span>Eigenvalue/eigenvector</span></a> <a href=#properties><span>Singular-value decomposition</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#calculus>Matrix calculus</a></div> <div class=dropdown-container> <a href=#calculus><span>Gradient</span></a> <a href=#calculus><span>Hessian</span></a> <a href=#calculus><span>Operations</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf onclick=trackOutboundLink(this); style=""color: white; text-decoration:none;""> <i aria-hidden=false class=""fa fa-github fa-fw""></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class=""markdown-body entry-content"" itemprop=text>
<div class=""alert alert-primary"" role=alert>
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang>
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;>
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class=""btn-group btn-group-justified"" role=group>
  <div class=btn-group role=group>
    <button class=""btn btn-default"" onclick=""location.href='teaching/cs-229/refresher-probabilities-statistics'"" type=button>Probabilities</button>
  </div>
  <div class=btn-group role=group>
    <button class=""btn btn-default active"" onclick=""location.href='teaching/cs-229/refresher-algebra-calculus'"" type=button><b>Algebra</b></button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Linear Algebra and Calculus refresher
  <div style=float:right><a aria-label=""Star afshinea/stanford-cs-229-machine-learning on GitHub"" class=""github-button fa-fw"" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></i>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>General notations</h2>
<h3>Definitions</h3>
<p><span class=""new-item item-b"">Vector</span> We note $x\in\mathbb{R}^n$ a vector with $n$ entries, where $x_i\in\mathbb{R}$ is the $i^{th}$ entry:</p>
<div class=mobile-container>
\[x=\left(\begin{array}{c}x_1\\x_2\\\vdots\\x_n\end{array}\right)\in\mathbb{R}^n\]
</div>
<br>
<p><span class=""new-item item-b"">Matrix</span> We note $A\in\mathbb{R}^{m\times n}$ a matrix with $m$ rows and $n$ columns, where $A_{i,j}\in\mathbb{R}$ is the entry located in the $i^{th}$ row and $j^{th}$ column:</p>
<div class=mobile-container>
\[A=\left(\begin{array}{ccc}A_{1,1}&amp; \cdots&amp;A_{1,n}\\\vdots&amp;&amp; \vdots\\A_{m,1}&amp; \cdots&amp;A_{m,n}\end{array}\right)\in\mathbb{R}^{m\times n}\]
</div>
<p><span class=remark>Remark: the vector $x$ defined above can be viewed as a $n\times1$ matrix and is more particularly called a column-vector.</span></p>
<br>
<h3>Main matrices</h3>
<p><span class=""new-item item-b"">Identity matrix</span> The identity matrix $I\in\mathbb{R}^{n\times n}$ is a square matrix with ones in its diagonal and zero everywhere else:</p>
<div class=mobile-container>
\[I=\left(\begin{array}{cccc}1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;1\end{array}\right)\]
</div>
<p><span class=remark>Remark: for all matrices $A\in\mathbb{R}^{n\times n}$, we have $A\times I=I\times A=A$.</span></p>
<br>
<p><span class=""new-item item-b"">Diagonal matrix</span> A diagonal matrix $D\in\mathbb{R}^{n\times n}$ is a square matrix with nonzero values in its diagonal and zero everywhere else:</p>
<div class=mobile-container>
\[D=\left(\begin{array}{cccc}d_1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;d_n\end{array}\right)\]
</div>
<p><span class=remark>Remark: we also note $D$ as $\textrm{diag}(d_1,...,d_n)$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#operations id=operations></a>Matrix operations</h2>
<h3>Multiplication</h3>
<p><span class=""new-item item-r"">Vector-vector</span> There are two types of vector-vector products:
</p><ul>
<li>inner product: for $x,y\in\mathbb{R}^n$, we have:
<div class=mobile-container>
\[\boxed{x^Ty=\sum_{i=1}^nx_iy_i\in\mathbb{R}}\]
</div>
</li><li>outer product: for $x\in\mathbb{R}^m, y\in\mathbb{R}^n$, we have:
<div class=mobile-container>
\[\boxed{xy^T=\left(\begin{array}{ccc}x_1y_1&amp; \cdots&amp;x_1y_n\\\vdots&amp;&amp; \vdots\\x_my_1&amp; \cdots&amp;x_my_n\end{array}\right)\in\mathbb{R}^{m\times n}}\]
</div>
</li></ul>
<p></p>
<br>
<p><span class=""new-item item-r"">Matrix-vector</span> The product of matrix $A\in\mathbb{R}^{m\times n}$ and vector $x\in\mathbb{R}^{n}$ is a vector of size $\mathbb{R}^{m}$, such that:
</p><div class=mobile-container>
\[\boxed{Ax=\left(\begin{array}{c}a_{r,1}^Tx\\\vdots\\a_{r,m}^Tx\end{array}\right)=\sum_{i=1}^na_{c,i}x_{i}\in\mathbb{R}^{m}}\]
</div>
where $a_{r,i}^T$ are the vector rows and $a_{c,j}$ are the vector columns of $A$, and $x_i$ are the entries of $x$.<p></p>
<br>
<p><span class=""new-item item-r"">Matrix-matrix</span> The product of matrices $A\in\mathbb{R}^{m\times n}$ and $B\in\mathbb{R}^{n\times p}$ is a matrix of size $\mathbb{R}^{n\times p}$, such that:
</p><div class=mobile-container>
\[\boxed{AB=\left(\begin{array}{ccc}a_{r,1}^Tb_{c,1}&amp; \cdots&amp;a_{r,1}^Tb_{c,p}\\\vdots&amp;&amp; \vdots\\a_{r,m}^Tb_{c,1}&amp; \cdots&amp;a_{r,m}^Tb_{c,p}\end{array}\right)=\sum_{i=1}^na_{c,i}b_{r,i}^T\in\mathbb{R}^{n\times p}}\]
</div>
where $a_{r,i}^T, b_{r,i}^T$ are the vector rows and $a_{c,j}, b_{c,j}$ are the vector columns of $A$ and $B$ respectively.<p></p>
<br>
<h3>Other operations</h3>
<p><span class=""new-item item-g"">Transpose</span> The transpose of a matrix $A\in\mathbb{R}^{m\times n}$, noted $A^T$, is such that its entries are flipped:</p>
<div class=mobile-container>
\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]
</div><br>
<p><span class=remark>Remark: for matrices $A,B$, we have $(AB)^T=B^TA^T$.</span></p>
<br>
<p><span class=""new-item item-g"">Inverse</span> The inverse of an invertible square matrix $A$ is noted $A^{-1}$ and is the only matrix such that:</p>
<div class=mobile-container>
\[\boxed{AA^{-1}=A^{-1}A=I}\]
</div>
<p><span class=remark>Remark: not all square matrices are invertible. Also, for matrices $A,B$, we have $(AB)^{-1}=B^{-1}A^{-1}$</span></p>
<br>
<p><span class=""new-item item-g"">Trace</span> The trace of a square matrix $A$, noted $\textrm{tr}(A)$, is the sum of its diagonal entries:</p>
<div class=mobile-container>
\[\boxed{\textrm{tr}(A)=\sum_{i=1}^nA_{i,i}}\]
</div>
<p><span class=remark>Remark: for matrices $A,B$, we have $\textrm{tr}(A^T)=\textrm{tr}(A)$ and $\textrm{tr}(AB)=\textrm{tr}(BA)$</span></p>
<br>
<p><span class=""new-item item-g"">Determinant</span> The determinant of a square matrix $A\in\mathbb{R}^{n\times n}$, noted $|A|$ or $\textrm{det}(A)$ is expressed recursively in terms of $A_{\backslash i, \backslash j}$, which is the matrix A without its $i^{th}$ row and $j^{th}$ column, as follows:</p>
<div class=mobile-container>
\[\boxed{\textrm{det}(A)=|A|=\sum_{j=1}^n(-1)^{i+j}A_{i,j}|A_{\backslash i,\backslash j}|}\]
</div>
<p><span class=remark>Remark: $A$ is invertible if and only if $|A|\neq0$. Also, $|AB|=|A||B|$ and $|A^T|=|A|$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#properties id=properties></a>Matrix properties</h2>
<h3>Definitions</h3>
<p><span class=""new-item item-r"">Symmetric decomposition</span> A given matrix $A$ can be expressed in terms of its symmetric and antisymmetric parts as follows:</p>
<div class=mobile-container>
\[\boxed{A=\underbrace{\frac{A+A^T}{2}}_{\textrm{Symmetric}}+\underbrace{\frac{A-A^T}{2}}_{\textrm{Antisymmetric}}}\]
</div>
<br>
<p><span class=""new-item item-b"">Norm</span> A norm is a function $N:V\longrightarrow[0,+\infty[$ where $V$ is a vector space, and such that for all $x,y\in V$, we have:
</p><ul>
<li>$N(x+y)\leqslant N(x)+N(y)$
</li><li>$N(ax)=|a|N(x)$ for $a$ scalar
</li><li>if $N(x)=0$, then $x=0$</li></ul><p></p>
<p>For $x\in V$, the most commonly used norms are summed up in the table below:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Norm</b></td>
<td align=center><b>Notation</b></td>
<td align=center><b>Definition</b></td>
<td align=center><b>Use case</b></td>
</tr>
<tr>
<td align=center>Manhattan, $L^1$</td>
<td align=center>$||x||_1$</td>
<td align=center>$\displaystyle\sum_{i=1}^n|x_i|$</td>
<td align=center>LASSO regularization</td>
</tr>
<tr>
<td align=center>Euclidean, $L^2$</td>
<td align=center>$||x||_2$</td>
<td align=center>$\displaystyle\sqrt{\sum_{i=1}^nx_i^2}$</td>
<td align=center>Ridge regularization</td>
</tr>
<tr>
<td align=center>$p$-norm, $L^p$</td>
<td align=center>$||x||_p$</td>
<td align=center>$\displaystyle\left(\sum_{i=1}^nx_i^p\right)^{\frac{1}{p}}$</td>
<td align=center>Hölder inequality</td>
</tr>
<tr>
<td align=center>Infinity, $L^{\infty}$</td>
<td align=center>$||x||_{\infty}$</td>
<td align=center>$\underset{i}{\textrm{max }}|x_i|$</td>
<td align=center>Uniform convergence</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class=""new-item item-r"">Linearly dependence</span> A set of vectors is said to be linearly dependent if one of the vectors in the set can be defined as a linear combination of the others.</p>
<p><span class=remark>Remark: if no vector can be written this way, then the vectors are said to be linearly independent.</span></p>
<br>
<p><span class=""new-item item-b"">Matrix rank</span> The rank of a given matrix $A$ is noted $\textrm{rank}(A)$ and is the dimension of the vector space generated by its columns. This is equivalent to the maximum number of linearly independent columns of $A$.</p>
<br>
<p><span class=""new-item item-r"">Positive semi-definite matrix</span> A matrix $A\in\mathbb{R}^{n\times n}$ is positive semi-definite (PSD) and is noted $A\succeq 0$ if we have:</p>
<div class=mobile-container>
\[\boxed{A=A^T}\quad\textrm{ and }\quad\boxed{\forall x\in\mathbb{R}^n,\quad x^TAx\geqslant0}\]
</div>
<p><span class=remark>Remark: similarly, a matrix $A$ is said to be positive definite, and is noted $A\succ0$, if it is a PSD matrix which satisfies for all non-zero vector $x$, $x^TAx&gt;0$.</span></p>
<br>
<p><span class=""new-item item-b"">Eigenvalue, eigenvector</span> Given a matrix $A\in\mathbb{R}^{n\times n}$, $\lambda$ is said to be an eigenvalue of $A$ if there exists a vector $z\in\mathbb{R}^n\backslash\{0\}$, called eigenvector, such that we have:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class=""new-item item-r"">Spectral theorem</span> Let $A\in\mathbb{R}^{n\times n}$. If $A$ is symmetric, then $A$ is diagonalizable by a real orthogonal matrix $U\in\mathbb{R}^{n\times n}$. By noting $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, we have:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda\textrm{ diagonal},\quad A=U\Lambda U^T}\]
</div>
<br>
<p><span class=""new-item item-g"">Singular-value decomposition</span> For a given matrix $A$ of dimensions $m\times n$, the singular-value decomposition (SVD) is a factorization technique that guarantees the existence of $U$ $m\times m$ unitary, $\Sigma$ $m\times n$ diagonal and $V$ $n\times n$ unitary matrices, such that:</p>
<div class=mobile-container>
\[\boxed{A=U\Sigma V^T}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#calculus id=calculus></a>Matrix calculus</h2>
<p><span class=""new-item item-b"">Gradient</span> Let $f:\mathbb{R}^{m\times n}\rightarrow\mathbb{R}$ be a function and $A\in\mathbb{R}^{m\times n}$ be a matrix. The gradient of $f$ with respect to $A$ is a $m\times n$ matrix, noted $\nabla_A f(A)$, such that:</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_A f(A)\Big)_{i,j}=\frac{\partial f(A)}{\partial A_{i,j}}}\]
</div>
<p><span class=remark>Remark: the gradient of $f$ is only defined when $f$ is a function that returns a scalar.</span></p>
<br>
<p><span class=""new-item item-b"">Hessian</span> Let $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ be a function and $x\in\mathbb{R}^{n}$ be a vector. The hessian of $f$ with respect to $x$ is a $n\times n$ symmetric matrix, noted $\nabla_x^2 f(x)$, such that:</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_x^2 f(x)\Big)_{i,j}=\frac{\partial^2 f(x)}{\partial x_i\partial x_j}}\]
</div>
<p><span class=remark>Remark: the hessian of $f$ is only defined when $f$ is a function that returns a scalar.</span></p>
<br>
<p><span class=""new-item item-r"">Gradient operations</span> For matrices $A,B,C$, the following gradient properties are worth having in mind:</p>
<div class=mobile-container>
\[\boxed{\nabla_A\textrm{tr}(AB)=B^T}\quad\quad\boxed{\nabla_{A^T}f(A)=\left(\nabla_Af(A)\right)^T}\]
\[\boxed{\nabla_A\textrm{tr}(ABA^TC)=CAB+C^TAB^T}\quad\quad\boxed{\nabla_A|A|=|A|(A^{-1})^T}\]
</div>
<br>
</article> </div> <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-twitter fa-3x fa-fw""></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class=""fa fa-linkedin fa-3x fa-fw""></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class=""fa fa-github fa-3x fa-fw""></i></a> <a href=""https://scholar.google.com/citations?user=nMnMTm8AAAAJ"" onclick=trackOutboundLink(this);><i class=""fa fa-google fa-3x fa-fw""></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick=""trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld""><i class=""fa fa-envelope fa-3x fa-fw""></i></a> </div> </div> </footer> </body></html>",
